<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Bayesian Inference · PEtab.jl</title><meta name="title" content="Bayesian Inference · PEtab.jl"/><meta property="og:title" content="Bayesian Inference · PEtab.jl"/><meta property="twitter:title" content="Bayesian Inference · PEtab.jl"/><meta name="description" content="Documentation for PEtab.jl."/><meta property="og:description" content="Documentation for PEtab.jl."/><meta property="twitter:description" content="Documentation for PEtab.jl."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/custom_theme.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">PEtab.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../tutorial/">Tutorial</a></li><li><input class="collapse-toggle" id="menuitem-3" type="checkbox"/><label class="tocitem" for="menuitem-3"><span class="docs-label">Extended Tutorials</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../petab_simcond/">Simulation conditions</a></li><li><a class="tocitem" href="../petab_preeq_simulations/">Steady-State Simulations (Pre-Equilibration)</a></li><li><a class="tocitem" href="../petab_event/">Events (callbacks, dosages, etc.)</a></li><li><a class="tocitem" href="../petab_cond_specific/">Simulation Condition-Specific Parameters</a></li><li><a class="tocitem" href="../petab_obs_noise/">Noise and Observable Parameters</a></li><li><a class="tocitem" href="../import_petab/">Importing PEtab Standard Format</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4" type="checkbox"/><label class="tocitem" for="menuitem-4"><span class="docs-label">Parameter Estimation</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../pest_method/">Parameter Estimation Methods</a></li><li><a class="tocitem" href="../pest_plot/">Plotting Estimation Results</a></li><li><a class="tocitem" href="../pest_algs/">Available and Recommended Algorithms</a></li><li><a class="tocitem" href="../pest_select/">Model Selection with PEtab-select</a></li><li><a class="tocitem" href="../pest_custom/">Wrapping Optimization Packages</a></li></ul></li><li class="is-active"><a class="tocitem" href>Bayesian Inference</a><ul class="internal"><li><a class="tocitem" href="#Creating-a-Bayesian-Inference-Problem"><span>Creating a Bayesian Inference Problem</span></a></li><li><a class="tocitem" href="#Bayesian-Inference-(General-Setup)"><span>Bayesian Inference (General Setup)</span></a></li><li><a class="tocitem" href="#Bayesian-inference-with-AdvancedHMC.jl-(NUTS)"><span>Bayesian inference with AdvancedHMC.jl (NUTS)</span></a></li><li><a class="tocitem" href="#Bayesian-inference-with-AdaptiveMCMC.jl"><span>Bayesian inference with AdaptiveMCMC.jl</span></a></li><li><a class="tocitem" href="#References"><span>References</span></a></li></ul></li><li><a class="tocitem" href="../API/">API</a></li><li><a class="tocitem" href="../grad_hess_methods/">Gradient and Hessian Methods</a></li><li><a class="tocitem" href="../default_options/">Default Options</a></li><li><input class="collapse-toggle" id="menuitem-9" type="checkbox"/><label class="tocitem" for="menuitem-9"><span class="docs-label">Performance Tips</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../nonstiff_models/">Non-Biology (Non-Stiff) Models</a></li><li><a class="tocitem" href="../Beer/">Condition-Specific Parameters</a></li><li><a class="tocitem" href="../Bachmann/">Adjoint Sensitivity Analysis (Large Models)</a></li></ul></li><li><a class="tocitem" href="../references/">References</a></li><li><a class="tocitem" href="../FAQ/">FAQ</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Bayesian Inference</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Bayesian Inference</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/sebapersson/PEtab.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/sebapersson/PEtab.jl/blob/main/docs/src/inference.md#" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Bayesian-Inference"><a class="docs-heading-anchor" href="#Bayesian-Inference">Bayesian Inference</a><a id="Bayesian-Inference-1"></a><a class="docs-heading-anchor-permalink" href="#Bayesian-Inference" title="Permalink"></a></h1><p>When performing parameter estimation for a model with PEtab.jl, the unknown model parameters are estimated within a frequentist framework, where the goal is to find the maximum likelihood estimate. When prior knowledge about the parameters is available, Bayesian inference offers an alternative approach to fitting a model to data. The aim of Bayesian inference is to infer the posterior distribution of unknown parameters given the data, <span>$\pi(\mathbf{x} \mid \mathbf{y})$</span>, by running a Markov chain Monte Carlo (MCMC) algorithm to sample from the posterior. A major challenge, aside from creating a good model, is to effectively sample the posterior. PEtab.jl supports Bayesian inference via two packages that implement different sampling algorithms:</p><ul><li><strong>Adaptive Metropolis Hastings Samplers</strong> available in <a href="https://github.com/mvihola/AdaptiveMCMC.jl">AdaptiveMCMC.jl</a> [<a href="../references/#vihola2014ergonomic">12</a>].</li><li><strong>Hamiltonian Monte Carlo (HMC) Samplers</strong> available in <a href="https://github.com/TuringLang/AdvancedHMC.jl">AdvancedHMC.jl</a>. The default HMC sampler is the NUTS sampler, which is the default in Stan [<a href="../references/#hoffman2014no">13</a>, <a href="../references/#carpenter2017stan">14</a>]. HMC samplers are often efficient for continuous targets (models with non-discrete parameters).</li></ul><p>This tutorial covers how to create a <code>PEtabODEProblem</code> with priors and how to use <a href="https://github.com/mvihola/AdaptiveMCMC.jl">AdaptiveMCMC.jl</a> and <a href="https://github.com/TuringLang/AdvancedHMC.jl">AdvancedHMC.jl</a> for Bayesian inference. It should be noted that this part of PEtab.jl is planned to be moved to a separate package, so the syntax will change and be made more user-friendly in the future.</p><div class="admonition is-info" id="Note-8e6126f3c0440114"><header class="admonition-header">Note<a class="admonition-anchor" href="#Note-8e6126f3c0440114" title="Permalink"></a></header><div class="admonition-body"><p>To use the Bayesian inference functionality in PEtab.jl, the Bijectors.jl, LogDensityProblems.jl, and LogDensityProblemsAD.jl packages must be loaded.</p></div></div><h2 id="Creating-a-Bayesian-Inference-Problem"><a class="docs-heading-anchor" href="#Creating-a-Bayesian-Inference-Problem">Creating a Bayesian Inference Problem</a><a id="Creating-a-Bayesian-Inference-Problem-1"></a><a class="docs-heading-anchor-permalink" href="#Creating-a-Bayesian-Inference-Problem" title="Permalink"></a></h2><p>If a PEtab problem is in the PEtab standard format, priors are defined in the <a href="https://petab.readthedocs.io/en/latest/documentation_data_format.html#parameter-table">parameter table</a>. Here, we focus on the case when the model is defined directly in Julia, using a simple saturated growth model. First, we create the model and simulate some data:</p><pre><code class="language-julia hljs">using Distributions, ModelingToolkit, OrdinaryDiffEq, Plots
using ModelingToolkit: t_nounits as t, D_nounits as D
@mtkmodel SYS begin
    @parameters begin
        b1
        b2
    end
    @variables begin
        x(t) = 0.0
    end
    @equations begin
        D(x) ~ b2 * (b1 - x)
    end
end
@mtkbuild sys = SYS()

# Simulate data with normal measurement noise and σ = 0.03
oprob = ODEProblem(sys, [0.0], (0.0, 2.5), [1.0, 0.2])
tsave = range(0.0, 2.5, 101)
dist = Normal(0.0, 0.03)
sol = solve(oprob, Rodas4(), abstol=1e-12, reltol=1e-12, saveat=tsave)
obs = sol[:x] .+ rand(Normal(0.0, 0.03), length(tsave))
plot(sol.t, obs, seriestype=:scatter, title = &quot;Observed data&quot;)</code></pre><img src="e7dae368.svg" alt="Example block output"/><p>Given this, we can now create a <code>PEtabODEProblem</code> (for an introduction, see the starting <a href="../tutorial/#tutorial">tutorial</a>):</p><pre><code class="language-julia hljs">using DataFrames, PEtab
measurements = DataFrame(obs_id=&quot;obs_X&quot;, time=sol.t, measurement=obs)
@parameters sigma
obs_X = PEtabObservable(:x, sigma)
observables = Dict(&quot;obs_X&quot; =&gt; obs_X)</code></pre><p>When defining parameters to estimate via <code>PEtabParameter</code>, a prior can be assigned using any continuous distribution available in <a href="https://github.com/JuliaStats/Distributions.jl">Distributions.jl</a>. For instance, we can set the following priors:</p><ul><li><code>b_1</code>: Uniform distribution between 0.0 and 5.0; <code>Uniform(0.0, 5.0)</code>.</li><li><code>log10_b2</code>: Uniform distribution between -6.0 and log10(5.0); <code>Uniform(-6.0, log10(5.0))</code>.</li><li><code>sigma</code>: Gamma distribution with shape and rate parameters both set to 1.0, <code>Gamma(1.0, 1.0)</code>.</li></ul><p>Using the following code:</p><pre><code class="language-julia hljs">p_b1 = PEtabParameter(:b1, value=1.0, lb=0.0, ub=5.0, scale=:log10, prior_on_linear_scale=true, prior=Uniform(0.0, 5.0))
p_b2 = PEtabParameter(:b2, value=0.2, scale=:log10, prior_on_linear_scale=false, prior=Uniform(-6, log10(5.0)))
p_sigma = PEtabParameter(:sigma, value=0.03, lb=1e-3, ub=1e2, scale=:lin, prior_on_linear_scale=true, prior=Gamma(1.0, 1.0))
pest = [p_b1, p_b2, p_sigma]</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">3-element Vector{PEtabParameter}:
 <span class="sgr1">PEtabParameter:</span> <span class="sgr34">b1</span> estimated on log10-scale with bounds [0.0e+00, 5.0e+00] and prior Uniform(a=0.0, b=5.0)
 <span class="sgr1">PEtabParameter:</span> <span class="sgr34">b2</span> estimated on log10-scale with bounds [1.0e-03, 1.0e+03] and prior Uniform(a=-6.0, b=0.6989700043360189)
 <span class="sgr1">PEtabParameter:</span> <span class="sgr34">sigma</span> estimated on lin-scale with bounds [1.0e-03, 1.0e+02] and prior Gamma(α=1.0, θ=1.0)</code></pre><p>When specifying priors, it is important to keep in mind the parameter scale (where <code>log10</code> is the default). In particular, when <code>prior_on_linear_scale=false</code>, the prior applies to the parameter scale, so for <code>b2</code> above, the prior is on the <code>log10</code> scale. If <code>prior_on_linear_scale=true</code> (the default), the prior is on the linear scale, which applies to <code>b1</code> and <code>sigma</code> above. If a prior is not specified, the default prior is a Uniform distribution on the parameter scale, with bounds corresponding to the upper and lower bounds specified for the <code>PEtabParameter</code>. With these priors, we can now create the <code>PEtabODEProblem</code>.</p><pre><code class="language-julia hljs">osolver = ODESolver(Rodas5P(), abstol=1e-6, reltol=1e-6)
model = PEtabModel(sys, observables, measurements, pest)
petab_prob = PEtabODEProblem(model; odesolver=osolver)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi"><span class="sgr1">PEtabODEProblem:</span> <span class="sgr34">ODESystemModel</span> with ODE-states 1 and 3 parameters to estimate
---------------- <span class="sgr1">Problem options</span> ---------------
Gradient method: <span class="sgr34">ForwardDiff</span>
Hessian method: <span class="sgr34">ForwardDiff</span>
ODE-solver nllh: <span class="sgr34">Rodas5P</span>
ODE-solver gradient: <span class="sgr34">Rodas5P</span></code></pre><h2 id="Bayesian-Inference-(General-Setup)"><a class="docs-heading-anchor" href="#Bayesian-Inference-(General-Setup)">Bayesian Inference (General Setup)</a><a id="Bayesian-Inference-(General-Setup)-1"></a><a class="docs-heading-anchor-permalink" href="#Bayesian-Inference-(General-Setup)" title="Permalink"></a></h2><p>The first step in in order to run Bayesian inference is to construct a <code>PEtabLogDensity</code>. This structure supports the <a href="https://github.com/tpapp/LogDensityProblems.jl">LogDensityProblems.jl</a> interface, meaning it contains all the necessary methods for running Bayesian inference:</p><pre><code class="language-julia hljs">using Bijectors, LogDensityProblems, LogDensityProblemsAD
target = PEtabLogDensity(petab_prob)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi"><span class="sgr1">PEtabLogDensity</span> with 3 parameters to infer</code></pre><p>When performing Bayesian inference, the settings for the ODE solver and gradient computations are those specified in <code>petab_prob</code>. In this case, we use the default gradient method (<code>ForwardDiff</code>) and simulate the ODE model using the <code>Rodas5P</code> ODE solver.</p><p>One important consideration before running Bayesian inference is the starting point. For simplicity, we here use the parameter vector that was used for simulating the data, but note that typically inference should be performed using at least four chains from different starting points [<a href="../references/#gelman2020bayesian">15</a>]:</p><pre><code class="language-julia hljs">x = get_x(petab_prob)</code></pre><p>Lastly, when performing Bayesian inference with PEtab.jl, it is <strong>important</strong> to note that inference is performed on the prior scale. For instance, if a parameter has <code>scale=:log10</code>, but the prior is defined on the linear scale (<code>prior_on_linear_scale=true</code>), inference is performed on the linear scale. Additionally, Bayesian inference algorithms typically prefer to operate in an unconstrained space, so a bounded prior like <code>Uniform(0.0, 5.0)</code> is not ideal. To address this, bounded parameters are <a href="https://mc-stan.org/docs/reference-manual/change-of-variables.html">transformed</a> to be unconstrained.</p><p>In summary, for a parameter vector on the PEtab parameter scale (<code>x</code>), for inference we must transform to the prior scale (<code>xprior</code>), and then to the inference scale (<code>xinference</code>). This can be done via:</p><pre><code class="language-julia hljs">xprior = to_prior_scale(petab_prob.xnominal_transformed, target)
xinference = target.inference_info.bijectors(xprior)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">3-element Vector{Float64}:
 -1.3862943611198906
  1.3329014098421619
 -3.506557897319982</code></pre><div class="admonition is-category-warn" id="Warn-830fff56f5726c64"><header class="admonition-header">Warn<a class="admonition-anchor" href="#Warn-830fff56f5726c64" title="Permalink"></a></header><div class="admonition-body"><p>To get correct inference results, it is important that the starting value is on the transformed parameter scale (as <code>xinference</code> above).</p></div></div><h2 id="Bayesian-inference-with-AdvancedHMC.jl-(NUTS)"><a class="docs-heading-anchor" href="#Bayesian-inference-with-AdvancedHMC.jl-(NUTS)">Bayesian inference with AdvancedHMC.jl (NUTS)</a><a id="Bayesian-inference-with-AdvancedHMC.jl-(NUTS)-1"></a><a class="docs-heading-anchor-permalink" href="#Bayesian-inference-with-AdvancedHMC.jl-(NUTS)" title="Permalink"></a></h2><p>Given a starting point we can run the NUTS sampler with 2000 samples, and 1000 adaptation steps:</p><pre><code class="language-julia hljs">using AdvancedHMC
# δ=0.8 - acceptance rate (default in Stan)
sampler = NUTS(0.8)
res = sample(target, sampler, 2000; n_adapts = 1000, initial_params = xinference,
             drop_warmup=true, progress=false)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi"><span class="sgr36"><span class="sgr1">[ Info: </span></span>Found initial step size 0.00625</code></pre><p>Any other algorithm found in AdvancedHMC.jl <a href="https://github.com/TuringLang/AdvancedHMC.jl">documentation</a> can also be used. To get the output in an easy to interact with format, we can convert it to a <a href="https://github.com/TuringLang/MCMCChains.jl">MCMCChains</a></p><pre><code class="language-julia hljs">using MCMCChains
chain_hmc = PEtab.to_chains(res, target)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Chains MCMC chain (2000×3×1 Array{Float64, 3}):

Iterations        = 1:1:2000
Number of chains  = 1
Samples per chain = 2000
parameters        = b1, b2, sigma

Use `describe(chains)` for summary statistics and quantiles.
</code></pre><p>which we can also plot:</p><pre><code class="language-julia hljs">using Plots, StatsPlots
plot(chain_hmc)</code></pre><img src="7be90bf9.svg" alt="Example block output"/><div class="admonition is-info" id="Note-37a13d0db97ccaab"><header class="admonition-header">Note<a class="admonition-anchor" href="#Note-37a13d0db97ccaab" title="Permalink"></a></header><div class="admonition-body"><p>When converting the output to a <code>MCMCChains</code> the parameters are transformed to the prior-scale (inference scale).</p></div></div><h2 id="Bayesian-inference-with-AdaptiveMCMC.jl"><a class="docs-heading-anchor" href="#Bayesian-inference-with-AdaptiveMCMC.jl">Bayesian inference with AdaptiveMCMC.jl</a><a id="Bayesian-inference-with-AdaptiveMCMC.jl-1"></a><a class="docs-heading-anchor-permalink" href="#Bayesian-inference-with-AdaptiveMCMC.jl" title="Permalink"></a></h2><p>Given a starting point we can run the robust adaptive MCMC sampler for <span>$100 \, 000$</span> iterations with:</p><pre><code class="language-julia hljs">using AdaptiveMCMC
# target.logtarget = posterior logdensity
res = adaptive_rwm(xinference, target.logtarget, 100000; progress=false)</code></pre><p>and we can convert the output to a <code>MCMCChains</code></p><pre><code class="language-julia hljs">chain_adapt = to_chains(res, target)
plot(chain_adapt)</code></pre><img src="b538964e.svg" alt="Example block output"/><p>Any other algorithm found in AdaptiveMCMC.jl <a href="https://github.com/mvihola/AdaptiveMCMC.jl">documentation</a> can also be used.</p><h2 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h2><div class="citation noncanonical"><dl><dt>[12]</dt><dd><div>M. Vihola. <em>Ergonomic and reliable Bayesian inference with adaptive Markov chain Monte Carlo</em>. Wiley statsRef: statistics reference online, 1–12 (2014).</div></dd><dt>[13]</dt><dd><div>M. D. Hoffman, A. Gelman and others. <em>The No-U-Turn sampler: adaptively setting path lengths in Hamiltonian Monte Carlo.</em> J. Mach. Learn. Res. <strong>15</strong>, 1593–1623 (2014).</div></dd><dt>[14]</dt><dd><div>B. Carpenter, A. Gelman, M. D. Hoffman, D. Lee, B. Goodrich, M. Betancourt, M. A. Brubaker, J. Guo, P. Li and A. Riddell. <em>Stan: A probabilistic programming language</em>. Journal of statistical software <strong>76</strong> (2017).</div></dd><dt>[15]</dt><dd><div>A. Gelman, A. Vehtari, D. Simpson, C. C. Margossian, B. Carpenter, Y. Yao, L. Kennedy, J. Gabry, P.-C. Bürkner and M. Modrák. <em>Bayesian workflow</em>, arXiv preprint arXiv:2011.01808 (2020).</div></dd></dl></div></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../pest_custom/">« Wrapping Optimization Packages</a><a class="docs-footer-nextpage" href="../API/">API »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.14.1 on <span class="colophon-date" title="Saturday 12 July 2025 12:01">Saturday 12 July 2025</span>. Using Julia version 1.11.6.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
