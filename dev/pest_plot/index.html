<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Plotting Estimation Results · PEtab.jl</title><meta name="title" content="Plotting Estimation Results · PEtab.jl"/><meta property="og:title" content="Plotting Estimation Results · PEtab.jl"/><meta property="twitter:title" content="Plotting Estimation Results · PEtab.jl"/><meta name="description" content="Documentation for PEtab.jl."/><meta property="og:description" content="Documentation for PEtab.jl."/><meta property="twitter:description" content="Documentation for PEtab.jl."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/custom_theme.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">PEtab.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../tutorial/">Tutorial</a></li><li><input class="collapse-toggle" id="menuitem-3" type="checkbox"/><label class="tocitem" for="menuitem-3"><span class="docs-label">Extended Tutorials</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../petab_simcond/">Simulation conditions</a></li><li><a class="tocitem" href="../petab_preeq_simulations/">Steady-State Simulations (Pre-Equilibration)</a></li><li><a class="tocitem" href="../petab_event/">Events (callbacks, dosages, etc.)</a></li><li><a class="tocitem" href="../petab_cond_specific/">Simulation Condition-Specific Parameters</a></li><li><a class="tocitem" href="../petab_obs_noise/">Noise and Observable Parameters</a></li><li><a class="tocitem" href="../import_petab/">Importing PEtab Standard Format</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4" type="checkbox" checked/><label class="tocitem" for="menuitem-4"><span class="docs-label">Parameter Estimation</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../pest_method/">Parameter Estimation Methods</a></li><li class="is-active"><a class="tocitem" href>Plotting Estimation Results</a><ul class="internal"><li><a class="tocitem" href="#Parameter-Estimation-Result-Plots"><span>Parameter Estimation Result Plots</span></a></li><li><a class="tocitem" href="#Plotting-the-Model-Fit"><span>Plotting the Model Fit</span></a></li><li><a class="tocitem" href="#References"><span>References</span></a></li></ul></li><li><a class="tocitem" href="../pest_algs/">Available and Recommended Algorithms</a></li><li><a class="tocitem" href="../pest_select/">Model Selection with PEtab-select</a></li><li><a class="tocitem" href="../pest_custom/">Wrapping Optimization Packages</a></li></ul></li><li><a class="tocitem" href="../inference/">Bayesian Inference</a></li><li><a class="tocitem" href="../API/">API</a></li><li><a class="tocitem" href="../grad_hess_methods/">Gradient and Hessian Methods</a></li><li><a class="tocitem" href="../default_options/">Default Options</a></li><li><input class="collapse-toggle" id="menuitem-9" type="checkbox"/><label class="tocitem" for="menuitem-9"><span class="docs-label">Performance Tips</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../nonstiff_models/">Non-Biology (Non-Stiff) Models</a></li><li><a class="tocitem" href="../Beer/">Condition-Specific Parameters</a></li><li><a class="tocitem" href="../Bachmann/">Adjoint Sensitivity Analysis (Large Models)</a></li></ul></li><li><a class="tocitem" href="../references/">References</a></li><li><a class="tocitem" href="../FAQ/">FAQ</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Parameter Estimation</a></li><li class="is-active"><a href>Plotting Estimation Results</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Plotting Estimation Results</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/sebapersson/PEtab.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/sebapersson/PEtab.jl/blob/main/docs/src/pest_plot.md#" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="optimization_output_plotting"><a class="docs-heading-anchor" href="#optimization_output_plotting">Plots Evaluating Parameter Estimation</a><a id="optimization_output_plotting-1"></a><a class="docs-heading-anchor-permalink" href="#optimization_output_plotting" title="Permalink"></a></h1><p>Following parameter estimation, it is prudent to evaluate the estimation results. The most straightforward approach is to simulate the model with the estimated parameters and inspect the fit. While informative, this kind of plot does not help determine whether:</p><ul><li>There are unfound parameter sets that yield better fits than those found (indicating that a local minimum was reached).</li><li>There are additional parameter sets yielding equally good fits to those found (suggesting a <em>parameter identifiability</em> problem).</li></ul><p>This page demonstrates various plots implemented in PEtab for evaluating parameter estimation results. These plots can be generated by calling <code>plot</code> on the output of <code>calibrate_model</code> (a <code>PEtabOptimisationResult</code> structure) or <code>calibrate_multistart</code> (a <code>PEtabMultistartResult</code> structure), with the <code>plot_type</code> argument allowing you to select the type of plot. There are two main types of plots that can be generated: (i) those that evaluate parameter estimation results (e.g., objective value, model parameter values), and (ii) those that evaluate and visualize how well the model fits the measured data. This tutorial covers both types.</p><h2 id="Parameter-Estimation-Result-Plots"><a class="docs-heading-anchor" href="#Parameter-Estimation-Result-Plots">Parameter Estimation Result Plots</a><a id="Parameter-Estimation-Result-Plots-1"></a><a class="docs-heading-anchor-permalink" href="#Parameter-Estimation-Result-Plots" title="Permalink"></a></h2><p>As a working example, we use already pre-computed parameter estimation results for a published signaling model, which we load into a <code>PEtabMultistartResult</code> struct (the files to load can be found <a href="https://github.com/sebapersson/PEtab.jl/tree/main/docs/src/assets/optimization_results/boehm">here</a>):</p><pre><code class="language-julia hljs">using PEtab, Plots
path_res = joinpath(@__DIR__, &quot;assets&quot;, &quot;optimization_results&quot;, &quot;boehm&quot;)
ms_res = PEtabMultistartResult(path_res)</code></pre><h3 id="Objective-Function-Evaluations-Plots"><a class="docs-heading-anchor" href="#Objective-Function-Evaluations-Plots">Objective Function Evaluations Plots</a><a id="Objective-Function-Evaluations-Plots-1"></a><a class="docs-heading-anchor-permalink" href="#Objective-Function-Evaluations-Plots" title="Permalink"></a></h3><p>The objective function evaluation plot can be generated by setting <code>plot_type=waterfall</code>, and is available for both single-start and multi-start optimization results. This plot shows the objective value for each iteration of the optimization process. For single-start optimization results, a single trajectory of dots is plotted. For multi-start optimization results, each run corresponds to a trajectory of dots.</p><pre><code class="language-julia hljs">plot(ms_res; plot_type=:objective)</code></pre><img src="6dc8dfa7.svg" alt="Example block output"/><p>If the objective function fails to successfully simulate the model for a particular parameter set (indicating a poor fit), the trajectory for said run is marked with crosses instead of circles.</p><p>In this and other plots for multi-start parameter estimation, different runs are separated by color. The color is assigned via a clustering process that identifies runs converging to the same local minimum (details and tunable options can be found <a href="#optimization_output_plotting_multirun_indexing">here</a>). Additionally, when many multi-starts are performed, plots like the one above can become too cluttered. Therefore, only the 10 best runs are shown by default, but this can be <a href="#optimization_output_plotting_multirun_indexing">customized</a>.</p><div class="admonition is-info" id="Note-541e7a1812eef973"><header class="admonition-header">Note<a class="admonition-anchor" href="#Note-541e7a1812eef973" title="Permalink"></a></header><div class="admonition-body"><p>For the <code>:objective</code> plot type (as well as the <code>:best_objective</code>, <code>:waterfall</code>, and <code>:runtime_eval</code> plot types), PEtab automatically determine whether to use linear or logarithmic scaling of the y-axis. If the largest value in the plot is at least two orders of magnitude larger than the smallest one, logarithmic scaling is used (else, linear). Petab also checks whether a logarithmic y-axis is used in combination with negative objective values. As these cannot be plotted on the logarithmic scale, an automatic rescaling is performed. Here, from each value <span>$plotmin - 1$</span> is subtracted, where <span>$plotmin$</span> is the <em>minimal value encountered in that plot</em> (i.e. the smallest value is set to 1, and other values are scaled linearly with it). These defaults can be changed through the <code>yaxis_scale</code> (scaling of the <code>y-axis</code>) and <code>obj_shift</code> arguments to <code>plot</code>.</p></div></div><h3 id="Best-Objective-Function-Evaluations-Plots"><a class="docs-heading-anchor" href="#Best-Objective-Function-Evaluations-Plots">Best Objective Function Evaluations Plots</a><a id="Best-Objective-Function-Evaluations-Plots-1"></a><a class="docs-heading-anchor-permalink" href="#Best-Objective-Function-Evaluations-Plots" title="Permalink"></a></h3><p>The best objective function evaluation plot can be generated by setting <code>plot_type=waterfall</code>, and is available for both single-start and multi-start optimization results. This plot is similar to the objective function evaluation plot, but instead, it shows the <em>best value reached so far</em> during the process (and is therefore a decreasing function). This is the default plot type for single-start parameter estimation.</p><pre><code class="language-julia hljs">plot(ms_res; plot_type=:best_objective)</code></pre><img src="83e9f7cd.svg" alt="Example block output"/><h3 id="Waterfall-Plots"><a class="docs-heading-anchor" href="#Waterfall-Plots">Waterfall Plots</a><a id="Waterfall-Plots-1"></a><a class="docs-heading-anchor-permalink" href="#Waterfall-Plots" title="Permalink"></a></h3><p>The waterfall plot can be generated by setting <code>plot_type=waterfall</code>, and is only available for multi-start optimization results. This plot-type shows final objective values of all runs, sorted from best to worst. Typically, local minima can be identified as plateaus in the plot, and in PEtab runs with similar final objective value are grouped by colors. This plot is also the default for multi-start optimization results.</p><pre><code class="language-julia hljs">plot(ms_res; plot_type=:waterfall)</code></pre><img src="e86f91f0.svg" alt="Example block output"/><p>We strongly recommend to include a waterfall plot when reporting results from a multistart parameter estimation run. For more information on interpreting a waterfall plot, see Fig. 5 in [<a href="../references/#raue2013lessons">2</a>].</p><h3 id="Parallel-Coordinates-Plots"><a class="docs-heading-anchor" href="#Parallel-Coordinates-Plots">Parallel Coordinates Plots</a><a id="Parallel-Coordinates-Plots-1"></a><a class="docs-heading-anchor-permalink" href="#Parallel-Coordinates-Plots" title="Permalink"></a></h3><p>The parallel coordinates plot can be generated by setting <code>plot_type=parallel_coordinates</code>, and it is available for multi-start optimization results. This plot shows parameter values for the best parameter estimation runs, with each run represented by a line. The parameter values are normalized, where <code>0</code> corresponds to the minimum value encountered for that parameter and <code>1</code> to the maximum. If several runs share similar parameter values, the runs in this cluster likely converged to the same local minimum. Meanwhile, if runs in the same cluster show widely different values for a particular parameter, it indicates that the parameter is unidentifiable (i.e., multiple values of that parameter fit the data equally well).</p><pre><code class="language-julia hljs">plot(ms_res; plot_type=:parallel_coordinates)</code></pre><img src="b226c630.svg" alt="Example block output"/><h3 id="Runtime-Evaluation-Plots"><a class="docs-heading-anchor" href="#Runtime-Evaluation-Plots">Runtime Evaluation Plots</a><a id="Runtime-Evaluation-Plots-1"></a><a class="docs-heading-anchor-permalink" href="#Runtime-Evaluation-Plots" title="Permalink"></a></h3><p>The runtime evaluation plot can be generated by setting the <code>plot_type=runtime_eval</code>, and it is only available for multi-start optimization results. It is a scatter plot that shows the relationship between runtime and final objective value for each run:</p><pre><code class="language-julia hljs">plot(ms_res; plot_type=:runtime_eval)</code></pre><img src="72fb9458.svg" alt="Example block output"/><h3 id="optimization_output_plotting_multirun_clustering"><a class="docs-heading-anchor" href="#optimization_output_plotting_multirun_clustering">Multi-Start Run Color Clustering</a><a id="optimization_output_plotting_multirun_clustering-1"></a><a class="docs-heading-anchor-permalink" href="#optimization_output_plotting_multirun_clustering" title="Permalink"></a></h3><p>When using the <code>calibrate_multistart</code> function, multiple parameter estimation runs are performed. When plotting results for multiple runs, a clustering function is applied by default to identify runs that have likely converged to the same local minimum, and these runs are assigned the same color. The default clustering method is the <code>objective_value_clustering</code> function, which clusters runs if their objective function values are within <code>0.1</code> of each other. Users can define their own clustering function and supply it to the <code>plot</code> command via the <code>clustering_function</code> argument. The custom clustering function should take a <code>Vector{PEtabOptimisationResult}</code> as input and return a <code>Vector{Int64}</code> of the same size, where each index corresponds to the cluster assignment for that run.</p><h3 id="optimization_output_plotting_multirun_indexing"><a class="docs-heading-anchor" href="#optimization_output_plotting_multirun_indexing">Sub-selecting Runs to Plot</a><a id="optimization_output_plotting_multirun_indexing-1"></a><a class="docs-heading-anchor-permalink" href="#optimization_output_plotting_multirun_indexing" title="Permalink"></a></h3><p>When plotting multi-start parameter estimation results with the <code>:objective</code>, <code>:best_objective</code>, or <code>:parallel_coordinates</code> plot types, the output becomes hard to read if more than 10 runs are performed. Therefore, for these plot types, only the <code>10</code> runs with the best final objective values are plotted by default. This can be adjusted using the <code>best_idxs_n</code> optional argument, an <code>Int64</code> specifying how many runs to include in the plot (starting with the best one). Alternatively, the <code>idxs</code> optional argument can be used to specify the indexes of the runs to plot.</p><p>For the <code>:waterfall</code> and <code>:runtime_eval</code> plot types, all runs are plotted by default. However, both the <code>best_idxs_n</code> and <code>idxs</code> arguments can be provided.</p><h2 id="Plotting-the-Model-Fit"><a class="docs-heading-anchor" href="#Plotting-the-Model-Fit">Plotting the Model Fit</a><a id="Plotting-the-Model-Fit-1"></a><a class="docs-heading-anchor-permalink" href="#Plotting-the-Model-Fit" title="Permalink"></a></h2><p>After fitting the model, it is useful to compare the model output against the measurement data. This can be done by providing both the optimization solution and the <code>PEtabODEProblem</code> to the plot command. By default, the plot will show the output solution for all observables for the first simulation condition. However, any subset of observables can be selected using the <code>obsid</code> option, and any simulation condition can be specified using the <code>cid</code> option. Moreover, if a problem has potential pre-equilibration IDs, a specific pre-equilibration condition can be selected using the <code>preeq_id</code> option.</p><p>This tutorial covers how to plot the model fit for different observables and simulation conditions. It assumes you are familiar with PEtab simulation conditions; if not, see this <a href="../petab_simcond/#petab_sim_cond">tutorial</a>. As a working example, we use the Michaelis-Menten enzyme kinetics model from the starting <a href="../tutorial/#tutorial">tutorial</a>, which we fit to for two simulation conditions (<code>cond1</code> and <code>cond2</code>) and two observables (<code>obs_e</code> and <code>obs_p</code>).  Even though the code below encodes the model as a ReactionSystem, everything works exactly the same if the model is encoded as an <code>ODESystem</code>.</p><pre><code class="language-julia hljs">using Catalyst
rn = @reaction_network begin
    kB, S + E --&gt; SE
    kD, SE --&gt; S + E
    kP, SE --&gt; P + E
end
u0 = [:E =&gt; 1.0, :SE =&gt; 0.0, :P =&gt; 0.0]
p_true = [:kB =&gt; 1.0, :kD =&gt; 0.1, :kP =&gt; 0.5]

# Simulate data.
using OrdinaryDiffEq
# cond1
oprob_true_cond1 = ODEProblem(rn,  [:S =&gt; 1.0; u0], (0.0, 10.0), p_true)
true_sol_cond1 = solve(oprob_true_cond1, Rodas5P())
data_sol_cond1 = solve(oprob_true_cond1, Rodas5P(); saveat=1.0)
cond1_t, cond1_e, cond1_p = (data_sol_cond1.t[2:end], (0.8 .+ 0.1*randn(10)) .*
                             data_sol_cond1[:E][2:end], (0.8 .+ 0.1*randn(10)) .*
                             data_sol_cond1[:P][2:end])

# cond2
oprob_true_cond2 = ODEProblem(rn,  [:S =&gt; 0.5; u0], (0.0, 10.0), p_true)
true_sol_cond2 = solve(oprob_true_cond2, Tsit5())
data_sol_cond2 = solve(oprob_true_cond2, Tsit5(); saveat=1.0)
cond2_t, cond2_e, cond2_p = (data_sol_cond2.t[2:end], (0.8 .+ 0.1*randn(10)) .*
                             data_sol_cond2[:E][2:end], (0.8 .+ 0.1*randn(10)) .*
                             data_sol_cond2[:P][2:end])

using PEtab
@unpack E, P = rn
obs_e = PEtabObservable(E, 0.5)
obs_p = PEtabObservable(P, 0.5)
observables = Dict(&quot;obs_e&quot; =&gt; obs_e, &quot;obs_p&quot; =&gt; obs_p)

p_kB = PEtabParameter(:kB)
p_kD = PEtabParameter(:kD)
p_kP = PEtabParameter(:kP)
pest = [p_kB, p_kD, p_kP]

cond1 = Dict(:S =&gt; 1.0)
cond2 = Dict(:S =&gt; 0.5)
conds = Dict(&quot;cond1&quot; =&gt; cond1, &quot;cond2&quot; =&gt; cond2)

using DataFrames
m_cond1_e = DataFrame(simulation_id=&quot;cond1&quot;, obs_id=&quot;obs_e&quot;, time=cond1_t,
                      measurement=cond1_e)
m_cond1_p = DataFrame(simulation_id=&quot;cond1&quot;, obs_id=&quot;obs_p&quot;, time=cond1_t,
                      measurement=cond1_p)
m_cond2_e = DataFrame(simulation_id=&quot;cond2&quot;, obs_id=&quot;obs_e&quot;, time=cond2_t,
                      measurement=cond2_e)
m_cond2_p = DataFrame(simulation_id=&quot;cond2&quot;, obs_id=&quot;obs_p&quot;, time=cond2_t,
                      measurement=cond2_p)
measurements = vcat(m_cond1_e, m_cond1_p, m_cond2_e, m_cond2_p)

model = PEtabModel(rn , observables, measurements, pest; simulation_conditions = conds,
                   speciemap=u0)
petab_prob = PEtabODEProblem(model)

using Optim
res = calibrate_multistart(petab_prob, IPNewton(), 50)</code></pre><p>Following parameter estimation, we can plot the fitted solution for <code>P</code> in the first simulation condition (<code>cond1</code>) as:</p><pre><code class="language-julia hljs">using Plots
plot(res, petab_prob; obsids=[&quot;obs_p&quot;], cid=&quot;cond1&quot;, linewidth = 2.0)</code></pre><img src="c98ae5ac.svg" alt="Example block output"/><p>To instead wish to plot both observables for the second simulation condition (<code>cond2</code>), do:</p><pre><code class="language-julia hljs">plot(res, petab_prob; obsids=[&quot;obs_e&quot;, &quot;obs_p&quot;], cid=&quot;cond2&quot;, linewidth = 2.0)</code></pre><img src="636bddde.svg" alt="Example block output"/><p>In this example, the <code>obsid</code> option is technically not required, as plotting all observables is the default behavior. Furthermore, by default, the observable formula is shown in the legend or label. If the observable formula is long (e.g., the sum of all model species), this can make the plot unreadable. To address this, you can display only the observable ID in the label by setting <code>obsid_label = true</code>:</p><pre><code class="language-julia hljs">plot(res, petab_prob; obsids=[&quot;obs_e&quot;, &quot;obs_p&quot;], cid=&quot;cond2&quot;, linewidth = 2.0, obsid_label = true)</code></pre><img src="74ae7dff.svg" alt="Example block output"/><p>If as above a parameter estimation result (<code>res</code>) is provided, the fit for the best-found parameter vector is plotted. It can also be useful to plot the fit for another parameter vector, such as the initial values <code>x0</code>. This can be easily done, as the <code>plot_fit</code> function also works for any parameter vector that is in the correct order expected by PEtab.jl (for more on parameter order, see <a href="../API/#PEtab.get_x"><code>get_x</code></a>). For example, to plot the fit for the initial value for parameter estimation run 1, do:</p><pre><code class="language-julia hljs">x0 = res.runs[1].x0
plot(x0, petab_prob; obsids=[&quot;obs_e&quot;, &quot;obs_p&quot;], cid=&quot;cond2&quot;, linewidth = 2.0)</code></pre><img src="35b16dba.svg" alt="Example block output"/><p>Finally, it is possible to retrieve a dictionary containing plots for all combinations of observables and simulation conditions with:</p><pre><code class="language-julia hljs">comp_dict = get_obs_comparison_plots(res, petab_prob; linewidth = 2.0)</code></pre><p>Here, <code>comp_dict</code> contains one entry for each condition (with keys corresponding to their condition IDs). Each entry is itself a dictionary that contains one entry for each observable (with keys corresponding to their observable IDs). To retrieve the plot for <code>E</code> and <code>cond1</code> do:</p><pre><code class="language-julia hljs">comp_dict[&quot;cond1&quot;][&quot;obs_e&quot;]</code></pre><img src="a08c63a6.svg" alt="Example block output"/><p>The input to <code>get_obs_comparison_plots</code> can also be a parameter vector.</p><h2 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h2><div class="citation noncanonical"><dl><dt>[2]</dt><dd><div>A. Raue, M. Schilling, J. Bachmann, A. Matteson, M. Schelke, D. Kaschek, S. Hug, C. Kreutz, B. D. Harms, F. J. Theis and others. <em>Lessons learned from quantitative dynamical modeling in systems biology</em>. PloS one <strong>8</strong>, e74335 (2013).</div></dd></dl></div></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../pest_method/">« Parameter Estimation Methods</a><a class="docs-footer-nextpage" href="../pest_algs/">Available and Recommended Algorithms »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Thursday 8 January 2026 14:12">Thursday 8 January 2026</span>. Using Julia version 1.11.8.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
