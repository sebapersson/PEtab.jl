var documenterSearchIndex = {"docs":
[{"location":"pest_method/#pest_methods","page":"Parameter Estimation Methods","title":"Parameter Estimation Methods","text":"The main function of PEtab.jl is to create parameter estimation problems and provide runtime-efficient gradient and Hessian functions for estimating unknown model parameters using suitable numerical optimization algorithms. Specifically, the parameter estimation problems considered by PEtab.jl are on the form:\n\nmin_mathbfx in mathbbR^N -ell(mathbfx) quad textsubject to \nmathbflb leq mathbfx leq mathbfub\n\nWhere, since PEtab.jl works with likelihoods (see the API documentation on PEtabObservable), -ell(mathbfx) is a negative log-likelihood, and mathbflb and mathbfub are the lower and upper parameter bounds. For a good introduction to parameter estimation for ODE models in biology (which is applicable to other fields as well), see [9].\n\nThis advanced section of the documentation focuses on PEtab.jl's parameter estimation functionality, and before reading this part, we recommended the starting tutorial. Specifically, this section of the documentation covers available and recommended optimization algorithms, how to plot optimization results, and how to perform automatic model selection. First though, it covers how to perform parameter estimation. While the PEtabODEProblem contains all the necessary information for wrapping a suitable optimizer to solve the problem (see here), manually wrapping optimizers is cumbersome. Therefore, PEtab.jl provides convenient wrappers for:\n\nSingle-start parameter estimation\nMulti-start parameter estimation\nCreating an OptimizationProblem to access the solvers in Optimization.jl\n\nAs a working example, we use the Michaelis-Menten enzyme kinetics model from the starting tutorial. Even though the code below presents the model as a ReactionSystem, everything works the same if the model is provided as an ODESystem.\n\nusing Catalyst, PEtab\n\n# Create the dynamic model\nrn = @reaction_network begin\n    @parameters S0 c3=1.0\n    @species S(t)=S0\n    c1, S + E --> SE\n    c2, SE --> S + E\n    c3, SE --> P + E\nend\nspeciemap = [:E => 50.0, :SE => 0.0, :P => 0.0]\n\n# Observables\n@unpack E, S = rn\nobs_sum = PEtabObservable(S + E, 3.0)\n@unpack P = rn\n@parameters sigma\nobs_p = PEtabObservable(P, sigma)\nobservables = Dict(\"obs_p\" => obs_p, \"obs_sum\" => obs_sum)\n\n# Parameters to estimate\np_c1 = PEtabParameter(:c1)\np_c2 = PEtabParameter(:c2)\np_s0 = PEtabParameter(:S0)\np_sigma = PEtabParameter(:sigma)\npest = [p_c1, p_c2, p_s0, p_sigma]\n\n# Simulate measurement data with 'true' parameters\nusing OrdinaryDiffEq, DataFrames\nps = [:c1 => 1.0, :c2 => 10.0, :c3 => 1.0, :S0 => 100.0]\nu0 = [:S => 100.0, :E => 50.0, :SE => 0.0, :P => 0.0]\ntspan = (0.0, 10.0)\noprob = ODEProblem(rn, u0, tspan, ps)\nsol = solve(oprob, Rodas5P(); saveat = 0:0.5:10.0)\nobs_sum = (sol[:S] + sol[:E]) .+ randn(length(sol[:E]))\nobs_p = sol[:P] + .+ randn(length(sol[:P]))\ndf_sum = DataFrame(obs_id = \"obs_sum\", time = sol.t, measurement = obs_sum)\ndf_p = DataFrame(obs_id = \"obs_p\", time = sol.t, measurement = obs_p)\nmeasurements = vcat(df_sum, df_p)\n\nmodel = PEtabModel(rn, observables, measurements, pest; speciemap = speciemap)\npetab_prob = PEtabODEProblem(model)\nnothing # hide","category":"section"},{"location":"pest_method/#Single-Start-Parameter-Estimation","page":"Parameter Estimation Methods","title":"Single-Start Parameter Estimation","text":"Single-start parameter estimation is an approach where a numerical optimization algorithm is run from a starting point x0 until it hopefully reaches a local minimum. When performing parameter estimation, the objective function generated by a PEtabODEProblem expects the parameters to be in a specific order. The most straightforward way to obtain a correctly ordered vector is via the get_x function:\n\nFor our working example, we have:\n\nx0 = get_x(petab_prob)\n\nAs discussed in the starting tutorial, x0 is a ComponentArray, meaning it holds both parameter values and names. Additionally, parameters like c1 have a log10 prefix, as the parameter (by default) is estimated on the log10 scale, which typically improves performance [2, 3]. Interacting with a ComponentArray is straightforward, for example, to change c1 to 10.0 do:\n\nx0.log10_c1 = log10(10.0)\nnothing # hide\n\nor alteratively:\n\nx0[:log10_c1] = log10(10.0)\nnothing # hide\n\nnote: Note\nWhen setting values in the starting point vector x0, the new value should be provided on the parameter's scale, which is log10 by default.\n\nGiven a starting point, parameter estimation can be performed with the calibrate function:\n\nFor information and recommendations on algorithms (alg), see this page. For our working example, following the recommendations, we use Optim.jl's Interior-Point Newton method (IPNewton):\n\nusing Optim\nres = calibrate(petab_prob, x0, IPNewton())\n\nThe result from calibrate is returned as a PEtabOptimisationResult which holds the relevant statistics from the optimization:\n\nThe result from calibrate can also be plotted. For example, to see how well the model fits the data, the fit can be plotted as:\n\nusing Plots\ndefault(left_margin=12.5Plots.Measures.mm, bottom_margin=12.5Plots.Measures.mm, size = (600*1.25, 400 * 1.25), palette = [\"#CC79A7\", \"#009E73\", \"#0072B2\", \"#D55E00\", \"#999999\", \"#E69F00\", \"#56B4E9\", \"#F0E442\"], linewidth=4.0) # hide\nplot(res, petab_prob)\n\nInformation on other available plots can be found on this page. Now, even though the plot above may look good, it is important to remember that the objective function (-ell above) often has multiple local minima. To ensure the global optimum is found, a global optimization approach is needed. One effective global method is multi-start parameter estimation.","category":"section"},{"location":"pest_method/#multistart_est","page":"Parameter Estimation Methods","title":"Multi-Start Parameter Estimation","text":"Multi-start parameter estimation is an approach where n parameter estimation runs are initiated from n random starting points. The rationale is that a subset of these runs should, hopefully, converge to the global optimum. While simple, empirical benchmark studies have shown that this method performs well for ODE models in biology [2, 2].\n\nThe first step for multi-start parameter estimation is to generate n starting points. While random uniform sampling may initially seem like a good approach, random points tend to cluster. Instead, it's better to use a Quasi-Monte Carlo method, such as Latin hypercube sampling, to generate more spread-out starting points. This approach has been shown to improve performance [2]. The difference can quite clearly be seen generating 100 random points and 50 Latin hypercube-sampled points on the plane.\n\nusing Distributions, QuasiMonteCarlo, Plots\nimport Random # hide\nRandom.seed!(123) # hide\ns1 = QuasiMonteCarlo.sample(100, [-1.0, -1.0], [1.0, 1.0], Uniform())\ns2 = QuasiMonteCarlo.sample(100, [-1.0, -1.0], [1.0, 1.0], LatinHypercubeSample())\np1 = plot(s1[1, :], s1[2, :], title = \"Uniform sampling\", seriestype=:scatter)\np2 = plot(s2[1, :], s2[2, :], title = \"Latin Hypercube Sampling\", seriestype=:scatter)\np1 = plot(s1[1, :], s1[2, :], title = \"Uniform sampling\", seriestype=:scatter, label = false) # hide\np2 = plot(s2[1, :], s2[2, :], title = \"Latin Hypercube Sampling\", seriestype=:scatter, label = false) # hide\nplot(p1, p2)\nplot(p1, p2; size = (800, 400)) # hide\n\nFor a PEtabODEProblem, Latin hypercube sampled points within the parameter bounds can be generated with the get_startguesses function:\n\nFor our working example, we can generate 50 starting guesses with:\n\nimport Random # hide\nRandom.seed!(123) # hide\nx0s = get_startguesses(petab_prob, 50)\nnothing # hide\n\nIn principle, x0s can now be used together with calibrate to perform multi-start parameter estimation. But, to further simplify this process, PEtab.jl provides a convenient function, calibrate_multistart, which combines start-guess generation and parameter estimation in one step:\n\nTwo important keyword arguments for calibrate_multistart are dirsave and nprocs. If nprocs > 1, the parameter estimation runs are performed in parallel using the pmap function from Distributed.jl with nprocs processes. Even though pmap introduces some overhead because it must load and compile the code on each process, setting nprocs > 1 often reduces runtime when the parameter estimation is expected to take longer than 5 minutes. Meanwhile, dirsave specifies an optional directory to continuously save the results from each individual run. We strongly recommend providing such a directory, as parameter estimation for larger models can take hours or even days. If something goes wrong with the computer during that time, it is, to put it mildly, frustrating to lose all the results. For our working example, we can perform 50 multistarts in parallel on two processes with:\n\nms_res = calibrate_multistart(petab_prob, IPNewton(), 50; nprocs = 2,\n                              dirsave=\"path_to_save_directory\")\n\nThe results are returned as a PEtabMultistartResult, which, in addition to printout statistics, contains relevant information for each run:\n\nFinally, a common approach to evaluate the result of multi-start parameter estimation is through plotting. One widely used evaluation plot is the waterfall plot, which shows the final objective values for each run:\n\nplot(ms_res; plot_type=:waterfall)\n\nIn the waterfall plot, each plateau corresponds to different local optima (represented by different colors). Since many runs (dots) are found on the plateau with the smallest objective value, we can be confident that the global optimum has been found. In addition to waterfall plots, more plotting options can be found on this page.","category":"section"},{"location":"pest_method/#Creating-an-OptimizationProblem","page":"Parameter Estimation Methods","title":"Creating an OptimizationProblem","text":"Optimization.jl is a Julia package that provides a unified interface for over 100 optimization algorithms (see their documentation for the complete list). While Optimization.jl is undoubtedly useful, it is currently undergoing heavy updates, so at the moment we do not recommend it as the default choice for parameter estimation.\n\nThe central object in Optimization.jl is the OptimizationProblem, and PEtab.jl directly supports converting a PEtabODEProblem into an OptimizationProblem:\n\nFor our working example, we can create an OptimizationProblem with:\n\nusing Optimization\nopt_prob = OptimizationProblem(petab_prob)\n\nGiven a start-guess x0, we can then estimate the parameters using, for example, Optim.jl's ParticleSwarm() method, with:\n\nusing OptimizationOptimJL\nopt_prob.u0 .= x0\nres = solve(opt_prob, Optim.ParticleSwarm())\n\nwhich returns an OptimizationSolution. For more information on options and how to interact with OptimizationSolution, see the Optimization.jl documentation.","category":"section"},{"location":"pest_method/#References","page":"Parameter Estimation Methods","title":"References","text":"A. Raue, M. Schilling, J. Bachmann, A. Matteson, M. Schelke, D. Kaschek, S. Hug, C. Kreutz, B. D. Harms, F. J. Theis and others. Lessons learned from quantitative dynamical modeling in systems biology. PloS one 8, e74335 (2013).\n\n\n\nH. Hass, C. Loos, E. Raimundez-Alvarez, J. Timmer, J. Hasenauer and C. Kreutz. Benchmark problems for dynamic modeling of intracellular processes. Bioinformatics 35, 3073–3082 (2019).\n\n\n\nA. F. Villaverde, D. Pathirana, F. Fröhlich, J. Hasenauer and J. R. Banga. A protocol for dynamic model calibration. Briefings in bioinformatics 23, bbab387 (2022).\n\n\n\n","category":"section"},{"location":"pest_method/#PEtab.get_x-pest_method","page":"Parameter Estimation Methods","title":"PEtab.get_x","text":"get_x(prob::PEtabODEProblem; linear_scale = false)::ComponentArray\n\nGet the nominal parameter vector with parameters in the correct order expected by prob for parameter estimation/inference. Nominal values can optionally be specified when creating a PEtabParameter, or in the parameters table if the problem is provided in the PEtab standard format.\n\nFor ease of interaction (e.g., changing values), the parameter vector is returned as a ComponentArray.  For how to interact with a ComponentArray, see the documentation and the ComponentArrays.jl documentation.\n\nSee also PEtabParameter.\n\nKeyword argument\n\nlinear_scale: Whether to return parameters on the linear scale. By default, parameters are returned on the scale they are estimated, which by default is log10 as this often improves parameter estimation performance.\n\n\n\n\n\n","category":"function"},{"location":"pest_method/#PEtab.calibrate-pest_method","page":"Parameter Estimation Methods","title":"PEtab.calibrate","text":"calibrate(prob::PEtabODEProblem, x0, alg; kwargs...)::PEtabOptimisationResult\n\nFrom starting point x0 using optimization algorithm alg, estimate unknown model parameters for prob, and get results as a PEtabOptimisationResult.\n\nx0 can be a Vector or a ComponentArray, where the individual parameters must be in the order expected by prob. To get a vector in the correct order, see get_x.\n\nA list of available and recommended optimization algorithms (alg) can be found in the documentation. Briefly, supported algorithms are from:\n\nOptim.jl: LBFGS(), BFGS(),   or IPNewton() methods.\nIpopt.jl: IpoptOptimizer() interior-point Newton   method.\nFides.py: Fides() Newton trust region method.\n\nDifferent ways to visualize the parameter estimation result can be found in the documentation.\n\nSee also PEtabOptimisationResult, Fides and IpoptOptimizer\n\nKeyword Arguments\n\nsave_trace::Bool = false: Whether to save the optimization trace of the objective   function and parameter vector. Only applicable for some algorithms; see the   documentation for details.\noptions = DEFAULT_OPTIONS: Configurable options for alg. The type and available   options depend on which package alg belongs to. For example, if alg = IPNewton()   from Optim.jl, options should be provided as an Optim.Options() struct. A list of   configurable options can be found in the documentation.\n\n\n\n\n\n","category":"function"},{"location":"pest_method/#PEtab.PEtabOptimisationResult-pest_method","page":"Parameter Estimation Methods","title":"PEtab.PEtabOptimisationResult","text":"PEtabOptimisationResult\n\nParameter estimation statistics from single-start optimization with calibrate.\n\nSee also: calibrate\n\nFields\n\nxmin: Minimizing parameter vector found by the optimization.\nfmin: Minimum objective value found by the optimization.\nx0: Starting parameter vector.\nalg: Parameter estimation algorithm used.\nniterations: Number of iterations for the optimization.\nruntime: Runtime in seconds for the optimization.\nxtrace: Parameter vector optimization trace. Empty if save_trace = false was   provided to calibrate.\nftrace: Objective function optimization trace. Empty if save_trace = false was   provided to calibrate.\nconverged: Convergence flag from alg.\noriginal: Original result struct returned by alg. For example, if alg = IPNewton()   from Optim.jl, original is the Optim return struct.\n\n\n\n\n\n","category":"type"},{"location":"pest_method/#PEtab.get_startguesses-pest_method","page":"Parameter Estimation Methods","title":"PEtab.get_startguesses","text":"get_startguesses([rng::AbstractRNG], prob::PEtabODEProblem, n::Integer; kwargs...)\n\nGenerate n random parameter vectors within the parameter bounds in prob.\n\nrng is optional and if omitted defaults to Random.default_rng(). If n = 1, a single random vector is returned. For n > 1, a vector of random parameter vectors is returned. In both cases, parameter vectors are returned as a ComponentArray. For details on how to interact with a ComponentArray, see the documentation and the ComponentArrays.jl documentation.\n\nSee also calibrate and calibrate_multistart.\n\nKeyword Arguments\n\nsampling_method = LatinHypercubeSample(): Method for sampling a diverse (spread out) set  of parameter vectors. Any algorithm from  QuasiMonteCarlo is allowed, but the  default LatinHypercubeSample is recommended as it usually performs well.\nsample_prior::Bool = true: Whether to sample random parameter values from the  prior distribution if a parameter has a prior.\nallow_inf::Bool = false: Whether to return parameter vectors for which the likelihood  cannot be computed (typically happens because the ODEProblem cannot be solved). Often  it only makes sense to use starting points with a computable likelihood for  parameter estimation, hence it typically does not make sense to change this option.\n\n\n\n\n\n","category":"function"},{"location":"pest_method/#PEtab.calibrate_multistart-pest_method","page":"Parameter Estimation Methods","title":"PEtab.calibrate_multistart","text":"calibrate_multistart([rng::AbstractRng], prob::PEtabODEProblem, alg, nmultistarts::Integer;\n                     nprocs = 1, dirsave=nothing, kwargs...)::PEtabMultistartResult\n\nPerform nmultistarts parameter estimation runs from randomly sampled starting points using the optimization algorithm alg to estimate the unknown model parameters in prob.\n\nA list of available and recommended optimisation algorithms (alg) can be found in the package documentation and in the calibrate documentation.\n\nAs with get_startguesses, the rng controlling the generation of starting points is optional; if omitted, Random.default_rng() is used. For reproducible starting points, pass a seeded rng (e.g., MersenneTwister(42)).\n\nIf nprocs > 1, the parameter estimation runs are performed in parallel using the pmap function from Distributed.jl with nprocs processes. If parameter estimation on a single process (nprocs = 1) takes longer than 5 minutes, we strongly recommend setting nprocs > 1, as this can greatly reduce runtime. Note that nprocs should not be larger than the number of cores on the computer.\n\nIf dirsave is provided, intermediate results for each run are saved in dirsave. It is strongly recommended to provide dirsave for larger models, as parameter estimation can take hours (or even days!),and without dirsave, all intermediate results will be lost if something goes wrong.\n\nDifferent ways to visualize the parameter estimation result can be found in the documentation.\n\nSee also PEtabMultistartResult, get_startguesses, and calibrate.\n\nKeyword Arguments\n\nsampling_method = LatinHypercubeSample(): Method for sampling a diverse (spread out) set  of starting points. See the documentation for get_startguesses, which is the  function used for generating starting points.\nsample_prior::Bool = true: See the documentation for get_startguesses.\noptions = DEFAULT_OPTIONS: Configurable options for alg. See the documentation for   calibrate.\n\n\n\n\n\n","category":"function"},{"location":"pest_method/#PEtab.PEtabMultistartResult-pest_method","page":"Parameter Estimation Methods","title":"PEtab.PEtabMultistartResult","text":"PEtabMultistartResult\n\nParameter estimation statistics from multi-start optimization with calibrate_multistart.\n\nSee also calibrate_multistart and PEtabOptimisationResult.\n\nFields\n\nxmin: Best minimizer across all runs.\nfmin: Best minimum across all runs.\nalg: Parameter estimation algorithm.\nnmultistarts: Number of parameter estimation runs.\nsampling_method: Sampling method used for generating starting points.\ndirsave: Path of directory where parameter estimation run statistics are saved if   dirsave was provided to calibrate_multistart.\nruns: Vector of PEtabOptimisationResult with the parameter estimation results   for each run.\n\nPEtabMultistartResult(dirres::String; which_run::String=\"1\")\n\nImport multistart parameter estimation results saved at dirres.\n\nEach time a new optimization run is performed, results are saved with unique numerical endings. Results from a specific run can be retrieved by specifying the numerical ending with which_run.\n\n\n\n\n\n","category":"type"},{"location":"pest_method/#PEtab.OptimizationProblem-pest_method","page":"Parameter Estimation Methods","title":"PEtab.OptimizationProblem","text":"OptimizationProblem(prob::PEtabODEProblem; box_constraints::Bool = true)\n\nCreate an Optimization.jl OptimizationProblem from prob.\n\nTo use algorithms not compatible with box constraints (e.g., Optim.jl NewtonTrustRegion), set box_constraints = false. Note that with this option, optimizers may move outside the bounds, which can negatively impact performance. More information on how to use an OptimizationProblem can be found in the Optimization.jl documentation.\n\n\n\n\n\n","category":"function"},{"location":"petab_preeq_simulations/#define_with_ss","page":"Steady-State Simulations (Pre-Equilibration)","title":"Steady-State Simulations (Pre-Equilibration)","text":"Sometimes, such as with perturbation experiments, the model should be at a steady state at time zero before performing the simulation that is compared against data. From a modeling perspective, this can be handled by first simulating the model to reach a steady state and then, possibly by changing some control parameters, perform the main simulation. In PEtab.jl, this is handled by defining pre-equilibration simulation conditions.\n\nThis tutorial covers how to specify pre-equilibration conditions for a PEtabModel. It requires that you are familiar with PEtab simulation conditions, if not; see this tutorial. As a working example, we use the Michaelis-Menten enzyme kinetics model from the starting tutorial. Even though the code below encodes the model as a ReactionSystem, everything works exactly the same if the model is encoded as an ODESystem.\n\nusing Catalyst, PEtab\n\nrn = @reaction_network begin\n    @parameters S0 c3=1.0\n    @species S(t)=S0\n    c1, S + E --> SE\n    c2, SE --> S + E\n    c3, SE --> P + E\nend\nspeciemap = [:E => 50.0, :SE => 0.0, :P => 0.0]\n\n@unpack E, S, P = rn\n@parameters sigma\nobs_sum = PEtabObservable(S + E, 3.0)\nobs_p = PEtabObservable(P, sigma)\nobservables = Dict(\"obs_p\" => obs_p, \"obs_sum\" => obs_sum)\n\n# Unlike the starting tutorial we do not estimate S0 here as it below \n# dictates simulation conditions\np_c1 = PEtabParameter(:c1)\np_c2 = PEtabParameter(:c2)\np_sigma = PEtabParameter(:sigma)\npest = [p_c1, p_c2, p_sigma]\nnothing # hide","category":"section"},{"location":"petab_preeq_simulations/#Specifying-Pre-equilibration-Conditions","page":"Steady-State Simulations (Pre-Equilibration)","title":"Specifying Pre-equilibration Conditions","text":"Pre-equilibration conditions are specified in the same way as simulation conditions. For instance, assume we have two simulation conditions for which we have measurement data (cond1 and cond2), where in cond1, the parameter value for S0 is 3.0, and in cond2, the value for S0 is 5.0:\n\ncond1 = Dict(:S0 => 3.0)\ncond2 = Dict(:S0 => 5.0)\nnothing # hide\n\nAdditionally, assume that before gathering measurements for conditions cond1 and cond2, the system should be at a steady state starting from S0 = 2.0. This pre-equilibration condition (the conditions under which the system reaches steady state) is defined just like any other simulation condition:\n\ncond_preeq = Dict(:S0 => 2.0)\nnothing # hide\n\nAs usual, the condition should be collected in a Dict:\n\nconds = Dict(\"cond_preeq\" => cond_preeq, \"cond1\" => cond1, \"cond2\" => cond2)","category":"section"},{"location":"petab_preeq_simulations/#Mapping-Measurements-to-Pre-equilibration-Conditions","page":"Steady-State Simulations (Pre-Equilibration)","title":"Mapping Measurements to Pre-equilibration Conditions","text":"To properly link the measurements to a specific simulation configuration, both the main simulation ID and the pre-equilibration ID must be specified in the measurements DataFrame. For our working example, a valid measurement table would look like this (the column names matter, but not the order):\n\nsimulation_id (str) pre_eq_id (str) obs_id (str) time (float) measurement (float)\ncond1 cond_preeq obs_p 1.0 2.5\ncond1 cond_preeq obs_sum 10.0 50.0\ncond2 cond_preeq obs_p 1.0 2.6\ncond2 cond_preeq obs_sum 20.0 51.0\n\nFor each measurement, the simulation configuration is interpreted as follows: the model is first simulated to a steady state using the condition specified in the pre_eq_id column, and then the model is simulated and compared against the data using the condition in the simulation_id. In Julia this measurement table would look like:\n\nusing DataFrames\nmeasurements = DataFrame(simulation_id=[\"cond1\", \"cond1\", \"cond2\", \"cond2\"],\n                         pre_eq_id=[\"cond_preeq\", \"cond_preeq\", \"cond_preeq\", \"cond_preeq\"],\n                         obs_id=[\"obs_p\", \"obs_sum\", \"obs_p\", \"obs_sum\"],\n                         time=[1.0, 10.0, 1.0, 20.0],\n                         measurement=[2.5, 50.0, 2.6, 51.0])","category":"section"},{"location":"petab_preeq_simulations/#Bringing-It-All-Together","page":"Steady-State Simulations (Pre-Equilibration)","title":"Bringing It All Together","text":"Given a Dict with simulation conditions and measurements in the correct format, it is straightforward to create a PEtab problem with pre-equilibration conditions by providing the condition Dict under the simulation_conditions keyword:\n\nmodel = PEtabModel(rn, observables, measurements, pest;\n                   simulation_conditions = conds)\npetab_prob = PEtabODEProblem(model)\n\nFrom the printout, we see that the PEtabODEProblem now has a SteadyStateSolver. The default steady-state solver is generally a good choice, but if you are interested in more details, see to the API and [this] ADD! example.","category":"section"},{"location":"petab_preeq_simulations/#Additional-Possible-Pre-equilibration-Configurations","page":"Steady-State Simulations (Pre-Equilibration)","title":"Additional Possible Pre-equilibration Configurations","text":"In the example above, each measurement has the same pre-equilibration condition, and all observations have a pre-equilibration condition. PEtab.jl also allows for more flexibility, and the following configurations are supported:\n\nDifferent pre-equilibration conditions: If measurements have different pre-equilibration conditions, simply define these as simulation conditions, and specify the corresponding condition in the pre_eq_id column of the measurements table.\nNo pre-equilibration for some measurements: If some measurements do not require pre-equilibration, leave the entry in the pre_eq_id column empty for these measurements.","category":"section"},{"location":"references/#References","page":"References","title":"References","text":"Throughout the documentation, references related to parameter estimation for ODE models can be found. This page contains a complete list of all references mentioned in the documentation.\n\nF. Fröhlich and P. K. Sorger. Fides: Reliable trust-region optimization for parameter estimation of ordinary differential equation models. PLoS computational biology 18, e1010322 (2022).\n\n\n\nA. Raue, M. Schilling, J. Bachmann, A. Matteson, M. Schelke, D. Kaschek, S. Hug, C. Kreutz, B. D. Harms, F. J. Theis and others. Lessons learned from quantitative dynamical modeling in systems biology. PloS one 8, e74335 (2013).\n\n\n\nH. Hass, C. Loos, E. Raimundez-Alvarez, J. Timmer, J. Hasenauer and C. Kreutz. Benchmark problems for dynamic modeling of intracellular processes. Bioinformatics 35, 3073–3082 (2019).\n\n\n\nH. Wickham. Tidy data. Journal of statistical software 59, 1–23 (2014).\n\n\n\nA. F. Villaverde, F. Fröhlich, D. Weindl, J. Hasenauer and J. R. Banga. Benchmarking optimization methods for parameter estimation in large kinetic models. Bioinformatics 35, 830–838 (2019).\n\n\n\nF. Fröhlich, F. J. Theis, J. O. Rädler and J. Hasenauer. Parameter estimation for dynamical systems with discrete events and logical operations. Bioinformatics 33, 1049–1056 (2017).\n\n\n\nL. Schmiester, Y. Schälte, F. T. Bergmann, T. Camba, E. Dudkin, J. Egert, F. Fröhlich, L. Fuhrmann, A. L. Hauber, S. Kemmer and others. PEtab—Interoperable specification of parameter estimation problems in systems biology. PLoS computational biology 17, e1008646 (2021).\n\n\n\nM. E. Boehm, L. Adlung, M. Schilling, S. Roth, U. Klingmüller and W. D. Lehmann. Identification of isoform-specific dynamics in phosphorylation-dependent STAT5 dimerization by quantitative mass spectrometry and mathematical modeling. Journal of proteome research 13, 5685–5694 (2014).\n\n\n\nA. F. Villaverde, D. Pathirana, F. Fröhlich, J. Hasenauer and J. R. Banga. A protocol for dynamic model calibration. Briefings in bioinformatics 23, bbab387 (2022).\n\n\n\nA. Wächter and L. T. Biegler. On the implementation of an interior-point filter line-search algorithm for large-scale nonlinear programming. Mathematical programming 106, 25–57 (2006).\n\n\n\nM. Gabel, T. Hohl, A. Imle, O. T. Fackler and F. Graw. FAMoS: A Flexible and dynamic Algorithm for Model Selection to analyse complex systems dynamics. PLOS Computational Biology 15, e1007230 (2019).\n\n\n\nM. Vihola. Ergonomic and reliable Bayesian inference with adaptive Markov chain Monte Carlo. Wiley statsRef: statistics reference online, 1–12 (2014).\n\n\n\nM. D. Hoffman, A. Gelman and others. The No-U-Turn sampler: adaptively setting path lengths in Hamiltonian Monte Carlo. J. Mach. Learn. Res. 15, 1593–1623 (2014).\n\n\n\nB. Carpenter, A. Gelman, M. D. Hoffman, D. Lee, B. Goodrich, M. Betancourt, M. A. Brubaker, J. Guo, P. Li and A. Riddell. Stan: A probabilistic programming language. Journal of statistical software 76 (2017).\n\n\n\nA. Gelman, A. Vehtari, D. Simpson, C. C. Margossian, B. Carpenter, Y. Yao, L. Kennedy, J. Gabry, P.-C. Bürkner and M. Modrák. Bayesian workflow, arXiv preprint arXiv:2011.01808 (2020).\n\n\n\nF. Sapienza, J. Bolibar, F. Schäfer, B. Groenke, A. Pal, V. Boussange, P. Heimbach, G. Hooker, F. Pérez, P.-O. Persson and others. Differentiable Programming for Differential Equations: A Review, arXiv preprint arXiv:2406.09699 (2024).\n\n\n\nM. Blondel and V. Roulet. The elements of differentiable programming, arXiv preprint arXiv:2403.14606 (2024).\n\n\n\nJ. Revels, M. Lubin and T. Papamarkou. Forward-mode automatic differentiation in Julia, arXiv preprint arXiv:1607.07892 (2016).\n\n\n\nR. Mester, A. Landeros, C. Rackauckas and K. Lange. Differential methods for assessing sensitivity in biological models. PLoS computational biology 18, e1009598 (2022).\n\n\n\nF. Fröhlich, B. Kaltenbacher, F. J. Theis and J. Hasenauer. Scalable parameter estimation for genome-scale biochemical reaction networks. PLoS computational biology 13, e1005331 (2017).\n\n\n\nY. Ma, V. Dixit, M. J. Innes, X. Guo and C. Rackauckas. A comparison of automatic differentiation and continuous sensitivity analysis for derivatives of differential equation solutions. In: 2021 IEEE High Performance Extreme Computing Conference (HPEC) (IEEE, 2021); pp. 1–9.\n\n\n\nA. Raue, B. Steiert, M. Schelker, C. Kreutz, T. Maiwald, H. Hass, J. Vanlier, C. Tönsing, L. Adlung, R. Engesser and others. Data2Dynamics: a modeling environment tailored to parameter estimation in dynamical systems. Bioinformatics 31, 3558–3560 (2015).\n\n\n\nP. Städter, Y. Schälte, L. Schmiester, J. Hasenauer and P. L. Stapor. Benchmarking of numerical integration methods for ODE models of biological systems. Scientific reports 11, 2696 (2021).\n\n\n\nR. Beer, K. Herbst, N. Ignatiadis, I. Kats, L. Adlung, H. Meyer, D. Niopek, T. Christiansen, F. Georgi, N. Kurzawa and others. Creating functional engineered variants of the single-module non-ribosomal peptide synthetase IndC by T domain exchange. Molecular BioSystems 10, 1709–1718 (2014).\n\n\n\nJ. Bachmann, A. Raue, M. Schilling, M. E. Böhm, C. Kreutz, D. Kaschek, H. Busch, N. Gretz, W. D. Lehmann, J. Timmer and others. Division of labor by dual feedback regulators controls JAK2/STAT5 signaling over broad ligand range. Molecular systems biology 7, 516 (2011).\n\n\n\n","category":"section"},{"location":"petab_simcond/#petab_sim_cond","page":"Simulation conditions","title":"Simulation Conditions","text":"Sometimes measurements are collected under various experimental conditions, where, for example, the initial concentration of a substrate differs between conditions. From a modeling viewpoint, experimental conditions correspond to different simulation conditions where the model is simulated with different initial values and/or different values for a set of control parameters for each simulation condition. In other words, for each simulation condition, a unique model simulation is performed.\n\nThis tutorial covers how to specify simulation conditions for a PEtabModel. As a working example, we use the Michaelis-Menten enzyme kinetics model from the starting tutorial. Even though the code below encodes the model as a ReactionSystem, everything works exactly the same if the model is encoded as an ODESystem.\n\nusing Catalyst, PEtab\n\nrn = @reaction_network begin\n    @parameters S0 c3=1.0\n    @species S(t)=S0\n    c1, S + E --> SE\n    c2, SE --> S + E\n    c3, SE --> P + E\nend\nspeciemap = [:E => 50.0, :SE => 0.0, :P => 0.0]\n\n@unpack E, S, P = rn\n@parameters sigma\nobs_sum = PEtabObservable(S + E, 3.0)\nobs_p = PEtabObservable(P, sigma)\nobservables = Dict(\"obs_p\" => obs_p, \"obs_sum\" => obs_sum)\n\np_c1 = PEtabParameter(:c1)\np_c2 = PEtabParameter(:c2)\np_s0 = PEtabParameter(:S0)\np_sigma = PEtabParameter(:sigma)\npest = [p_c1, p_c2, p_s0, p_sigma]\nusing Plots # hide\ndefault(left_margin=12.5Plots.Measures.mm, bottom_margin=12.5Plots.Measures.mm, size = (600*1.25, 400 * 1.25), palette = [\"#CC79A7\", \"#009E73\", \"#0072B2\", \"#D55E00\", \"#999999\", \"#E69F00\", \"#56B4E9\", \"#F0E442\"], linewidth=4.0) # hide\nnothing # hide","category":"section"},{"location":"petab_simcond/#Specifying-Simulation-Conditions","page":"Simulation conditions","title":"Specifying Simulation Conditions","text":"Simulation conditions should be encoded as a Dict, where for each condition, the parameters and/or initial values that change are specified. For instance, assume we have two simulation conditions (cond1 and cond2), where in cond1, the initial value for E is 0.0 and the parameter c3 is 1.0, whereas in cond2, the initial value for E is 3.0 and the parameter c3 is 2.0. This is encoded as:\n\ncond1 = Dict(:E => 50.0, :c3 => 1.0)\ncond2 = Dict(:E => 100.0, :c3 => 2.0)\nconds = Dict(\"cond1\" => cond1, \"cond2\" => cond2)\n\nIn more detail, if a specie is specified (e.g., E above), its initial value is set to the provided value. Meanwhile, if a parameter is specified (e.g., c3 above), the parameter is set to the provided value.\n\nnote: Note\nIf a parameter or species is specified for one simulation condition, it must be specified for all simulation conditions. This to prevent ambiguity when simulating the model.","category":"section"},{"location":"petab_simcond/#Mapping-Measurements-to-Simulation-Conditions","page":"Simulation conditions","title":"Mapping Measurements to Simulation Conditions","text":"To properly link the measurements to a specific simulation condition, the condition ID for each measurement must be specified in the measurement DataFrame. For our working example, a valid measurement table would look like (the column names matter, but not the order):\n\nsimulation_id (str) obs_id (str) time (float) measurement (float)\ncond1 obs_p 1.0 0.7\ncond1 obs_sum 10.0 0.1\ncond2 obs_p 1.0 1.0\ncond2 obs_sum 20.0 1.5\n\nIn Julia this would look like:\n\nusing DataFrames\nmeasurements = DataFrame(simulation_id=[\"cond1\", \"cond1\", \"cond2\", \"cond2\"],\n                         obs_id=[\"obs_p\", \"obs_sum\", \"obs_p\", \"obs_sum\"],\n                         time=[1.0, 10.0, 1.0, 20.0],\n                         measurement=[0.7, 0.1, 1.0, 1.5])","category":"section"},{"location":"petab_simcond/#Bringing-It-All-Together","page":"Simulation conditions","title":"Bringing It All Together","text":"Given a Dict with simulation conditions and measurements in the correct format, it is straightforward to create a PEtab problem with multiple simulation conditions by providing the condition Dict under the simulation_conditions keyword:\n\nmodel = PEtabModel(rn, observables, measurements, pest; simulation_conditions = conds)\npetab_prob = PEtabODEProblem(model)\n\nFrom plotting the solution of the ODE model for cond1 and cond2, we can clearly see that both the dynamics and initial value for specie E differs:\n\nusing Plots\nx = get_x(petab_prob)\nsol_cond1 = get_odesol(x, petab_prob; cid = \"cond1\")\nsol_cond2 = get_odesol(x, petab_prob; cid = \"cond2\")\np1 = plot(sol_cond1, title = \"cond1\")\np2 = plot(sol_cond2, title = \"cond2\")\nplot(p1, p2)\nplot(p1, p2; size = (800, 400)) # hide","category":"section"},{"location":"Bachmann/#adjoint","page":"Adjoint Sensitivity Analysis (Large Models)","title":"Adjoint Sensitivity Analysis (large models)","text":"Having access to the gradient is beneficial for parameter estimation, as gradient-based optimization algorithms often perform best [2, 5]. For large model, the most efficient gradient method is adjoint sensitivity analysis [20, 21], with a good mathematical description provided in [16]. PEtab.jl supports the adjoint sensitivity algorithms in SciMLSensitivity.jl. For these algorithms, three key options impact performance: which algorithm is used to compute the gradient quadrature, which method is used to compute the Vector-Jacobian-Product (VJP) in the adjoint ODE, and which ODE solver is used. This advanced example covers these considerations and assumes familiarity with gradient methods in PEtab (see this page). In addition to this page, further details on tunable options are available in the SciMLSensitivity documentation.\n\nAs a working example, we use a published signaling model referred to as the Bachhman model after the first author [25]. The Bachmann model is available in the PEtab standard format (a tutorial on importing problems in the standard format can be found here), and the PEtab files for this model can be downloaded from here. Given the problem YAML file, we can import the problem as:\n\nusing PEtab\npath_yaml = joinpath(@__DIR__, \"assets\", \"bachmann\", \"Bachmann_MSB2011.yaml\")\nmodel = PEtabModel(path_yaml)\nnothing # hide","category":"section"},{"location":"Bachmann/#Tuning-Options","page":"Adjoint Sensitivity Analysis (Large Models)","title":"Tuning Options","text":"The Bachmann model is a medium-sized model with 25 species in the ODE system and 113 parameters to estimate. Even though gradient_method=:ForwardDiff performs best for this model (more on this below), it is a good example for showcasing different tuning options. In particular, when computing the gradient via adjoint sensitivity analysis, the key tunable options for a PEtabODEProblem are:\n\nodesolver_gradient: Which ODE solver and solver tolerances (abstol and reltol) to use when solving the adjoint ODE system. Currently, CVODE_BDF() performs best.\nsensealg: Which adjoint algorithm to use. PEtab.jl supports the InterpolatingAdjoint, QuadratureAdjoint, and GaussAdjoint methods from SciMLSensitivity. For these, the most important tunable option is the VJP method, where EnzymeVJP often performs best. If this method does not work, ReverseDiffVJP(true) is a good alternative.\n\nAs QuadratureAdjoint is the least reliable method, we here explore InterpolatingAdjoint and GaussAdjoint:\n\nusing SciMLSensitivity, Sundials\nosolver = ODESolver(CVODE_BDF(); abstol_adj = 1e-3, reltol_adj = 1e-6)\npetab_prob1 = PEtabODEProblem(model; gradient_method = :Adjoint,\n                              odesolver = osolver, odesolver_gradient = osolver,\n                              sensealg = InterpolatingAdjoint(autojacvec = ReverseDiffVJP(true)))\npetab_prob2 = PEtabODEProblem(model; gradient_method = :Adjoint,\n                              odesolver = osolver, odesolver_gradient = osolver,\n                              sensealg = GaussAdjoint(autojacvec = ReverseDiffVJP(true)))\nnothing # hide\n\nTwo things should be noted here. First, to use the adjoint functionality in PEtab.jl, SciMLSensitivity must be loaded. Second, when creating the ODESolver, adj_abstol sets the tolerances for solving the adjoint ODE (but not the standard forward ODE). From our experience, setting the adjoint tolerances lower than the default 1e-8 improves simulation stability (gradient computations fail less frequently). Given this, we can now compare runtime:\n\nusing Printf\nx = get_x(petab_prob1)\ng1, g2 = similar(x), similar(x)\npetab_prob1.grad!(g1, x)\npetab_prob2.grad!(g2, x)\nb1 = @elapsed petab_prob1.grad!(g1, x) # hide\nb2 = @elapsed petab_prob2.grad!(g2, x) # hide\n@printf(\"Runtime InterpolatingAdjoint: %.1fs\\n\", b1)\n@printf(\"Runtime GaussAdjoint: %.1fs\\n\", b2)\n\nIn this case InterpolatingAdjoint performs best (this can change dependent on computer). As mentioned above, another important argument is the VJP method; let us explore the best two options for InterpolatingAdjoint:\n\npetab_prob1 = PEtabODEProblem(model; gradient_method = :Adjoint,\n                              odesolver = osolver, odesolver_gradient = osolver,\n                              sensealg = InterpolatingAdjoint(autojacvec = EnzymeVJP()))\npetab_prob2 = PEtabODEProblem(model; gradient_method = :Adjoint,\n                              odesolver = osolver, odesolver_gradient = osolver,\n                              sensealg = InterpolatingAdjoint(autojacvec = ReverseDiffVJP(true)))\npetab_prob1.grad!(g1, x) # hide\npetab_prob2.grad!(g2, x) # hide\nb1 = @elapsed petab_prob1.grad!(g1, x)\nb2 = @elapsed petab_prob2.grad!(g2, x)\n@printf(\"Runtime EnzymeVJP() : %.1fs\\n\", b1)\n@printf(\"Runtime ReverseDiffVJP(true): %.1fs\\n\", b2)                              \nnothing # hide\n\nIn this case, ReverseDiffVJP(true) performs best (this can vary depending on the computer), but often EnzymeVJP is the better choice. Generally, GaussAdjoint with EnzymeVJP is often the best combination, but as seen above, this is not always the case. Therefore, for larger models where runtime can be substantial, we recommend benchmarking different adjoint algorithms and VJP methods to find the best configuration for your specific problem.\n\nLastly, it should be noted that even if gradient_method=:Adjoint is the fastest option for larger models, we still recommend using :ForwardDiff if it is not substantially slower. This is because computing the gradient via adjoint methods is much more challenging than with forward methods, as the adjoint approach requires solving a difficult adjoint ODE. In our benchmarks, we have observed that sometimes :ForwardDiff successfully computes the gradient, while :Adjoint does not. Moreover, forward methods tend to produce more accurate gradients.","category":"section"},{"location":"Bachmann/#References","page":"Adjoint Sensitivity Analysis (Large Models)","title":"References","text":"A. Raue, M. Schilling, J. Bachmann, A. Matteson, M. Schelke, D. Kaschek, S. Hug, C. Kreutz, B. D. Harms, F. J. Theis and others. Lessons learned from quantitative dynamical modeling in systems biology. PloS one 8, e74335 (2013).\n\n\n\nA. F. Villaverde, F. Fröhlich, D. Weindl, J. Hasenauer and J. R. Banga. Benchmarking optimization methods for parameter estimation in large kinetic models. Bioinformatics 35, 830–838 (2019).\n\n\n\nF. Sapienza, J. Bolibar, F. Schäfer, B. Groenke, A. Pal, V. Boussange, P. Heimbach, G. Hooker, F. Pérez, P.-O. Persson and others. Differentiable Programming for Differential Equations: A Review, arXiv preprint arXiv:2406.09699 (2024).\n\n\n\nF. Fröhlich, B. Kaltenbacher, F. J. Theis and J. Hasenauer. Scalable parameter estimation for genome-scale biochemical reaction networks. PLoS computational biology 13, e1005331 (2017).\n\n\n\nY. Ma, V. Dixit, M. J. Innes, X. Guo and C. Rackauckas. A comparison of automatic differentiation and continuous sensitivity analysis for derivatives of differential equation solutions. In: 2021 IEEE High Performance Extreme Computing Conference (HPEC) (IEEE, 2021); pp. 1–9.\n\n\n\nJ. Bachmann, A. Raue, M. Schilling, M. E. Böhm, C. Kreutz, D. Kaschek, H. Busch, N. Gretz, W. D. Lehmann, J. Timmer and others. Division of labor by dual feedback regulators controls JAK2/STAT5 signaling over broad ligand range. Molecular systems biology 7, 516 (2011).\n\n\n\n","category":"section"},{"location":"pest_algs/#options_optimizers","page":"Available and Recommended Algorithms","title":"Available and Recommended Optimization Algorithms","text":"For the calibrate and calibrate_multistart functions, PEtab.jl supports optimization algorithms from several popular optimization packages: Optim.jl, Ipopt.jl, and Fides.py. This page provides information on each package, as well as recommendations.","category":"section"},{"location":"pest_algs/#Recommended-Optimization-Algorithm","page":"Available and Recommended Algorithms","title":"Recommended Optimization Algorithm","text":"When choosing an optimization algorithm, it is important to keep the no free lunch principle in mind: while an algorithm may work well for one problem, there is no universally best method. Nevertheless, benchmark studies have identified algorithms that often perform well for ODE models in biology (and likely beyond) [2, 3, 5]. In particular, the best algorithm to use depends on the size of the parameter estimation problem. This is because the problem considered here is a non-linear continuous optimization problem, and for such problems, having access to a good Hessian approximation improves performance. And, the problem size dictates which type of Hessian approximation can be computed (see this page for more details). Following this, we recommend:\n\nFor small models (fewer than 10 ODEs and fewer than 20 parameters to estimate) where computing the Hessian is often computationally feasible, the IPNewton() method from Optim.jl.\nFor medium sized models (roughly more than 10 ODEs and fewer than 75 parameters), where a Gauss-Newton Hessian can be computed, Fides. The Gauss-Newton Hessian approximation typically outperforms the more common (L)-BFGS approximation, and benchmarks have shown that Fides performs well with such a Hessian approximation [1]. If Fides is difficult to install, Optim.BFGS also performs well.\nFor large models (more than 20 ODEs and more than 75 parameters to estimate), where a Gauss-Newton approximation is too computationally expensive, a (L)-BFGS optimizer is recommended, such as Ipopt or Optim.BFGS.","category":"section"},{"location":"pest_algs/#Optim_alg","page":"Available and Recommended Algorithms","title":"Optim.jl","text":"PEtab.jl supports three optimization algorithms from Optim.jl: LBFGS, BFGS, and IPNewton (Interior-point Newton). Options for these algorithms can be specified via Optim.Options(), and a complete list of options can be found here. For example, to use LBFGS with 10,000 iterations, do:\n\nusing Optim\nres = calibrate(petab_prob, x0, Optim.LBFGS();\n                options=Optim.Options(iterations = 10000))\n\nIf no options are provided, the default ones are used:\n\nOptim.Options(iterations = 1000,\n              show_trace = false,\n              allow_f_increases = true,\n              successive_f_tol = 3,\n              f_tol = 1e-8,\n              g_tol = 1e-6,\n              x_tol = 0.0)\n\nFor more details on each algorithm and tunable options, see the Optim.jl documentation.","category":"section"},{"location":"pest_algs/#Ipopt","page":"Available and Recommended Algorithms","title":"Ipopt","text":"Ipopt is an Interior-point Newton method for nonlinear optimization [10]. In PEtab.jl, Ipopt can be configured to either use the Hessian from the PEtabODEProblem or a LBFGS Hessian approximation through the IpoptOptimizer:\n\nIpopt offers a wide range of options (perhaps too many, in the words of the authors). A subset of these options can be specified using IpoptOptions:\n\nFor example, to use Ipopt with 10,000 iterations and the LBFGS Hessian approximation, do:\n\nusing Ipopt\nres = calibrate(petab_prob, x0, IpoptOptimizer(true); \n                options=IpoptOptions(max_iter = 10000))\n\nFor more information on Ipopt and its available options, see the Ipopt documentation and the original publication [10].\n\nnote: Note\nTo use Ipopt, the Ipopt.jl package must be loaded with using Ipopt before running parameter estimation.","category":"section"},{"location":"pest_algs/#Fides","page":"Available and Recommended Algorithms","title":"Fides","text":"Fides.py is a trust-region Newton method designed for box-constrained optimization problems [1]. It is particularly efficient when the Hessian is approximated using the Gauss-Newton method.\n\nThe only drawback with Fides is that it is a Python package, but fortunately, it can be used from PEtab.jl through PyCall. To this end, you must build PyCall with a Python environment that has Fides installed:\n\nusing PyCall\n# Path to Python executable with Fides installed\npath_python_exe = \"path_python\"\nENV[\"PYTHON\"] = path_python_exe\n# Build PyCall with the Fides Python environment\nimport Pkg\nPkg.build(\"PyCall\")\n\nFides supports several Hessian approximations, which can be specified in the Fides constructor:\n\nA notable feature of Fides is that in each optimization step, the objective, gradient, and Hessian are computed simultaneously. This opens up the possibility for efficient reuse of computed quantities, especially when the Hessian is computed via the Gauss-Newton approximation. Because, to compute the Gauss-Newton Hessian the forward sensitivities are used, which can also be used to compute the gradient. Hence, a good PEtabODEProblem configuration for Fides with Gauss-Newton is:\n\npetab_prob = PEtabODEProblem(model; gradient_method = :ForwardEquations, \n                             hessian_method = :GaussNewton,\n                             reuse_sensitivities = true)\n\nGiven this setup, the Hessian method from the PEtabODEProblem can be used to run Fides for 200 iterations with:\n\nusing PyCall\nres = calibrate(petab_prob, x0, Fides(nothing);\n                options=py\"{'maxiter' : 1000}\")\n\nAs noted above, for Fides options are specified using a Python dictionary. Available options and their default values can be found in the Fides documentation, and more information on the algorithm can be found in the original publication [1].","category":"section"},{"location":"pest_algs/#References","page":"Available and Recommended Algorithms","title":"References","text":"F. Fröhlich and P. K. Sorger. Fides: Reliable trust-region optimization for parameter estimation of ordinary differential equation models. PLoS computational biology 18, e1010322 (2022).\n\n\n\nA. Raue, M. Schilling, J. Bachmann, A. Matteson, M. Schelke, D. Kaschek, S. Hug, C. Kreutz, B. D. Harms, F. J. Theis and others. Lessons learned from quantitative dynamical modeling in systems biology. PloS one 8, e74335 (2013).\n\n\n\nH. Hass, C. Loos, E. Raimundez-Alvarez, J. Timmer, J. Hasenauer and C. Kreutz. Benchmark problems for dynamic modeling of intracellular processes. Bioinformatics 35, 3073–3082 (2019).\n\n\n\nA. F. Villaverde, F. Fröhlich, D. Weindl, J. Hasenauer and J. R. Banga. Benchmarking optimization methods for parameter estimation in large kinetic models. Bioinformatics 35, 830–838 (2019).\n\n\n\nA. Wächter and L. T. Biegler. On the implementation of an interior-point filter line-search algorithm for large-scale nonlinear programming. Mathematical programming 106, 25–57 (2006).\n\n\n\n","category":"section"},{"location":"pest_algs/#PEtab.IpoptOptimizer-pest_algs","page":"Available and Recommended Algorithms","title":"PEtab.IpoptOptimizer","text":"IpoptOptimizer(LBFGS::Bool)\n\nSetup the Ipopt Interior-point Newton method optmizer for parameter estimation.\n\nIpopt can be configured to use either the Hessian method from the PEtabODEProblem (LBFGS=false) or an LBFGS scheme (LBFGS=true). For setting other Ipopt options, see IpoptOptions.\n\nSee also calibrate and calibrate_multistart.\n\nDescription\n\nIpopt is an Interior-point Newton method for constrained non-linear optimization problems. More information on the algorithm can be found in [1].\n\nWächter and Biegler, Mathematical programming, pp 25-57 (2006)\n\n\n\n\n\n","category":"type"},{"location":"pest_algs/#PEtab.IpoptOptions-pest_algs","page":"Available and Recommended Algorithms","title":"PEtab.IpoptOptions","text":"IpoptOptions(; kwargs...)\n\nOptions for parameter estimation with IpoptOptimizer.\n\nMore details on the options can be found in the Ipopt documentation.\n\nSee also IpoptOptimizer, calibrate, and calibrate_multistart.\n\nKeyword Arguments\n\nprint_level = 0: Output verbosity level (valid values are 0 ≤ print_level ≤ 12)\nmax_iter = 1000: Maximum number of iterations\ntol = 1e-8: Relative convergence tolerance\nacceptable_tol = 1e-6: Acceptable relative convergence tolerance\nmax_wall_time 1e20: Maximum wall time optimization is allowed to run\nacceptable_obj_change_tol 1e20: Acceptance stopping criterion based on objective   function change.\n\n\n\n\n\n","category":"type"},{"location":"pest_algs/#PEtab.Fides-pest_algs","page":"Available and Recommended Algorithms","title":"PEtab.Fides","text":"Fides(hessian_method; verbose::Bool=false)\n\nSetup the Fides box-constrained Newton-trust region optimizer for parameter estimation.\n\nSee also calibrate and calibrate_multistart.\n\nArguments\n\nhessian_method: Method for computing the Hessian. Allowed options are:\nnothing: The Hessian computed by the PEtabODEProblem is used.\n:BB: Broyden's \"bad\" method.\n:BFGS: Broyden-Fletcher-Goldfarb-Shanno update strategy.\n:BG: Broyden's \"good\" method.\n:Broyden: Broyden-class update scheme.\n:SR1: Symmetric Rank 1 update.\n:SSM: Structured Secant Method.\n:TSSM: Totally Structured Secant Method.\nverbose: Whether to print progress during the parameter estimation.\n\nDescription\n\nFides is a Newton-trust region optimizer for box-constrained optmization problems. More information on the algorithm can be found in [1]. Fides particularly excels when the full Hessian is too computationally expensive to compute, but a Gauss-Newton Hessian approximation can be computed (for more details see the documentation). In addition to supporting user Hessians via the PEtabODEProblem, it supports several Hessian approximation methods. Aa more extensive description than above see the Fides documentation.\n\nFröhlich and Sorger, PLoS computational biology, pp e1010322 (2022)\n\n\n\n\n\n","category":"type"},{"location":"default_options/#default_options","page":"Default Options","title":"Default Options","text":"PEtab.jl supports several gradient and Hessian computation methods, as well as the ODE solvers available in OrdinaryDiffEq.jl. As a result, there are many possible choices when creating a PEtabODEProblem. To simplify usage, PEtab.jl has benchmark derived heuristics to select appropriate default options based on the size of the parameter estimation problem. This page discusses these default options when creating a PEtabODEProblem.\n\nThe default options are based on model size, which is determined by the number of ODEs and the number of parameters to estimate. This is because there is typically no \"one-size-fits-all\" solution: ODE solvers that perform well for small models may not perform well for large models, and gradient methods that are effective for small models may not be suitable for larger ones. It should also be noted that the defaults are based on benchmarks for stiff biological models. For information on how to configure the PEtabODEProblem for models outside of biology, see this page.\n\nnote: Note\nThese defaults often work well, but they may not be optimal for every model as each problem is unique.","category":"section"},{"location":"default_options/#Small-Models-(\\leq-20-Parameters-and-\\leq-15-ODEs)","page":"Default Options","title":"Small Models (leq 20 Parameters and leq 15 ODEs)","text":"ODE solver: For small stiff models, the Rosenbrock Rodas5P() solver is typically the fastest and most accurate. While Julia's BDF solvers like QNDF() can perform well, they tend to be less reliable and accurate compared to Rodas5P() in this regime.\n\nGradient method: For small models, forward-mode automatic differentiation via ForwardDiff.jl is usually the fastest method, often being twice as fast as the forward-sensitivity equations approach. For :ForwardDiff, it is possible to set the chunk size, which can improve performance. However, determining the optimal value can be challenging, and thus we plan to add automatic tuning.\n\nHessian method: For small models, computing the full Hessian via ForwardDiff.jl is often computationally feasible. Benchmarks have shown that using the full Hessian improves convergence.\n\nOverall, for small models, the default configuration is:\n\npetab_prob = PEtabODEProblem(model; odesolver=ODESolver(Rodas5P()),\n                             gradient_method=:ForwardDiff, \n                             hessian_method=:ForwardDiff)\n\nnote: Note\nIf a model has many condition-specific parameters that only appear in a subset of simulation conditions (see this tutorial), runtime can be improved by setting split_over_conditions=true in the PEtabODEProblem. For more details, see [this] example.","category":"section"},{"location":"default_options/#Medium-Sized-Models-(\\leq-75-Parameters-and-\\leq-75-ODEs)","page":"Default Options","title":"Medium-Sized Models (leq 75 Parameters and leq 75 ODEs)","text":"ODE solver: For medium-sized stiff models, multi-step BDF solvers like QNDF() are generally fast and accurate [23]. However, they can fail for models with many events when using low tolerances. In such cases, KenCarp4() is a reliable alternative.\n\nGradient method: As with small models, the most efficient gradient method for medium-sized models is forward-mode automatic differentiation via ForwardDiff.jl.\n\nHessian method: For medium-sized models, computing the full Hessian via ForwardDiff.jl is often computationally infeasible. Instead, we recommend the Gauss-Newton Hessian approximation, which in behcmarks frequently outperforms the commonly used (L)-BFGS approximation [1].\n\nOverall, for medium models, the default configuration is:\n\npetab_prob = PEtabODEProblem(model; odesolver=ODESolver(QNDF(), abstol=1e-8, reltol=1e-8),\n                             gradient_method=:ForwardDiff, \n                             hessian_method=:GaussNewton)\n\nnote: Note\nIf an optimization algorithm computes both the gradient and Hessian simultaneously, and the Hessian is computed using the Gauss-Newton approximation, it is possible to reuse quantities from gradient computations by setting gradient_method = :ForwardEquations and reuse_sensitivities = true. For more information, see this page on the Fides optimizer.","category":"section"},{"location":"default_options/#Large-Models-(\\geq-75-Parameters-and-\\geq-75-ODEs)","page":"Default Options","title":"Large Models (geq 75 Parameters and geq 75 ODEs)","text":"While PEtab.jl provides default settings for large models, we recommend benchmarking different methods. This is because selecting the best ODE solver and gradient configuration can substantially impact runtime.\n\nODE solver: For efficiently simulating large models, we recommend benchmarking various ODE solvers designed for large problems, such as QNDF(), FBDF(), KenCarp4(), and CVODE_BDF(). Further, we recommend trying a sparse Jacobian (sparse_jacobian = true) and testing different linear solvers, such as CVODE_BDF(linsolve=:KLU). For more information on solving large stiff models in Julia, see this tutorial.\n\nGradient method: For large models, the most efficient gradient method is adjoint sensitivity analysis (gradient_method=:Adjoint). PEtab.jl supports the InterpolatingAdjoint(), GaussAdjoint(), and QuadratureAdjoint() algorithms from SciMLSensitivity.jl. The default is InterpolatingAdjoint(autojacvec = EnzymeVJP()), but we strongly recommend benchmarking different adjoint methods and different autojacvec options. For further details on adjoint options, see the SciMLSensitivity.jl documentation.\n\nHessian method: For large models, computing sensitivities (Gauss-Newton) or a full Hessian is not computationally feasible. Therefore, using an L-(BFGS) approximation is often the best option. BFGS support is built into most available optimizers such as Optim.jl, Ipopt.jl, and Fides.py.\n\nOverall, for large models, the default configuration is:\n\npetab_prob = PEtabODEProblem(model, odesolver=ODESolver(CVODE_BDF()),\n                             gradient_method=:Adjoint,\n                             sensealg=InterpolatingAdjoint(autojacvec=EnzymeVJP()))","category":"section"},{"location":"default_options/#References","page":"Default Options","title":"References","text":"F. Fröhlich and P. K. Sorger. Fides: Reliable trust-region optimization for parameter estimation of ordinary differential equation models. PLoS computational biology 18, e1010322 (2022).\n\n\n\nP. Städter, Y. Schälte, L. Schmiester, J. Hasenauer and P. L. Stapor. Benchmarking of numerical integration methods for ODE models of biological systems. Scientific reports 11, 2696 (2021).\n\n\n\n","category":"section"},{"location":"inference/#bayesian_inference","page":"Bayesian Inference","title":"Bayesian Inference","text":"When performing parameter estimation for a model with PEtab.jl, the unknown model parameters are estimated within a frequentist framework, where the goal is to find the maximum likelihood estimate. When prior knowledge about the parameters is available, Bayesian inference offers an alternative approach to fitting a model to data. The aim of Bayesian inference is to infer the posterior distribution of unknown parameters given the data, pi(mathbfx mid mathbfy), by running a Markov chain Monte Carlo (MCMC) algorithm to sample from the posterior. A major challenge, aside from creating a good model, is to effectively sample the posterior. PEtab.jl supports Bayesian inference via two packages that implement different sampling algorithms:\n\nAdaptive Metropolis Hastings Samplers available in AdaptiveMCMC.jl [12].\nHamiltonian Monte Carlo (HMC) Samplers available in AdvancedHMC.jl. The default HMC sampler is the NUTS sampler, which is the default in Stan [13, 14]. HMC samplers are often efficient for continuous targets (models with non-discrete parameters).\n\nThis tutorial covers how to create a PEtabODEProblem with priors and how to use AdaptiveMCMC.jl and AdvancedHMC.jl for Bayesian inference. It should be noted that this part of PEtab.jl is planned to be moved to a separate package, so the syntax will change and be made more user-friendly in the future.\n\nnote: Note\nTo use the Bayesian inference functionality in PEtab.jl, the Bijectors.jl, LogDensityProblems.jl, and LogDensityProblemsAD.jl packages must be loaded.","category":"section"},{"location":"inference/#Creating-a-Bayesian-Inference-Problem","page":"Bayesian Inference","title":"Creating a Bayesian Inference Problem","text":"If a PEtab problem is in the PEtab standard format, priors are defined in the parameter table. Here, we focus on the case when the model is defined directly in Julia, using a simple saturated growth model. First, we create the model and simulate some data:\n\nusing Distributions, ModelingToolkit, OrdinaryDiffEq, Plots\nusing ModelingToolkit: t_nounits as t, D_nounits as D\n@mtkmodel SYS begin\n    @parameters begin\n        b1\n        b2\n    end\n    @variables begin\n        x(t) = 0.0\n    end\n    @equations begin\n        D(x) ~ b2 * (b1 - x)\n    end\nend\n@mtkbuild sys = SYS()\n\n# Simulate data with normal measurement noise and σ = 0.03\nimport Random # hide\nRandom.seed!(1234) # hide\noprob = ODEProblem(sys, [0.0], (0.0, 2.5), [1.0, 0.2])\ntsave = range(0.0, 2.5, 101)\ndist = Normal(0.0, 0.03)\nsol = solve(oprob, Rodas4(), abstol=1e-12, reltol=1e-12, saveat=tsave)\nobs = sol[:x] .+ rand(Normal(0.0, 0.03), length(tsave))\ndefault(left_margin=12.5Plots.Measures.mm, bottom_margin=12.5Plots.Measures.mm, size = (600*1.25, 400 * 1.25), palette = [\"#CC79A7\", \"#009E73\", \"#0072B2\", \"#D55E00\", \"#999999\", \"#E69F00\", \"#56B4E9\", \"#F0E442\"], linewidth=2.0) # hide\nplot(sol.t, obs, seriestype=:scatter, title = \"Observed data\")\n\nGiven this, we can now create a PEtabODEProblem (for an introduction, see the starting tutorial):\n\nusing DataFrames, PEtab\nmeasurements = DataFrame(obs_id=\"obs_X\", time=sol.t, measurement=obs)\n@parameters sigma\nobs_X = PEtabObservable(:x, sigma)\nobservables = Dict(\"obs_X\" => obs_X)\nnothing # hide\n\nWhen defining parameters to estimate via PEtabParameter, a prior can be assigned using any continuous distribution available in Distributions.jl. For instance, we can set the following priors:\n\nb_1: Uniform distribution between 0.0 and 5.0; Uniform(0.0, 5.0).\nlog10_b2: Uniform distribution between -6.0 and log10(5.0); Uniform(-6.0, log10(5.0)).\nsigma: Gamma distribution with shape and rate parameters both set to 1.0, Gamma(1.0, 1.0).\n\nUsing the following code:\n\np_b1 = PEtabParameter(:b1, value=1.0, lb=0.0, ub=5.0, scale=:log10, prior_on_linear_scale=true, prior=Uniform(0.0, 5.0))\np_b2 = PEtabParameter(:b2, value=0.2, scale=:log10, prior_on_linear_scale=false, prior=Uniform(-6, log10(5.0)))\np_sigma = PEtabParameter(:sigma, value=0.03, lb=1e-3, ub=1e2, scale=:lin, prior_on_linear_scale=true, prior=Gamma(1.0, 1.0))\npest = [p_b1, p_b2, p_sigma]\n\nWhen specifying priors, it is important to keep in mind the parameter scale (where log10 is the default). In particular, when prior_on_linear_scale=false, the prior applies to the parameter scale, so for b2 above, the prior is on the log10 scale. If prior_on_linear_scale=true (the default), the prior is on the linear scale, which applies to b1 and sigma above. If a prior is not specified, the default prior is a Uniform distribution on the parameter scale, with bounds corresponding to the upper and lower bounds specified for the PEtabParameter. With these priors, we can now create the PEtabODEProblem.\n\nosolver = ODESolver(Rodas5P(), abstol=1e-6, reltol=1e-6)\nmodel = PEtabModel(sys, observables, measurements, pest)\npetab_prob = PEtabODEProblem(model; odesolver=osolver)","category":"section"},{"location":"inference/#Bayesian-Inference-(General-Setup)","page":"Bayesian Inference","title":"Bayesian Inference (General Setup)","text":"The first step in in order to run Bayesian inference is to construct a PEtabLogDensity. This structure supports the LogDensityProblems.jl interface, meaning it contains all the necessary methods for running Bayesian inference:\n\nusing Bijectors, LogDensityProblems, LogDensityProblemsAD\ntarget = PEtabLogDensity(petab_prob)\n\nWhen performing Bayesian inference, the settings for the ODE solver and gradient computations are those specified in petab_prob. In this case, we use the default gradient method (ForwardDiff) and simulate the ODE model using the Rodas5P ODE solver.\n\nOne important consideration before running Bayesian inference is the starting point. For simplicity, we here use the parameter vector that was used for simulating the data, but note that typically inference should be performed using at least four chains from different starting points [15]:\n\nx = get_x(petab_prob)\nnothing # hide\n\nLastly, when performing Bayesian inference with PEtab.jl, it is important to note that inference is performed on the prior scale. For instance, if a parameter has scale=:log10, but the prior is defined on the linear scale (prior_on_linear_scale=true), inference is performed on the linear scale. Additionally, Bayesian inference algorithms typically prefer to operate in an unconstrained space, so a bounded prior like Uniform(0.0, 5.0) is not ideal. To address this, bounded parameters are transformed to be unconstrained.\n\nIn summary, for a parameter vector on the PEtab parameter scale (x), for inference we must transform to the prior scale (xprior), and then to the inference scale (xinference). This can be done via:\n\nxprior = to_prior_scale(petab_prob.xnominal_transformed, target)\nxinference = target.inference_info.bijectors(xprior)\n\nwarn: Warn\nTo get correct inference results, it is important that the starting value is on the transformed parameter scale (as xinference above).","category":"section"},{"location":"inference/#Bayesian-inference-with-AdvancedHMC.jl-(NUTS)","page":"Bayesian Inference","title":"Bayesian inference with AdvancedHMC.jl (NUTS)","text":"Given a starting point we can run the NUTS sampler with 2000 samples, and 1000 adaptation steps:\n\nusing AdvancedHMC\n# δ=0.8 - acceptance rate (default in Stan)\nsampler = NUTS(0.8)\nRandom.seed!(1234) # hide\nres = sample(target, sampler, 2000; n_adapts = 1000, initial_params = xinference, \n             drop_warmup=true, progress=false)\nnothing #hide\n\nAny other algorithm found in AdvancedHMC.jl documentation can also be used. To get the output in an easy to interact with format, we can convert it to a MCMCChains\n\nusing MCMCChains\nchain_hmc = PEtab.to_chains(res, target)\n\nwhich we can also plot:\n\nusing Plots, StatsPlots\nplot(chain_hmc)\n\nnote: Note\nWhen converting the output to a MCMCChains the parameters are transformed to the prior-scale (inference scale).","category":"section"},{"location":"inference/#Bayesian-inference-with-AdaptiveMCMC.jl","page":"Bayesian Inference","title":"Bayesian inference with AdaptiveMCMC.jl","text":"Given a starting point we can run the robust adaptive MCMC sampler for 100  000 iterations with:\n\nusing AdaptiveMCMC\nRandom.seed!(123) # hide\n# target.logtarget = posterior logdensity\nres = adaptive_rwm(xinference, target.logtarget, 100000; progress=false)\nnothing #hide\n\nand we can convert the output to a MCMCChains\n\nchain_adapt = to_chains(res, target)\nplot(chain_adapt)\n\nAny other algorithm found in AdaptiveMCMC.jl documentation can also be used.","category":"section"},{"location":"inference/#References","page":"Bayesian Inference","title":"References","text":"M. Vihola. Ergonomic and reliable Bayesian inference with adaptive Markov chain Monte Carlo. Wiley statsRef: statistics reference online, 1–12 (2014).\n\n\n\nM. D. Hoffman, A. Gelman and others. The No-U-Turn sampler: adaptively setting path lengths in Hamiltonian Monte Carlo. J. Mach. Learn. Res. 15, 1593–1623 (2014).\n\n\n\nB. Carpenter, A. Gelman, M. D. Hoffman, D. Lee, B. Goodrich, M. Betancourt, M. A. Brubaker, J. Guo, P. Li and A. Riddell. Stan: A probabilistic programming language. Journal of statistical software 76 (2017).\n\n\n\nA. Gelman, A. Vehtari, D. Simpson, C. C. Margossian, B. Carpenter, Y. Yao, L. Kennedy, J. Gabry, P.-C. Bürkner and M. Modrák. Bayesian workflow, arXiv preprint arXiv:2011.01808 (2020).\n\n\n\n","category":"section"},{"location":"petab_event/#define_events","page":"Events (callbacks, dosages, etc.)","title":"Events (callbacks, dosages, etc.)","text":"To account for experimental interventions, such as the addition of a substrate, changes in experimental conditions (e.g., temperature), or automatic dosages, events (often called callbacks, dosages, etc.) can be used. When creating a PEtabModel in Julia, events should be encoded as a PEtabEvent:\n\nThis tutorial covers how to specify two types of events: those triggered at specific time points and those triggered by a species (e.g., when a specie exceeds a certain concentration). As a working example, we use the Michaelis-Menten enzyme kinetics model from the starting tutorial. Even though the code below provides the model as a ReactionSystem, everything works exactly the same if the model is provided as an ODESystem.\n\nusing Catalyst, DataFrames, PEtab\n\nrn = @reaction_network begin\n    @parameters S0 c3=1.0\n    @species S(t)=S0\n    c1, S + E --> SE\n    c2, SE --> S + E\n    c3, SE --> P + E\nend\nspeciemap = [:E => 2.0, :SE => 0.0, :P => 0.0]\n\n@unpack E, S, P = rn\n@parameters sigma\nobs_sum = PEtabObservable(S + E, 3.0)\nobs_p = PEtabObservable(P, sigma)\nobservables = Dict(\"obs_p\" => obs_p, \"obs_sum\" => obs_sum)\n\n# Set values for better plots\np_c1 = PEtabParameter(:c1; value = 1.0)\np_c2 = PEtabParameter(:c2; value = 2.0)\np_s0 = PEtabParameter(:S0; value = 5.0)\np_sigma = PEtabParameter(:sigma)\npest = [p_c1, p_c2, p_s0, p_sigma]\n\n# Smaller dataset compared to starting tutorial\nmeasurements = DataFrame(obs_id=[\"obs_p\", \"obs_sum\", \"obs_p\", \"obs_sum\"],\n                         time=[1.0, 10.0, 1.0, 20.0],\n                         measurement=[0.7, 0.1, 1.0, 1.5])\nusing Plots # hide\ndefault(left_margin=12.5Plots.Measures.mm, bottom_margin=12.5Plots.Measures.mm, size = (600*1.25, 400 * 1.25), palette = [\"#CC79A7\", \"#009E73\", \"#0072B2\", \"#D55E00\", \"#999999\", \"#E69F00\", \"#56B4E9\", \"#F0E442\"], linewidth=4.0) # hide\nnothing # hide\n\nnote: Note\nEvents/callbacks can be directly encoded in a Catalyst ReactionNetwork or a ModelingToolkit ODESystem model. However, we strongly recommend using PEtabEvent for optimal performance, and to ensure the correct evaluation of the objective function and especially its derivative [6].","category":"section"},{"location":"petab_event/#Time-Triggered-Events","page":"Events (callbacks, dosages, etc.)","title":"Time-Triggered Events","text":"Time-triggered events are activated at specific time points. The trigger value can be either a constant value (e.g., t == 2.0) or a model parameter (e.g., t == c2). For example, to trigger an event at t = 2, where species S is updated as S <- S + 2, do:\n\nt = default_t()\n@unpack S = rn\nevent = PEtabEvent(t == 2.0, S + 2, S)\n\nThen, to ensure the event is included when building the PEtabModel, include the event under the events keyword:\n\nmodel = PEtabModel(rn, observables, measurements, pest; events=event, speciemap = speciemap)\npetab_prob = PEtabODEProblem(model)\nnothing # hide\n\nFrom solving the dynamic ODE model, it is clear that at t == 2, S is incremented by 2:\n\nusing Plots\nx = get_x(petab_prob)\nsol = get_odesol(x, petab_prob)\nplot(sol; linewidth = 2.0)\n\nThe trigger time can also be a model parameter, where the parameter is allowed to be estimated. For instance, to trigger the event when t == c2 and assign c1 as c1 <- 2.0, do:\n\n@unpack c2 = rn\nevent = PEtabEvent(t == c2, 5.0, :c1)\n\nFrom plotting the solution, it is clear that a change in dynamics occurs at t == c2:\n\nmodel = PEtabModel(rn, observables, measurements, pest; events=event, speciemap = speciemap)\npetab_prob = PEtabODEProblem(model)\nsol = get_odesol(x, petab_prob)\nplot(sol; linewidth = 2.0)\n\nnote: Note\nIf the condition and target are single parameters or species, they can be specified as Num (from @unpack) or a Symbol (:c1 above). If the event involves multiple parameters or species, they must be provided as a Num equation (see below).","category":"section"},{"location":"petab_event/#Specie-Triggered-Events","page":"Events (callbacks, dosages, etc.)","title":"Specie-Triggered Events","text":"Specie-triggered events are activated when a species-dependent Boolean condition transitions from false to true. For example, suppose we have a dosage machine that triggers when the substrate S drops below the threshold value of 2.0, and at that point, the machine updates S as S <- S + 1. This can be encoded as:\n\n@unpack S = rn\nevent = PEtabEvent(S == 0.2, 1.0, S)\n\nPlotting the solution, we can clearly see how S is incremented every time it reaches 0.2:\n\nmodel = PEtabModel(rn, observables, measurements, pest; events=event, speciemap = speciemap)\npetab_prob = PEtabODEProblem(model)\nsol = get_odesol(x, petab_prob)\nplot(sol; linewidth = 2.0)\n\nWith species-triggered events, the direction can matter. For instance, with S == 0.2, the event is triggered when S approaches 0.2 from either above or below. To activate the event only when S drops below 0.2, write:\n\nevent = PEtabEvent(S < 0.2, 1.0, S)\nmodel = PEtabModel(rn, observables, measurements, pest; events=event, speciemap = speciemap)\npetab_prob = PEtabODEProblem(model)\nsol = get_odesol(x, petab_prob)\nplot(sol; linewidth = 2.0)\n\nBecause events only trigger when the condition (S < 0.2) transitions from false to true, this event is triggered when S approaches from above. Meanwhile, if we write S > 0.2, the event is never triggered:\n\nevent = PEtabEvent(S > 0.2, 1.0, S)\nmodel = PEtabModel(rn, observables, measurements, pest; events=event, speciemap = speciemap)\npetab_prob = PEtabODEProblem(model)\nsol = get_odesol(x, petab_prob)\nplot(sol; linewidth = 2.0)","category":"section"},{"location":"petab_event/#Multiple-Event-Targets","page":"Events (callbacks, dosages, etc.)","title":"Multiple Event Targets","text":"Sometimes an event can affect multiple species and/or parameters. In this case, both affect and target should be provided as vectors. For example, suppose an event is triggered when the substrate fulfillsS < 0.2, where S is updated as S <- S + 2 and c1 is updated as c1 <- 2.0. This can be encoded as:\n\nevent = PEtabEvent(S < 0.2, [S + 2, 2.0], [S, :c1])\n\nThe event is provided as usual to the PEtabModel:\n\nmodel = PEtabModel(rn, observables, measurements, pest; events=event, speciemap = speciemap)\npetab_prob = PEtabODEProblem(model)\nsol = get_odesol(x, petab_prob)\nplot(sol; linewidth = 2.0)\n\nWhen there are multiple targets, the length of the affect vector must match the length of the target vector.","category":"section"},{"location":"petab_event/#Multiple-Events","page":"Events (callbacks, dosages, etc.)","title":"Multiple Events","text":"Sometimes a model can have multiple events, which then should be provided as Vector of PEtabEvent. For example, suppose event1 is triggered when the substrate fulfills S < 0.2, where S is updated as S <- S + 2, and event2 is triggered when t == 1.0, where c1 is updated as c1 <- 2.0. This can be encoded as:\n\n@unpack S, c1 = rn\nevent1 = PEtabEvent(S < 0.2, 1.0, S)\nevent2 = PEtabEvent(1.0, 2.0, :c1)\nevents = [event1, event2]\n\nThese events are then provided as usual to the PEtabModel:\n\nmodel = PEtabModel(rn, observables, measurements, pest; events=event, speciemap = speciemap)\npetab_prob = PEtabODEProblem(model)\nsol = get_odesol(x, petab_prob)\nplot(sol; linewidth = 2.0)\n\nIn this example, two events are provided, but with your imagination as the limit, any number of events can be provided.","category":"section"},{"location":"petab_event/#Modifying-Event-Parameters-for-Different-Simulation-Conditions","page":"Events (callbacks, dosages, etc.)","title":"Modifying Event Parameters for Different Simulation Conditions","text":"The trigger time (condition) and/or affect can be made specific to different simulation conditions by introducing control parameters (here c_time and c_value) and setting their values accordingly in the simulation conditions:\n\nrn = @reaction_network begin\n    @parameters c3=1.0 S0 c_time c_value\n    @species S(t) = S0\n    c1, S + E --> SE\n    c2, SE --> S + E\n    c3, SE --> P + E\nend\n\ncond1 = Dict(:S => 5.0, :c_time => 1.0, :c_value => 2.0)\ncond2 = Dict(:S => 2.0, :c_time => 4.0, :c_value => 3.0)\nconds = Dict(\"cond1\" => cond1, \"cond2\" => cond2)\n\nmeasurements = DataFrame(simulation_id=[\"cond1\", \"cond1\", \"cond2\", \"cond2\"],\n                         obs_id=[\"obs_P\", \"obs_Sum\", \"obs_P\", \"obs_Sum\"],\n                         time=[1.0, 10.0, 1.0, 20.0],\n                         measurement=[0.7, 0.1, 1.0, 1.5])\nnothing # hide\n\nIn this setup, when the event is defined as:\n\nevent = PEtabEvent(:c_time, :c_value, :c1)\n\nthe c_time parameter controls when the event is triggered, so for condition c0, the event is triggered at t=1.0, while for condition c1, it is triggered at t=4.0. Additionally, for conditions cond1 and cond2, the parameter c1 takes on the corresponding c_value values, which is 2.0 and 3.0, respectively, which can clearly be seen when plotting the solution for cond1\n\nmodel = PEtabModel(rn, observables, measurements, pest; events=event, speciemap = speciemap,\n                   simulation_conditions = conds)\npetab_prob = PEtabODEProblem(model)\nsol_cond1 = get_odesol(x, petab_prob; cid=:cond1)\nplot(sol_cond1; linewidth = 2.0)\n\nand cond2\n\nsol = get_odesol(x, petab_prob; cid=:cond2)\nplot(sol; linewidth = 2.0)","category":"section"},{"location":"petab_event/#References","page":"Events (callbacks, dosages, etc.)","title":"References","text":"F. Fröhlich, F. J. Theis, J. O. Rädler and J. Hasenauer. Parameter estimation for dynamical systems with discrete events and logical operations. Bioinformatics 33, 1049–1056 (2017).\n\n\n\n","category":"section"},{"location":"petab_event/#PEtab.PEtabEvent-petab_event","page":"Events (callbacks, dosages, etc.)","title":"PEtab.PEtabEvent","text":"PEtabEvent(condition, affects, targets)\n\nA model event triggered by condition that sets the value of targets to that of affects.\n\nFor a collection of examples with corresponding plots, see the documentation.\n\nArguments\n\ncondition: A Boolean expression that triggers the event when it transitions from   false to true. For example, if t == c1, the event is triggered when the model   time t equals c1. For S > 2.0, the event triggers when specie S passes 2.0   from below.\naffects: An equation of of model species and parameters that describes the effect of   the event. It can be a single expression or a vector if there are multiple targets.\ntargets: Model species or parameters that the event acts on. Must match the dimension   of affects.\n\n\n\n\n\n","category":"type"},{"location":"Beer/#Beer_tut","page":"Condition-Specific Parameters","title":"Condition-Specific Parameters","text":"As discussed in this extended tutorial, sometimes a subset of the model parameters to estimate have different values across experimental/simulation conditions. For such models, runtime can drastically improve by setting split_over_conditions=true when creating a PEtabODEProblem. This example explores this option in more detail, and it assumes that that you are familiar with condition-specific parameters in PEtab (see this tutorial) and with the gradient methods in PEtab.jl (see this page).\n\nAs a working example, we use a published signaling model referred to as the Beer model after the first author [24]. The Beer model is available in the PEtab standard format (a tutorial on importing problems in the standard format can be found here), and the PEtab files for this model can be downloaded from here. Given the problem YAML file, we can import the problem as:\n\nusing PEtab\npath_yaml = joinpath(@__DIR__, \"assets\", \"beer\", \"Beer_MolBioSystems2014.yaml\")\nmodel = PEtabModel(path_yaml)\nnothing # hide","category":"section"},{"location":"Beer/#Efficient-Handling-of-Condition-Specific-Parameters","page":"Condition-Specific Parameters","title":"Efficient Handling of Condition-Specific Parameters","text":"The Beer problem is a small model with 4 species and 9 parameters in the ODE system, but there are 72 parameters to estimate. This is because most parameters are specific to a subset of simulation conditions. For example, cond1 has a parameter τ_cond1, and cond2 has τ_cond2, which map to the ODE model parameter τ, respectively. This can be seen by printing some model statistics:\n\nusing Catalyst\npetab_prob = PEtabODEProblem(model)\nprintln(\"Number of ODE model species = \", length(unknowns(model.sys)))\nprintln(\"Number of ODE model parameters = \", length(parameters(model.sys)))\nprintln(\"Number of parameters to estimate = \", length(petab_prob.xnames))\n\nFor small ODE models like the Beer model, the most efficient gradient method is gradient_method=:ForwardDiff, and it is often feasible to compute the Hessian using hessian_method=:ForwardDiff as well (see this page for details). Typically, with :ForwardDiff, PEtab.jl computes the gradient with a single call to ForwardDiff.gradient. However, for the Beer model, this approach is problematic because for each simulation condition, n forward passes are required to compute all derivatives, where n depends on the number of gradient parameters. Since many parameters only belong to a subset of conditions, actually only ni < n forward passes are needed for each condition. To this end, PEtab.jl provides the split_over_conditions=true keyword when building the PEtabODEProblem, which ensures that one ForwardDiff.gradient call is performed per simulation condition. Let us examine how this affects gradient runtime for the Beer model:\n\nusing Printf\npetab_prob1 = PEtabODEProblem(model; split_over_conditions = true)\npetab_prob2 = PEtabODEProblem(model; split_over_conditions = false)\nx = get_x(petab_prob1)\ng1, g2 = similar(x), similar(x)\npetab_prob1.grad!(g1, x) # hide\npetab_prob2.grad!(g2, x) # hide\nb1 = @elapsed petab_prob1.grad!(g1, x)\nb2 = @elapsed petab_prob2.grad!(g2, x)\n@printf(\"Runtime split_over_conditions = true: %.2fs\\n\", b1)\n@printf(\"Runtime split_over_conditions = false: %.2fs\\n\", b2)\n\nFor the Hessian, the difference in runtime is even larger:\n\nh1, h2 = zeros(length(x), length(x)), zeros(length(x), length(x))\n_ = petab_prob1.nllh(x) # hide\n_ = petab_prob2.nllh(x) # hide\npetab_prob1.hess!(h1, x) # hide\npetab_prob2.hess!(h2, x) # hide\nb1 = @elapsed petab_prob1.hess!(h1, x)\nb2 = @elapsed petab_prob2.hess!(h2, x)\n@printf(\"Runtime split_over_conditions = true: %.1fs\\n\", b1)\n@printf(\"Runtime split_over_conditions = false: %.1fs\\n\", b2)\n\nGiven that split_over_conditions=true reduces runtime in the example above, a natural question is: why is it not the default option in PEtab.jl? This is because calling ForwardDiff.gradient for each simulation condition, instead of once for all conditions, introduces an overhead. Therefore, for models with none or very few condition-specific parameters, split_over_conditions=false is faster. Determining exactly how many condition-specific parameters are needed to make true the faster option is difficult. Currently, the default is to enable this option when the number of condition-specific parameters is at least twice the number of parameters to estimate in the ODE model. For the Beer model, this means split_over_conditions=true is set by default, but this is a rough heuristic. Therefore, for models like these, we recommend benchmarking the two configurations to determine which is fastest.","category":"section"},{"location":"Beer/#References","page":"Condition-Specific Parameters","title":"References","text":"R. Beer, K. Herbst, N. Ignatiadis, I. Kats, L. Adlung, H. Meyer, D. Niopek, T. Christiansen, F. Georgi, N. Kurzawa and others. Creating functional engineered variants of the single-module non-ribosomal peptide synthetase IndC by T domain exchange. Molecular BioSystems 10, 1709–1718 (2014).\n\n\n\n","category":"section"},{"location":"FAQ/#FAQ","page":"FAQ","title":"Frequently Asked Questions","text":"","category":"section"},{"location":"FAQ/#install_fail","page":"FAQ","title":"Why do I encounter installation problems?","text":"PEtab.jl is regularly tested on, and should be installable on Linux, macOS and Windows. If you encounter installation issues on these systems, we recommend checking the following two common causes:\n\nan incorrectly installed or outdated Julia version,  \noutdated package dependencies.\n\nFirst, ensure that a supported Julia version is used. PEtab.jl is tested with Julia LTS version 1.10 and the latest stable version. Using an earlier version may result in installation failures. To reliably install and manage Julia versions across operating systems, we strongly recommend using juliaup. If you are constrained to using an older Julia version, for example on an HPC cluster, and encounter problems, please file an issue on GitHub.\n\nSecond, installation failures may result from outdated versions of PEtab.jl dependencies. For example, if PEtab.jl is installed into the global Julia environment, older versions of other packages may prevent the latest version from being installed. This can cause installation failures or break tutorials and example code. To avoid this, it is recommended to install PEtab.jl in a new, isolated environment. For example, to install it in an environment named petab_project, run the following in the Julia REPL:\n\nusing Pkg\nPkg.activate(\"petab_project\")\nPkg.add(\"PEtab\")\n# Add any additional packages as needed\n\nIf you need to install PEtab.jl into an existing environment and encounter issues, updating all packages may resolve the problem:\n\nPkg.update()\n\nThis is because PEtab.jl depends on numerous packages from the actively developing Julia SciML ecosystem. New releases of these dependencies sometimes introduce breaking changes that are not always caught by test suites (e.g., see this issue). In other words, PEtab.jl is not compatible with all versions of packages like Catalyst.jl, which can cause issues if an incompatible version is already installed in the environment.\n\nLastly, if you have tried everything above and still experience installation issues, it is likely a bug in PEtab. In this case, please open an issue on GitHub.","category":"section"},{"location":"FAQ/#How-do-I-check-that-I-implemented-my-parameter-estimation-problem-correctly?","page":"FAQ","title":"How do I check that I implemented my parameter estimation problem correctly?","text":"After creating a PEtabODEProblem, it is important to check that everything works as expected. Since PEtab.jl creates parameter estimation problems, this means checking that the objective function (the problem likelihood) is computable, because if not, running parameter estimation will only return NaN or Inf.\n\nThe first step to verify that the likelihood is computable is to check if the objective function can be computed for the nominal parameters:\n\nx = get_x(petab_prob)\npetab_prob.nllh(x)\n\nThe nominal values can be specified when creating a PEtabParameter or in the parameters table if the problem is provided in the PEtab standard format (otherwise, they default to the mean of the parameter bounds). If the problem is correctly specified, the likelihood should be computable for these values. However, sometimes the nominal values can be poor choices (far from the 'true' parameters as we do not know them, hence the need for PEtab.jl), and the code above may return Inf because the ODE cannot be solved. If this happens, check if the likelihood can be computed for random parameters:\n\nget_startguesses(petab_prob, 10)\n\nSpecially, the get_startguesses function tries to find random parameter vectors for which the likelihood can be computed. If this function fails to return a parameter set, there is likely an issue with the problem formulation.\n\nIf the objective function cannot be computed, check out the tips below. If none of the suggestions help, please file an issue on GitHub.","category":"section"},{"location":"FAQ/#Why-do-I-get-NaN-or-Inf-when-computing-the-objective-function-or-during-parameter-estimation?","page":"FAQ","title":"Why do I get NaN or Inf when computing the objective function or during parameter estimation?","text":"Sometimes, when computing the likelihood (petab_prob.nllh(x)) or during parameter estimation, Inf or NaN may be returned. This can be due to several reasons.\n\nInf is returned when the ODE model cannot be solved. When this happens, a warning like Failed to solve ODE model should be printed. If no ODE solver warning is shown, check that the observable formulas and noise formulas cannot evaluate to Inf (e.g., there are no expressions that can evaluate to log(0)). If neither of these reasons causes Inf to be returned, please file an issue on GitHub. For how to deal with ODE solver warnings, see one of the questions below.\n\nIf NaN is returned, the model formulas are likely ill-formulated. In PEtab.jl, the most common cause of NaN being returned is that log is applied to a negative value, often due to an ill-formulated noise formula. For example, consider the observable h = PEtabObservable(X, sigma * X), where X is a model species and sigma is a parameter. When computing the objective value (likelihood) for this observable, the log of the noise formula sigma * X is evaluated. Even if the model uses mass-action kinetics and X should never go below zero, in practice, numerical noise during ODE solving can cause X to become negative, leading to a negative argument for log. Therefore, a more stable noise formula than the one above would be sigma1 + sigma2 * X.","category":"section"},{"location":"FAQ/#Why-do-I-get-the-error-*MethodError:-Cannot-convert-an-object-of-type-Nothing-to-an-object-of-type-Real*?","page":"FAQ","title":"Why do I get the error MethodError: Cannot convert an object of type Nothing to an object of type Real?","text":"This error likely occurs because some model parameters have not been defined. For example, consider the observable h = PEtabObservable(X, sigma), where X is a model species and sigma is a parameter. If sigma has not been defined as a PEtabParameter, the above error will be thrown when computing the objective function. This also applies to misspellings. For example, if the observable is defined as h = PEtabObservable(X, sigma1) but only sigma (not sigma1) is defined as a PEtabParameter, the same error will be thrown.","category":"section"},{"location":"FAQ/#Why-are-my-parameter-values-(e.g.,-start-guesses)-negative?","page":"FAQ","title":"Why are my parameter values (e.g., start-guesses) negative?","text":"When creating start-guesses for parameter estimation with get_x or get_startguesses, the values in the returned vector(s) can sometimes be negative. As discussed in the starting tutorial, this is because parameters are estimated on the log10 scale by default, as this often improves performance. Consequently, when setting new parameter values manually, they should be provided on the parameter scale. It is also possible to change the parameter scale; see PEtabParameter.","category":"section"},{"location":"FAQ/#I-get-ODE-solver-warnings-during-parameter-estimation,-is-my-model-wrong?","page":"FAQ","title":"I get ODE-solver warnings during parameter estimation, is my model wrong?","text":"When doing parameter estimation, it is not uncommon for the warning Failed to solve ODE model to be thrown a few times. This is because when estimating model parameters with a numerical optimization algorithm that starts from random points in parameter space (e.g., when using calibrate_multistart), poor parameter values that cause difficult dynamics to solve are sometimes generated. However, if the Failed to solve ODE model warning is thrown frequently, there is likely a problem with the model structure, or a suboptimal ODE solver is used. We recommend first checking if the issue is related to the ODE solver.\n\nA great collection of tips for dealing with different ODE solver warnings can be found here. Briefly, it can be helpful to adjust the tolerances in ODESolver, as the default settings are quite strict. Further, if maxiters warnings are thrown, increasing the number of maximum iterations might help. Lastly, it can also be worthwhile to try different ODE solvers. Even though the default solver often performs well, every problem is unique. For hard-to-solve models, it can therefore be useful to try solvers like Rodas5P, QNDF, TRBDF2, or KenCarp4.\n\nIf changing ODE solver settings does not help, something may be wrong with the model structure (e.g., the model may not be coded correctly). However, it should also be kept in mind that some models are just hard to solve/simulate. Therefore, even if many warnings are thrown, a multi-start parameter estimation approach can still sometimes find a set of parameters that fits the data well.","category":"section"},{"location":"FAQ/#How-do-I-turn-off-ODE-solver-printing?","page":"FAQ","title":"How do I turn off ODE solver printing?","text":"When performing parameter estimation, as discussed above warnings are thrown when the ODE solver fails to solve the underlying ODE model. By default, we do not disable ODE solver warnings, as it can be beneficial to see them. In particular, if warnings are thrown frequently, it may indicate that something is wrong with the model structure (e.g. the model was not coded correctly) or that a sub-optimal (e.g., non-stiff) ODE solver was chosen when a stiff one should be used. Regardless, when running parameter estimation, it might be preferable not to have the terminal cluttered with warnings. You can turn off the warnings by setting the verbose = false option in the ODESolver:\n\nosolver = ODESolver(Rodas5P(); verbose = false)\npetab_prob = PEtabODEProblem(model; odesolver = osolver)\n\nFor which ODE solver to choose when manually setting the ODESolver, see this page.","category":"section"},{"location":"FAQ/#How-do-I-create-a-parameter-estimation-problem-for-an-SBML-model?","page":"FAQ","title":"How do I create a parameter estimation problem for an SBML model?","text":"If your model is in the SBML standard format, there are two ways to create a parameter estimation problem:\n\nFormulate the problem in the PEtab standard format (recommended). PEtab is a standard format for parameter estimation that assumes the model is in the SBML format. We recommend creating problems in this format, as it allows for the exchange of parameter estimation workflows and is more reproducible. A guide on how to create problems in this standard format can be found here, and a tutorial on importing problems can be found here.\nImport the model as a Catalyst.jl ReactionSystem with SBMLImporter.jl (see the SBMLImporter documentation for details). As demonstrated in the starting tutorial, a ReactionSystem is one of the model formats that PEtab.jl accepts for creating a parameter estimation problem directly in Julia.","category":"section"},{"location":"petab_cond_specific/#define_conditions","page":"Simulation Condition-Specific Parameters","title":"Simulation Condition-Specific Parameters","text":"Sometimes, a subset of model parameters to be estimated can have different values across experimental conditions. For example, the parameter to estimate c1 might have one value for condition cond1 and a different value for condition cond2. In such cases, these condition-specific parameters need to be handled separately in the parameter estimation process.\n\nThis tutorial covers how to handle condition-specific parameters when creating a PEtabModel. It requires that you are familiar with PEtab simulation conditions, if not; see this tutorial. As a working example, we use the Michaelis-Menten enzyme kinetics model from the starting tutorial. Even though the code below encodes the model as a ReactionSystem, everything works exactly the same if the model is encoded as an ODESystem.\n\nusing Catalyst, PEtab\n\nrn = @reaction_network begin\n    @parameters S0 c3=1.0\n    @species S(t)=S0\n    c1, S + E --> SE\n    c2, SE --> S + E\n    c3, SE --> P + E\nend\nspeciemap = [:E => 50.0, :SE => 0.0, :P => 0.0]\n\n@unpack E, S, P = rn\n@parameters sigma\nobs_sum = PEtabObservable(S + E, 3.0)\nobs_p = PEtabObservable(P, sigma)\nobservables = Dict(\"obs_p\" => obs_p, \"obs_sum\" => obs_sum)\n\np_S0 = PEtabParameter(:S0)\np_c2 = PEtabParameter(:c2)\np_sigma = PEtabParameter(:sigma)\nnothing # hide","category":"section"},{"location":"petab_cond_specific/#Specifying-Condition-Specific-Parameters","page":"Simulation Condition-Specific Parameters","title":"Specifying Condition-Specific Parameters","text":"Condition-specific parameters are handled by first defining them as PEtabParameter, followed by linking the model parameter to the appropriate PEtabParameter in the simulation conditions. For instance, assume the value of the model parameter c1 for condition cond1 should be given by c1_cond1, and for condition cond2 by c1_cond2, then the first step is to define c1_cond1 and c1_cond2 as PEtabParameter:\n\np_c1_cond1 = PEtabParameter(:c1_cond1)\np_c1_cond2 = PEtabParameter(:c1_cond2)\npest = [p_c1_cond1, p_c1_cond2, p_S0, p_c2, p_sigma]\nnothing # hide\n\nNext, the model parameter c1 must be mapped to the correct PEtabParameter in the simulation conditions:\n\ncond1 = Dict(:E => 5.0, :c1 => :c1_cond1)\ncond2 = Dict(:E => 2.0, :c1 => :c1_cond2)\nconds = Dict(\"cond1\" => cond1, \"cond2\" => cond2)\n\nNote that each simulation condition we also define the initial value for specie E. Finally, as usual, each measurement must be assigned to a simulation condition:\n\nusing DataFrames\nmeasurements = DataFrame(simulation_id=[\"cond1\", \"cond1\", \"cond2\", \"cond2\"],\n                         obs_id=[\"obs_p\", \"obs_sum\", \"obs_p\", \"obs_sum\"],\n                         time=[1.0, 10.0, 1.0, 20.0],\n                         measurement=[0.7, 0.1, 1.0, 1.5])\n\nGiven a Dict with simulation conditions and measurements in the correct format, it is then straightforward to create a PEtab problem with condition-specific parameters by simply providing the condition Dict under the simulation_conditions keyword:\n\nmodel = PEtabModel(rn, observables, measurements, pest; speciemap = speciemap,\n                   simulation_conditions = conds)\npetab_prob = PEtabODEProblem(model)\n\nWith this setup, the value for the model parameter c1 is given by c1_cond1 when simulating the model for cond1, and by c1_cond2 for cond2. Additionally, during parameter estimation, both c1_cond1 and c1_cond2 are estimated.\n\nFor models with many condition-specific parameters, runtime performance may improve by setting split_over_conditions=true (PEtab.jl tries to determine when to do this automatically, but it is a hard problem) when building the PEtabODEProblem. For more information on this, see this example.","category":"section"},{"location":"petab_cond_specific/#Additional-Possible-Configurations","page":"Simulation Condition-Specific Parameters","title":"Additional Possible Configurations","text":"In this tutorial, the condition-specific parameters [c1_cond1, c1_cond2] map to one model parameter. It is also possible for condition specific parameters to map to multiple parameters. For example, the following is allowed:\n\ncond1 = Dict(:c1 => :c1_cond1, :c2 => :c1_cond1)","category":"section"},{"location":"grad_hess_methods/#gradient_support","page":"Gradient and Hessian Methods","title":"Gradient and Hessian Methods","text":"PEtab.jl supports several gradient and Hessian computation methods when creating a PEtabODEProblem. This section provides a brief overview of each available method and the corresponding tunable options.","category":"section"},{"location":"grad_hess_methods/#Gradient-Methods","page":"Gradient and Hessian Methods","title":"Gradient Methods","text":"PEtab.jl supports three gradient computation methods: forward-mode automatic differentiation (:ForwardDiff), forward-sensitivity equations (:ForwardEquations), and adjoint sensitivity analysis (:Adjoint). A good introduction to the math behind these methods can be found in [16], and a good introduction to automatic differentitation can be found in [17]. Below is a brief description of each method.\n\n:ForwardDiff: This method uses ForwardDiff.jl to compute the gradient via forward-mode automatic differentiation [18]. The only tunable option is the chunksize (the number of directional derivatives computed in a single forward pass). While the default chunksize is typically a good choice, performance can be slightly improved by tuning this parameter, and we plan to add automatic tuning. This method is often the fastest for smaller models [19].\n:ForwardEquations: This method computes the gradient by solving an expanded ODE system to obtain the forward sensitivities during the forward pass. These sensitivities are then used to compute the gradient. The tunable option is sensealg, where the default option sensealg=:ForwardDiff (compute the sensitivities via forward-mode automatic differentiation) is often the fastest. PEtab.jl also supports the ForwardSensitivity() and ForwardDiffSensitivity() methods from SciMLSensitivity.jl. For more details and tunable options for these two methods, see the SciMLSensitivity documentation.\n:Adjoint: This method computes the gradient via adjoint sensitivity analysis, which involves solving an adjoint ODE backward in time. Several benchmark studies have shown that the adjoint method is the most efficient for larger models [20, 21]. The tunable option is sensealg, which specifies the adjoint algorithm from SciMLSensitivity to use. Available algorithms are InterpolatingAdjoint, GaussAdjoint, and QuadratureAdjoint. For information on their tunable options, see the SciMLSensitivity documentation.\n\nnote: Note\nTo use functionality from SciMLSensitivity (e.g., adjoint sensitivity analysis), the package must be loaded with using SciMLSensitivity before creating the PEtabODEProblem.","category":"section"},{"location":"grad_hess_methods/#Hessian-Methods","page":"Gradient and Hessian Methods","title":"Hessian Methods","text":"PEtab.jl supports three Hessian computation methods: forward-mode automatic differentiation (:ForwardDiff), a block Hessian approximation (:BlockForwardDiff), and the Gauss-Newton Hessian approximation (:GaussNewton). Below is a brief description of each method.\n\n:ForwardDiff: Thsi method computes the Hessian via forward-mode automatic differentiation using ForwardDiff.jl. As with the gradient, the only tunable option is the chunksize. This method has quadratic complexity, O(n^2), where n is the number of parameters, making it feasible only for models with up to n = 20 parameters. However, when computationally feasible, access to the full Hessian can improve the convergence of parameter estimation runs when doing multi-start parameter estimation.\n\n:BlockForwardDiff: This method computes a block Hessian approximation using forward-mode automatic differentiation with ForwardDiff.jl. Specifically, for PEtab problems, there are typically two sets of parameters to estimate: the parameters that are part of the ODE system, mathbfx_p, and those that are not, mathbfx_q. This block approach computes the Hessian for each block while approximating the cross-terms as zero:\n\nmathbfH_block =\nbeginbmatrix\nmathbfH_p  mathbf0 \nmathbf0  mathbfH_q\nendbmatrix\n\n:GaussNewton: This method approximates the Hessian using the Gauss-Newton method. This method often performs better than a (L)-BFGS approximation [20], but requires access to forward sensitivities (similar to :ForwardEquations above), and computing these for models with more than 75 parameters is often not computationally feasible. For more details on the computations see [22]. Therefore, for larger models, a (L)-BFGS approximation is often the only feasible option.","category":"section"},{"location":"grad_hess_methods/#References","page":"Gradient and Hessian Methods","title":"References","text":"F. Sapienza, J. Bolibar, F. Schäfer, B. Groenke, A. Pal, V. Boussange, P. Heimbach, G. Hooker, F. Pérez, P.-O. Persson and others. Differentiable Programming for Differential Equations: A Review, arXiv preprint arXiv:2406.09699 (2024).\n\n\n\nM. Blondel and V. Roulet. The elements of differentiable programming, arXiv preprint arXiv:2403.14606 (2024).\n\n\n\nJ. Revels, M. Lubin and T. Papamarkou. Forward-mode automatic differentiation in Julia, arXiv preprint arXiv:1607.07892 (2016).\n\n\n\nR. Mester, A. Landeros, C. Rackauckas and K. Lange. Differential methods for assessing sensitivity in biological models. PLoS computational biology 18, e1009598 (2022).\n\n\n\nF. Fröhlich, B. Kaltenbacher, F. J. Theis and J. Hasenauer. Scalable parameter estimation for genome-scale biochemical reaction networks. PLoS computational biology 13, e1005331 (2017).\n\n\n\nY. Ma, V. Dixit, M. J. Innes, X. Guo and C. Rackauckas. A comparison of automatic differentiation and continuous sensitivity analysis for derivatives of differential equation solutions. In: 2021 IEEE High Performance Extreme Computing Conference (HPEC) (IEEE, 2021); pp. 1–9.\n\n\n\nA. Raue, B. Steiert, M. Schelker, C. Kreutz, T. Maiwald, H. Hass, J. Vanlier, C. Tönsing, L. Adlung, R. Engesser and others. Data2Dynamics: a modeling environment tailored to parameter estimation in dynamical systems. Bioinformatics 31, 3558–3560 (2015).\n\n\n\n","category":"section"},{"location":"petab_obs_noise/#time_point_parameters","page":"Noise and Observable Parameters","title":"Noise and Observable Parameters","text":"Sometimes a model observable (e.g., a protein) is measured using different experimental assays. This can result in measurement noise parameter σ being different between measurements for the same observable. Additionally, if the observable is measured on a relative scale, the observable offset and scale parameters that link the model output scale to the measurement data scale might differ between measurements. From a modeling viewpoint, this can be handled by introducing time-point-specific noise and/or observable parameters.\n\nThis tutorial covers how to specify time-point specific observable and noise parameters for a PEtabModel. As a working example, we use the Michaelis-Menten enzyme kinetics model from the starting tutorial. Even though the code below encodes the model as a ReactionSystem, everything works exactly the same if the model is encoded as an ODESystem.\n\nusing Catalyst, PEtab\n\nrn = @reaction_network begin\n    @parameters S0 c3=1.0\n    @species S(t)=S0\n    c1, S + E --> SE\n    c2, SE --> S + E\n    c3, SE --> P + E\nend\nspeciemap = [:E => 50.0, :SE => 0.0, :P => 0.0]\n\np_c1 = PEtabParameter(:c1)\np_c2 = PEtabParameter(:c2)\np_s0 = PEtabParameter(:S0)\np_sigma = PEtabParameter(:sigma)\npest = [p_c1, p_c2, p_s0, p_sigma]\nnothing # hide","category":"section"},{"location":"petab_obs_noise/#Specifying-Noise-and-Observable-Parameters","page":"Noise and Observable Parameters","title":"Specifying Noise and Observable Parameters","text":"Time-point-specific parameters are handled by encoding observable and noise parameters in the PEtabObservable, followed by setting values for these parameters in the measurements DataFrame. For instance, assume that the measurement noise is time-point specific for the observable obs_sum. Then, the first step is to add a noise parameter of the form noiseParameter... in the PEtabObservable:\n\n@unpack E, S = rn\n@parameters noiseParameter1_obs_sum\nobs_sum = PEtabObservable(S + E, noiseParameter1_obs_sum)\n\nAdditionally, assume that data is measured on a relative scale, where the scale and offset parameters vary between time points for the observable obs_p. Then, the first step for this observable is to add observable parameters of the form observableParameter...:\n\n@unpack P = rn\n@parameters observableParameter1_obs_p observableParameter2_obs_p\nobs_p = PEtabObservable(observableParameter1_obs_p * P + observableParameter2_obs_p, 3.0)\n\nGiven this, the observables are collected in a Dict as usual:\n\nobservables = Dict(\"obs_p\" => obs_p, \"obs_sum\" => obs_sum)\nnothing # hide\n\nnote: Note\nNoise and observable parameters must follow the format observableParameter${n}_${observableId} and noiseParameter${n}_${observableId}, with n starting from 1, to ensure correct parameter mapping when building the PEtab problem. This follows the PEtab specification, and more details can be found here.","category":"section"},{"location":"petab_obs_noise/#Mapping-Measurements-to-Time-Point-Specific-Parameters","page":"Noise and Observable Parameters","title":"Mapping Measurements to Time-Point Specific Parameters","text":"To link the measurements to time-point-specific noise and/or observable parameters, values for these parameters must be specified in the measurements DataFrame. These values can be either constant numerical values or any defined PEtabParameter. For our working example, a valid measurement table would look like this (the column names matter, but not the order):\n\nobs_id (str) time (float) measurement (float) observable_parameters (str | float) noise_parameters (str | float)\nobs_p 1.0 0.7  sigma\nobs_sum 10.0 0.1 3.0; 4.0 \nobs_p 1.0 1.0  sigma\nobs_sum 20.0 1.5 2.0; 3.0 \n\nIn particular, the follow consideration apply to the measurements table:\n\nIf an observable does not have noise or observable parameters (e.g., obs_p above lacks observable parameters), the corresponding column should be left empty.\nFor multiple parameters, values are separated by a semicolon (e.g., for obs_sum, we have 3.0; 4.0).\nThe values for noise and observable parameters can be either numerical values or any defined PEtabParameter (e.g., sigma above). Combinations are also allowed, so sigma;1.0 is valid.\nIf an observable has noise and/or observable parameters, values for these must be specified for each measurement of that observable.\n\nFor our working example, the measurement data would in Julia look like:\n\nusing DataFrames\nmeasurements = DataFrame(\n    obs_id=[\"obs_p\", \"obs_sum\", \"obs_p\", \"obs_sum\"],\n    time=[1.0, 10.0, 1.0, 20.0],\n    measurement=[0.7, 0.1, 1.0, 1.5], \n    observable_parameters=[missing, \"3.0;4.0\", missing, \"2.0;3.0\"],\n    noise_parameters=[\"sigma\", missing, \"sigma\", missing]\n)","category":"section"},{"location":"petab_obs_noise/#Bringing-It-All-Together","page":"Noise and Observable Parameters","title":"Bringing It All Together","text":"Given observables and measurements in the correct format, it is straightforward to create a PEtab problem with time-point-specific parameters by creating the PEtabModel as usual:\n\nmodel = PEtabModel(rn, observables, measurements, pest; speciemap = speciemap)\npetab_prob = PEtabODEProblem(model)","category":"section"},{"location":"API/#API","page":"API","title":"PEtab.jl API","text":"","category":"section"},{"location":"API/#PEtabModel","page":"API","title":"PEtabModel","text":"A PEtabModel for parameter estimation/inference can be created by importing a PEtab parameter estimation problem in the standard format, or it can be directly defined in Julia. For the latter, observables that link the model to measurement data are provided by PEtabObservable, parameters to estimate are defined by PEtabParameter, and any potential events (callbacks) are specified as PEtabEvent.\n\nThen, given a dynamic model (as ReactionSystem or ODESystem), measurement data as a DataFrame, and potential simulation conditions as a Dict (see this tutorial), a PEtabModel can be created:","category":"section"},{"location":"API/#PEtabODEProblem","page":"API","title":"PEtabODEProblem","text":"From a PEtabModel, a PEtabODEProblem can:\n\nA PEtabODEProblem has numerous configurable options. Two of the most important options are the ODESolver and, for models with steady-state simulations, the SteadyStateSolver:\n\nPEtab.jl provides several functions for interacting with a PEtabODEProblem:\n\nAnd additionally, functions for interacting with the underlying dynamic model (ODEProblem) within a PEtabODEProblem:","category":"section"},{"location":"API/#Parameter-Estimation","page":"API","title":"Parameter Estimation","text":"A PEtabODEProblem contains all the necessary information for wrapping a suitable numerical optimization library, but for convenience, PEtab.jl provides wrappers for several available optimizers. In particular, single-start parameter estimation is provided via calibrate:\n\nMulti-start (recommended method) parameter estimation, is provided via calibrate_multistart:\n\nLastly, model selection is provided via petab_select:\n\nFor each case case, PEtab.jl supports the usage of optimization algorithms from Optim.jl, Ipopt.jl, and Fides.py:\n\nParameter estimation results can be visualized using the plot-recipes detailed in this page, and with get_obs_comparison_plots:\n\nAs an alternative to the PEtab.jl interface to parameter estimation, a PEtabODEProblem can be converted to an OptimizationProblem to access the algorithms available via Optimization.jl:","category":"section"},{"location":"API/#Bayesian-Inference","page":"API","title":"Bayesian Inference","text":"PEtab.jl offers wrappers to perform Bayesian inference using state-of-the-art methods such as NUTS (the same sampler used in Turing.jl) or AdaptiveMCMC.jl. It should be noted that this part of PEtab.jl is planned to be moved to a separate package, so the syntax will change and be made more user-friendly in the future.","category":"section"},{"location":"API/#PEtab.PEtabObservable","page":"API","title":"PEtab.PEtabObservable","text":"PEtabObservable(obs_formula, noise_formula; kwargs...)\n\nFormulas defining the likelihood that links the model output to the measurement data.\n\nobs_formula describes how the model output relates to the measurement data, while noise_formula describes the standard deviation (measurement error) and can be an equation or a numerical value. Both the observable and noise formulas can be a valid Julia equation. Variables used in these formulas must be either model species, model parameters, or parameters defined as PEtabParameter. The formulas can also include time-point-specific noise and observable parameters; for more information, see the documentation.\n\nKeyword Argument\n\ntransformation: The transformation applied to the observable and its corresponding   measurements. Valid options are :lin (normal measurement noise), :log, log2 or   :log10 (log-normal measurement noise). See below for more details.\n\nDescription\n\nFor a measurement y, an observable h = obs_formula, and a standard deviation σ = noise_formula, the PEtabObservable defines the likelihood that links the model output to the measurement data: pi(y mid h sigma). For transformation = :lin, the measurement noise is assumed to be normally distributed, and the likelihood is given by:\n\npi(yh sigma) = frac1sqrt2pi sigma^2mathrmexpbigg( -frac(y - h)^22sigma^2 bigg)\n\nAs a special case, if sigma = 1, this likelihood reduces to the least-squares objective function. For transformation = :log, the measurement noise is assumed to be log-normally distributed, and the likelihood is given by:\n\npi(yh sigma) = frac1sqrt2pi sigma^2 y^2mathrmexpbigg( -fracbig(mathrmlog(y) - mathrmlog(h)big)^22sigma^2 bigg)\n\nFor transformation = :log10, the measurement noise is assumed to be log10-normally distributed, and the likelihood is given by:\n\npi(yh sigma) = frac1sqrt2pi sigma^2 y^2mathrmlog(10) mathrmexpbigg( -fracbig(mathrmlog_10(y) - mathrmlog_10(h)big)^22sigma^2 bigg)\n\nLastly, for transformation = :log2, the measurement noise is assumed to be log2-normally distributed, and the likelihood is given by:\n\npi(yh sigma) = frac1sqrt2pi sigma^2 y^2mathrmlog(2) mathrmexpbigg( -fracbig(mathrmlog_2(y) - mathrmlog_2(h)big)^22sigma^2 bigg)\n\nFor numerical stabillity, PEtab.jl works with the log-likelihood in practice.\n\n\n\n\n\n","category":"type"},{"location":"API/#PEtab.PEtabParameter","page":"API","title":"PEtab.PEtabParameter","text":"PEtabParameter(x; kwargs...)\n\nParameter estimation information for parameter x.\n\nAll parameters to be estimated in a PEtabODEProblem must be declared as a PEtabParameter, and x must be the name of a parameter that appears in the model, observable formula, or noise formula.\n\nKeyword Arguments\n\nlb::Float64 = 1e-3: The lower parameter bound for parameter estimation. Must    be specified on the linear scale. For example, if scale = :log10, provide the    bound as 1e-3 rather than log10(1e-3).\nub::Float64 = 1e3: The upper parameter bound for parameter estimation. Must as for    lb be provided on linear scale.\nscale::Symbol = :log10: The scale on which to estimate the parameter. Allowed options   are :log10 (default), :log2 :log, and :lin. Estimating on the log10   scale typically improves performance and is recommended.\nprior = nothing: An optional continuous univariate parameter prior distribution from   Distributions.jl. The prior    overrides any parameter bounds.\nprior_on_linear_scale = true: Whether the prior is on the linear scale (default) or on   the transformed scale. For example, if scale = :log10 and   prior_on_linear_scale = false, the prior acts on the transformed value; log10(x).\nestimate = true: Whether the parameter should be estimated (default) or treated as a   constant.\nvalue = nothing: Value to use if estimate = false, and value retreived by the get_x   function. Defaults to the midpoint between lb and ub.\n\nDescription\n\nIf a prior pi(x_i) is provided, the parameter estimation problem becomes a maximum a posteriori problem instead of a maximum likelihood problem. Practically, instead of minimizing the negative log-likelihood,-ell(x), the negative posterior is minimized:\n\nmin_mathbfx -ell(mathbfx) - sum_i pi(x_i)\n\nFor all parameters i with a prior.\n\n\n\n\n\n","category":"type"},{"location":"API/#PEtab.PEtabEvent","page":"API","title":"PEtab.PEtabEvent","text":"PEtabEvent(condition, affects, targets)\n\nA model event triggered by condition that sets the value of targets to that of affects.\n\nFor a collection of examples with corresponding plots, see the documentation.\n\nArguments\n\ncondition: A Boolean expression that triggers the event when it transitions from   false to true. For example, if t == c1, the event is triggered when the model   time t equals c1. For S > 2.0, the event triggers when specie S passes 2.0   from below.\naffects: An equation of of model species and parameters that describes the effect of   the event. It can be a single expression or a vector if there are multiple targets.\ntargets: Model species or parameters that the event acts on. Must match the dimension   of affects.\n\n\n\n\n\n","category":"type"},{"location":"API/#PEtab.PEtabModel","page":"API","title":"PEtab.PEtabModel","text":"PEtabModel(sys, observables::Dict{String, PEtabObservable}, measurements::DataFrame,\n           parameters::Vector{PEtabParameter}; kwargs...)\n\nFrom a ReactionSystem or an ODESystem model, observables that link the model to measurements and parameters to estimate, create a PEtabModel for parameter estimation.\n\nFor examples on how to create a PEtabModel, see the documentation.\n\nSee also PEtabObservable, PEtabParameter, and PEtabEvent.\n\nKeyword Arguments\n\nsimulation_conditions = nothing: An optional dictionary specifying initial specie values   and/or model parameters for each simulation condition. Only required if the model has   multiple simulation conditions.\nevents = nothing: Optional model events (callbacks) provided as PEtabEvent. Multiple   events should be provided as a Vector of PEtabEvent.\nverbose::Bool = false: Whether to print progress while building the PEtabModel.\n\nPEtabModel(path_yaml; kwargs...)\n\nImport a PEtab problem in the standard format with YAML file at path_yaml into a PEtabModel for parameter estimation.\n\nFor examples on how to import a PEtab problem, see the documentation.\n\nKeyword Arguments\n\nifelse_to_callback::Bool = true: Whether to rewrite ifelse (SBML piecewise)   expressions to callbacks. This improves   simulation runtime. It is strongly recommended to set this to true.\nverbose::Bool = false: Whether to print progress while building the PEtabModel.\nwrite_to_file::Bool = false: Whether to write the generated Julia functions to files in  the same directory as the PEtab problem. Useful for debugging.\n\n\n\n\n\n","category":"type"},{"location":"API/#PEtab.PEtabODEProblem","page":"API","title":"PEtab.PEtabODEProblem","text":"PEtabODEProblem(model::PEtabModel; kwargs...)\n\nFrom model create a PEtabODEProblem for parameter estimation/inference.\n\nIf no options (kwargs) are provided, default settings are used for the ODESolver, gradient method, and Hessian method. For more information on the default options, see the documentation.\n\nSee also ODESolver, SteadyStateSolver, and PEtabModel.\n\nKeyword Arguments\n\nodesolver::ODESolver: ODE solver options for computing the likelihood (objective   function).\nodesolver_gradient::ODESolver: ODE solver options for computing the gradient. Defaults   to odesolver if not provided.\nss_solver::SteadyStateSolver: Steady-state solver options for computing the likelihood.   Only applicable for models with steady-state simulations.\nss_solver_gradient::SteadyStateSolver: Steady-state solver options for computing the   gradient. Defaults to ss_solver if not provided.\ngradient_method::Symbol: Method for computing the gradient. Available options and   defaults are listed in the documentation.\nhessian_method::Symbol: Method for computing the Hessian. As with the gradient,   available options and defaults can be found in the documentation.\nFIM_method=nothing: Method for computing the empirical Fisher Information Matrix (FIM).   Accepts the same options as hessian_method.\nsparse_jacobian=false: Whether to use a sparse Jacobian when solving the ODE model.   This can greatly improve performance for large models.\nsensealg: Sensitivity algorithm for gradient computations. Available and default   options depend on gradient_method. See the documentation for details.\nchunksize=nothing: Chunk size for ForwardDiff.jl when using forward-mode automatic   differentiation for gradients and Hessians. If not provided, a default value is used.   Tuning chunksize can improve performance but is non-trivial.\nsplit_over_conditions::Bool=false: Whether to split ForwardDiff.jl calls across   simulation conditions when computing the gradient and/or Hessian. This improves   performance for models with many condition-specific parameters, otherwise it increases   runtime.\nreuse_sensitivities::Bool=false: Whether to reuse forward sensitivities from the   gradient computation for the Gauss-Newton Hessian approximation. Only applies when   hessian_method=:GaussNewton and gradient_method=:ForwardEquations. This can greatly   improve  performance when the optimization algorithm computes both the gradient and   Hessian simultaneously.\nverbose::Bool = false: Whether to print progress while building the PEtabODEProblem.\n\nReturns\n\nA PEtabODEProblem, where the key fields are:\n\nnllh: Compute the negative log-likelihood function for an input vector x;   nllh(x). For this function and the ones below listed below, the input x can be   either a Vector or a ComponentArray.\ngrad!: Compute the in-place gradient of the nllh; grad!(g, x).\ngrad: Compute the out-of-place gradient of the nllh; g = grad(x).\nhess!: Compute the in-place Hessian of the nllh; hess!(H, x).\nhess: Compute the out-of-place Hessian of the nllh; H = hess(x).\nFIM: Compute the out-of-place empirical Fisher Information Matrix (FIM) of the nllh;   F = FIM(x).\nchi2: Compute the chi-squared test statistic for the nllh (see mathematical definition   below); χ² = chi2(x).\nresiduals: Computes the residuals between the measurement data and model output (see   the mathematical definition below); r = residuals(x).\nsimulated_values: Computes the corresponding model values for each measurement in the   measurements table, in the same order as the measurements appear.\nlower_bounds: Lower parameter bounds for parameter estimation, as specified when   creating the model.\nupper_bounds: Upper parameter bounds for parameter estimation, as specified when   creating the model.\n\nDescription\n\nFollowing the PEtab standard, the objective function to be used for parameter estimation created by the PEtabODEProblem is a likelihood function, or, if priors are provided, a posterior function. The characteristics of the objective is defined in the PEtabModel. In practice, for numerical stability, a PEtabODEProblem works with the negative log-likelihood:\n\n-ell(mathbfx) =  - sum_i = 1^N ell_i(mathbfx)\n\nwhere ell_i is the likelihood for each measurement i. In addition, to accommodate numerical optimization packages, the PEtabODEProblem provides efficient functions for computing the gradient -nabla ell(mathbfx) and the second derivative Hessian matrix -nabla^2 ell(mathbfx), using the specified or default gradient_method and hessian_method.\n\nIn addition to -ell and its derivatives, the PEtabODEProblem provides functions for diagnostics and model selection. The χ² (chi-squared) value can be used for model selection [1], and it is computed as the sum of the χ² values for each measurement. For a measurement y, an observable h = obs_formula, and a standard deviation σ = noise_formula, the χ² is computed as:\n\nchi^2 = frac(y - h)^2sigma^2\n\nThe residuals r can be used to assess the measurement error model and are computed as:\n\nr = frac(y - h)sigma\n\nLastly, the empirical Fisher Information Matrix (FIM) can be used for identifiability analysis [2]. It should ideally be computed with an exact Hessian method. The inverse of the FIM provides a lower bound on the covariance matrix. While the FIM can be useful, the profile-likelihood approach generally yields better results for identifiability analysis [2].\n\nCedersund et al, The FEBS journal, pp 903-922 (2009).\nRaue et al, Bioinformatics, pp 1923-1929 (2009).\n\n\n\n\n\n","category":"type"},{"location":"API/#PEtab.ODESolver","page":"API","title":"PEtab.ODESolver","text":"ODESolver(solver, kwargs..)\n\nODE-solver options (solver, tolerances, etc.) used for solving the ODE model in a PEtabODEProblem.\n\nAny solver from OrdinaryDiffEq.jl and Sundials.jl is supported. For solver recommendations and default options used when an ODESolver is not provided when creating a PEtabODEProblem, see the documentation.\n\nMore information on the available options and solvers can also be found in the documentation for DifferentialEquations.jl.\n\nKeyword Arguments\n\nabstol=1e-8: Absolute tolerance when solving the ODE model. It is not recommended to   increase above 1e-6 for gradients in order to obtain accurate gradients.\nreltol=1e-8: Absolute tolerance when solving the ODE model. It is not recommended to   increase above 1e-6 for gradients in order to obtain accurate gradients.\ndtmin=nothing: Minimum acceptable step size when solving the ODE model.\nmaxiters=10000: Maximum number of iterations when solving the ODE model. Increasing   above the default value can cause parameter estimation to take substantial longer time.\nverbose::Bool=true: Whether or not warnings are displayed if the solver exits early.   true is recommended to detect if a suboptimal choice of solver.\nadj_solver=solver: Solver to use when solving the adjoint ODE. Only applicable if   gradient_method=:Adjoint when creating the PEtabODEProblem. Defaults to solver.\nabstol_adj=abstol: Absolute tolerance when solving the adjoint ODE model. Only   applicable if gradient_method=:Adjoint when creating the PEtabODEProblem. Defaults   to abstol.\nreltol_adj=abstol: Relative tolerance when solving the adjoint ODE model. Only   applicable if gradient_method=:Adjoint when creating the PEtabODEProblem. Defaults   to reltol.\n\n\n\n\n\n","category":"type"},{"location":"API/#PEtab.SteadyStateSolver","page":"API","title":"PEtab.SteadyStateSolver","text":"SteadyStateSolver(method::Symbol; kwargs...)\n\nSteady-state solver options (method, tolerances, etc.) for computing the steady state, where the ODE right-hand side f fulfills du = f(u, p, t) ≈ 0.\n\nThe steady state can be computed in two ways. If method=:Simulate, by simulating the ODE model until du = f(u, p, t) ≈ 0 using ODE solver options defined in the provied ODESolver to the PEtabODEProblem. This approach is **strongly** recommended. Ifmethod=:Rootfinding, by directly finding the root of the RHSf(u, p, t) = 0` using any algorithm from NonlinearSolve.jl. The root-finding approach is far less reliable than the simulation approach (see description below).\n\nKeyword Arguments\n\ntermination_check = :wrms: Approach to check if the model has reached steady-state for   method = :Simulate. Two approaches are supported:\n:wrms: Weighted root-mean-square. Terminate when: sqrtfrac1N sum_i^N Big( fracdu_ireltol * u_i + abstolBig)^2  1\n:Newton: Terminate if the step for Newton's method Δu is sufficiently small: sqrtfrac1N sum_i^N Big(fracDelta u_ireltol * u_i + abstolBig)^2  1 The :Newton approach requires that the Newton step Δu can be computed, which is only possible if the Jacobian of the RHS of the ODE model is invertible. If this is not the case, a pseudo-inverse is used if pseudoinverse = true, else wrms is used. The :Newton termination should perform better than :wrms as it accounts for the scale of the ODEs, but until benchmarks confirm this, we recommend :wrms.\npseudoinverse = true: Whether to use a pseudo-inverse if inverting the Jacobian fails   for termination_check = :Newton.\nrootfinding_alg = nothing: Root-finding algorithm from NonlinearSolve.jl to use if   method = :Rootfinding. If left empty, the default NonlinearSolve.jl algorithm is used.\nabstol: Absolute tolerance for the NonlinearSolve.jl root-finding problem or the   termination_check formula. Defaults to 100 * abstol_ode, where abstol_ode is the   tolerance for the ODESolver in the PEtabODEProblem.\nreltol: Relative tolerance for the NonlinearSolve.jl root-finding problem or the   termination_check formula. Defaults to 100 * reltol_ode, where reltol_ode is the   tolerance for the ODESolver in the PEtabODEProblem.\nmaxiters: Maximum number of iterations to use if method = :Rootfinding.\n\nDescription\n\nFor an ODE model of the form:\n\nfracmathrmdumathrmdt = du = f(u p t)\n\nThe steady state is defined by:\n\nf(u p t) = 00\n\nThe steady state can be computed in two ways: either by simulating the ODE model from a set of initial values u₀ until du ≈ 0, or by using a root-finding algorithm such as Newton's method to directly solve f(u, p, t) = 0.0. While the root-finding approach is computationally more efficient (since it does not require solving the entire ODE), it is far less reliable and can converge to the wrong root. For example, in mass-action models with positive initial values, the feasible root should be positive in u. This is generally fulfilled when computing the steady state via simulation (a negative root typically only occurs if the ODE solver fails). However, with root-finding, there is no such guarantee, as any root that satisfies f(u, p, t) = 0.0 may be returned. Consistent with this, benchmarks have shown that simulation is the most reliable method [1].\n\nAnother alternative is to solve for the steady state  symbolically. If feasible, this is the most computationally efficient approach [1].\n\nFiedler et al, BMC system biology, pp 1-19 (2016)\n\n\n\n\n\n","category":"type"},{"location":"API/#PEtab.get_x","page":"API","title":"PEtab.get_x","text":"get_x(prob::PEtabODEProblem; linear_scale = false)::ComponentArray\n\nGet the nominal parameter vector with parameters in the correct order expected by prob for parameter estimation/inference. Nominal values can optionally be specified when creating a PEtabParameter, or in the parameters table if the problem is provided in the PEtab standard format.\n\nFor ease of interaction (e.g., changing values), the parameter vector is returned as a ComponentArray.  For how to interact with a ComponentArray, see the documentation and the ComponentArrays.jl documentation.\n\nSee also PEtabParameter.\n\nKeyword argument\n\nlinear_scale: Whether to return parameters on the linear scale. By default, parameters are returned on the scale they are estimated, which by default is log10 as this often improves parameter estimation performance.\n\n\n\n\n\n","category":"function"},{"location":"API/#SciMLBase.remake-Tuple{PEtabODEProblem, Dict}","page":"API","title":"SciMLBase.remake","text":"remake(prob::PEtabODEProblem, xchange::Dict)::PEtabODEProblem\n\nFix and consequently remove a set of parameters from being estimated without rebuilding prob.\n\nxchange should be provided as a Dict with parameter names and their new values. For example, to fix k1 to 1.0, provide xchange = Dict(:k1 => 1.0). The parameters to be fixed can only be those that were originally set to be estimated.\n\nremake is the most efficient approach for fixing parameters, as it does not re-compile the problem.\n\n\n\n\n\n","category":"method"},{"location":"API/#PEtab.get_u0","page":"API","title":"PEtab.get_u0","text":"get_u0(res, prob::PEtabODEProblem; kwargs...)\n\nRetrieve the ODEProblem initial values for simulating the ODE model in prob. res can be a parameter estimation result (e.g., PEtabMultistartResult) or a Vector with parameters in the order expected by prob (see get_x).\n\nFor information on keyword arguements see get_ps.\n\nSee also get_odeproblem and get_odesol.\n\n\n\n\n\n","category":"function"},{"location":"API/#PEtab.get_ps","page":"API","title":"PEtab.get_ps","text":"get_ps(res, prob::PEtabODEProblem; kwargs...)\n\nRetrieve the ODEProblem parameter values for simulating the ODE model in prob. res can be a parameter estimation result (e.g., PEtabMultistartResult) or a Vector with parameters in the order expected by prob (see get_x).\n\nSee also: get_u0, get_odeproblem, get_odesol.\n\nKeyword Arguments\n\nretmap=true: Whether to return the values as a map in the form [k1 => val1, ...]. Such   a map can be directly used when building an ODEProblem. If false, a Vector is   returned. This keyword is only applicable for get_u0 and get_ps.\ncid::Symbol: Which simulation condition to return parameters for. If not provided,   defaults to the first simulation condition. For other get functions, the   ODEProblem, u0, or ODESolution for the specified cid is returned.\npreeq_id: Which potential pre-equilibration (steady-state) simulation id to use.   If a valid preeq_id is provided, the ODE is first simulated to steady state for   preeq_id. Then the model shifts to cid, and the parameters for cid are returned.   For other get functions, the  ODEProblem, u0, or ODESolution for the   specified cid is returned\n\n\n\n\n\n","category":"function"},{"location":"API/#PEtab.get_system","page":"API","title":"PEtab.get_system","text":"get_system(res, prob::PEtabODEProblem; kwargs...) -> (sys, p, u0, callbacks)\n\nRetrieve the dynamic model system, parameter map (p), initial species map (u0), and callbacks (CallbackSet) for the model in prob. The argument res can be a parameter estimation result (e.g., PEtabMultistartResult) or a Vector of parameters in the order expected by prob (see get_x).\n\nThe system type returned depends on the input to PEtabModel. If the model is provided as a ReactionSystem, a ReactionSystem is returned. The same applies for an ODESystem. If the model is provided via an SBML file, a ReactionSystem is returned.\n\nFor information on keyword arguments, see get_ps.\n\nSee also: get_u0 and get_odesol.\n\n\n\n\n\n","category":"function"},{"location":"API/#PEtab.get_odeproblem","page":"API","title":"PEtab.get_odeproblem","text":"get_odeproblem(res, prob::PEtabODEProblem; kwargs...) -> (sys, callbacks)\n\nRetrieve the ODEProblem and callbacks (CallbackSet) for simulating the ODE model in prob. res can be a parameter estimation result (e.g., PEtabMultistartResult) or a Vector with parameters in the order expected by prob (see get_x).\n\nFor information on keyword arguements see get_ps.\n\nSee also: get_u0 and get_odesol.\n\n\n\n\n\n","category":"function"},{"location":"API/#PEtab.get_odesol","page":"API","title":"PEtab.get_odesol","text":"get_odesol(res, prob::PEtabODEProblem; kwargs...)::ODESolution\n\nRetrieve the ODESolution from simulating the ODE model in prob. res can be a parameter estimation result (e.g., PEtabMultistartResult) or a Vector with parameters in the order expected by prob (see get_x).\n\nFor information on keyword arguements see get_ps.\n\nSee also: get_u0 and get_odeproblem.\n\n\n\n\n\n","category":"function"},{"location":"API/#PEtab.solve_all_conditions","page":"API","title":"PEtab.solve_all_conditions","text":"solve_all_conditions(x, prob::PEtabODEProblem, solver; kwargs)\n\nSolve the ODE model in prob for all simulation conditions with the provided ODE-solver.\n\nx should be a Vector or ComponentArray with parameters in the order expected by prob (see get_x).\n\nKeyword Arguments\n\nabstol=1e-8: Absolute tolerance for the ODE solver.\nreltol=1e-8: Relative tolerance for the ODE solver.\nmaxiters=1e4: Maximum iterations for the ODE solver.\nntimepoints_save=0: The number of time points at which to save the ODE solution for   each condition. A value of 0 means the solution is saved at the solvers default time   points.\nsave_observed_t=false: When set to true, this option overrides ntimepoints_save   and saves the ODE solution only at the time points where measurement data is available.\n\nReturns\n\nodesols: A dictionary containing the ODESolution for each simulation condition.\n\n\n\n\n\n","category":"function"},{"location":"API/#PEtab.calibrate","page":"API","title":"PEtab.calibrate","text":"calibrate(prob::PEtabODEProblem, x0, alg; kwargs...)::PEtabOptimisationResult\n\nFrom starting point x0 using optimization algorithm alg, estimate unknown model parameters for prob, and get results as a PEtabOptimisationResult.\n\nx0 can be a Vector or a ComponentArray, where the individual parameters must be in the order expected by prob. To get a vector in the correct order, see get_x.\n\nA list of available and recommended optimization algorithms (alg) can be found in the documentation. Briefly, supported algorithms are from:\n\nOptim.jl: LBFGS(), BFGS(),   or IPNewton() methods.\nIpopt.jl: IpoptOptimizer() interior-point Newton   method.\nFides.py: Fides() Newton trust region method.\n\nDifferent ways to visualize the parameter estimation result can be found in the documentation.\n\nSee also PEtabOptimisationResult, Fides and IpoptOptimizer\n\nKeyword Arguments\n\nsave_trace::Bool = false: Whether to save the optimization trace of the objective   function and parameter vector. Only applicable for some algorithms; see the   documentation for details.\noptions = DEFAULT_OPTIONS: Configurable options for alg. The type and available   options depend on which package alg belongs to. For example, if alg = IPNewton()   from Optim.jl, options should be provided as an Optim.Options() struct. A list of   configurable options can be found in the documentation.\n\n\n\n\n\n","category":"function"},{"location":"API/#PEtab.PEtabOptimisationResult","page":"API","title":"PEtab.PEtabOptimisationResult","text":"PEtabOptimisationResult\n\nParameter estimation statistics from single-start optimization with calibrate.\n\nSee also: calibrate\n\nFields\n\nxmin: Minimizing parameter vector found by the optimization.\nfmin: Minimum objective value found by the optimization.\nx0: Starting parameter vector.\nalg: Parameter estimation algorithm used.\nniterations: Number of iterations for the optimization.\nruntime: Runtime in seconds for the optimization.\nxtrace: Parameter vector optimization trace. Empty if save_trace = false was   provided to calibrate.\nftrace: Objective function optimization trace. Empty if save_trace = false was   provided to calibrate.\nconverged: Convergence flag from alg.\noriginal: Original result struct returned by alg. For example, if alg = IPNewton()   from Optim.jl, original is the Optim return struct.\n\n\n\n\n\n","category":"type"},{"location":"API/#PEtab.calibrate_multistart","page":"API","title":"PEtab.calibrate_multistart","text":"calibrate_multistart([rng::AbstractRng], prob::PEtabODEProblem, alg, nmultistarts::Integer;\n                     nprocs = 1, dirsave=nothing, kwargs...)::PEtabMultistartResult\n\nPerform nmultistarts parameter estimation runs from randomly sampled starting points using the optimization algorithm alg to estimate the unknown model parameters in prob.\n\nA list of available and recommended optimisation algorithms (alg) can be found in the package documentation and in the calibrate documentation.\n\nAs with get_startguesses, the rng controlling the generation of starting points is optional; if omitted, Random.default_rng() is used. For reproducible starting points, pass a seeded rng (e.g., MersenneTwister(42)).\n\nIf nprocs > 1, the parameter estimation runs are performed in parallel using the pmap function from Distributed.jl with nprocs processes. If parameter estimation on a single process (nprocs = 1) takes longer than 5 minutes, we strongly recommend setting nprocs > 1, as this can greatly reduce runtime. Note that nprocs should not be larger than the number of cores on the computer.\n\nIf dirsave is provided, intermediate results for each run are saved in dirsave. It is strongly recommended to provide dirsave for larger models, as parameter estimation can take hours (or even days!),and without dirsave, all intermediate results will be lost if something goes wrong.\n\nDifferent ways to visualize the parameter estimation result can be found in the documentation.\n\nSee also PEtabMultistartResult, get_startguesses, and calibrate.\n\nKeyword Arguments\n\nsampling_method = LatinHypercubeSample(): Method for sampling a diverse (spread out) set  of starting points. See the documentation for get_startguesses, which is the  function used for generating starting points.\nsample_prior::Bool = true: See the documentation for get_startguesses.\noptions = DEFAULT_OPTIONS: Configurable options for alg. See the documentation for   calibrate.\n\n\n\n\n\n","category":"function"},{"location":"API/#PEtab.get_startguesses","page":"API","title":"PEtab.get_startguesses","text":"get_startguesses([rng::AbstractRNG], prob::PEtabODEProblem, n::Integer; kwargs...)\n\nGenerate n random parameter vectors within the parameter bounds in prob.\n\nrng is optional and if omitted defaults to Random.default_rng(). If n = 1, a single random vector is returned. For n > 1, a vector of random parameter vectors is returned. In both cases, parameter vectors are returned as a ComponentArray. For details on how to interact with a ComponentArray, see the documentation and the ComponentArrays.jl documentation.\n\nSee also calibrate and calibrate_multistart.\n\nKeyword Arguments\n\nsampling_method = LatinHypercubeSample(): Method for sampling a diverse (spread out) set  of parameter vectors. Any algorithm from  QuasiMonteCarlo is allowed, but the  default LatinHypercubeSample is recommended as it usually performs well.\nsample_prior::Bool = true: Whether to sample random parameter values from the  prior distribution if a parameter has a prior.\nallow_inf::Bool = false: Whether to return parameter vectors for which the likelihood  cannot be computed (typically happens because the ODEProblem cannot be solved). Often  it only makes sense to use starting points with a computable likelihood for  parameter estimation, hence it typically does not make sense to change this option.\n\n\n\n\n\n","category":"function"},{"location":"API/#PEtab.PEtabMultistartResult","page":"API","title":"PEtab.PEtabMultistartResult","text":"PEtabMultistartResult\n\nParameter estimation statistics from multi-start optimization with calibrate_multistart.\n\nSee also calibrate_multistart and PEtabOptimisationResult.\n\nFields\n\nxmin: Best minimizer across all runs.\nfmin: Best minimum across all runs.\nalg: Parameter estimation algorithm.\nnmultistarts: Number of parameter estimation runs.\nsampling_method: Sampling method used for generating starting points.\ndirsave: Path of directory where parameter estimation run statistics are saved if   dirsave was provided to calibrate_multistart.\nruns: Vector of PEtabOptimisationResult with the parameter estimation results   for each run.\n\nPEtabMultistartResult(dirres::String; which_run::String=\"1\")\n\nImport multistart parameter estimation results saved at dirres.\n\nEach time a new optimization run is performed, results are saved with unique numerical endings. Results from a specific run can be retrieved by specifying the numerical ending with which_run.\n\n\n\n\n\n","category":"type"},{"location":"API/#PEtab.petab_select","page":"API","title":"PEtab.petab_select","text":"petab_select(path_yaml, alg; nmultistarts = 100, kwargs...) -> path_res\n\nFor a PEtab-select problem, perform model selection with the method specified in the PEtab select problem files. Returns the path (path_res) to a YAML-file with model selection results.\n\nThe general model selection (e.g. to use forward-search) options are specified in the PEtab-select files. For details on how to set this up, see the PEtab-select documentation.\n\nFor each round of model selection, the candidate models are parameter estimated using multi-start parameter estimation, with nmultistarts performed for each model. The objective values obtained from parameter estimation are then used for the next round of  model evaluation.\n\nA list of available and recommended optimization algorithms (alg) can be found in the package documentation and calibrate documentation.\n\nSee also calibrate_multistart.\n\nKeyword Arguments\n\nkwargs: The same keywords accepted by PEtabODEProblem and calibrate.\n\n\n\n\n\n","category":"function"},{"location":"API/#PEtab.Fides","page":"API","title":"PEtab.Fides","text":"Fides(hessian_method; verbose::Bool=false)\n\nSetup the Fides box-constrained Newton-trust region optimizer for parameter estimation.\n\nSee also calibrate and calibrate_multistart.\n\nArguments\n\nhessian_method: Method for computing the Hessian. Allowed options are:\nnothing: The Hessian computed by the PEtabODEProblem is used.\n:BB: Broyden's \"bad\" method.\n:BFGS: Broyden-Fletcher-Goldfarb-Shanno update strategy.\n:BG: Broyden's \"good\" method.\n:Broyden: Broyden-class update scheme.\n:SR1: Symmetric Rank 1 update.\n:SSM: Structured Secant Method.\n:TSSM: Totally Structured Secant Method.\nverbose: Whether to print progress during the parameter estimation.\n\nDescription\n\nFides is a Newton-trust region optimizer for box-constrained optmization problems. More information on the algorithm can be found in [1]. Fides particularly excels when the full Hessian is too computationally expensive to compute, but a Gauss-Newton Hessian approximation can be computed (for more details see the documentation). In addition to supporting user Hessians via the PEtabODEProblem, it supports several Hessian approximation methods. Aa more extensive description than above see the Fides documentation.\n\nFröhlich and Sorger, PLoS computational biology, pp e1010322 (2022)\n\n\n\n\n\n","category":"type"},{"location":"API/#PEtab.IpoptOptimizer","page":"API","title":"PEtab.IpoptOptimizer","text":"IpoptOptimizer(LBFGS::Bool)\n\nSetup the Ipopt Interior-point Newton method optmizer for parameter estimation.\n\nIpopt can be configured to use either the Hessian method from the PEtabODEProblem (LBFGS=false) or an LBFGS scheme (LBFGS=true). For setting other Ipopt options, see IpoptOptions.\n\nSee also calibrate and calibrate_multistart.\n\nDescription\n\nIpopt is an Interior-point Newton method for constrained non-linear optimization problems. More information on the algorithm can be found in [1].\n\nWächter and Biegler, Mathematical programming, pp 25-57 (2006)\n\n\n\n\n\n","category":"type"},{"location":"API/#PEtab.IpoptOptions","page":"API","title":"PEtab.IpoptOptions","text":"IpoptOptions(; kwargs...)\n\nOptions for parameter estimation with IpoptOptimizer.\n\nMore details on the options can be found in the Ipopt documentation.\n\nSee also IpoptOptimizer, calibrate, and calibrate_multistart.\n\nKeyword Arguments\n\nprint_level = 0: Output verbosity level (valid values are 0 ≤ print_level ≤ 12)\nmax_iter = 1000: Maximum number of iterations\ntol = 1e-8: Relative convergence tolerance\nacceptable_tol = 1e-6: Acceptable relative convergence tolerance\nmax_wall_time 1e20: Maximum wall time optimization is allowed to run\nacceptable_obj_change_tol 1e20: Acceptance stopping criterion based on objective   function change.\n\n\n\n\n\n","category":"type"},{"location":"API/#PEtab.get_obs_comparison_plots","page":"API","title":"PEtab.get_obs_comparison_plots","text":"get_obs_comparison_plots(res, prob::PEtabODEProblem; kwargs...)::Dict\n\nPlot the model fit against data for all simulation conditions and all observable ids for a PEtab.jl parameter estimation result (res).\n\nEach entry in the returned Dict corresponds to plot(res, prob; obsids=[obsid], cid=cid, kwargs...) for all possible cid and all obsid.\n\n\n\n\n\n","category":"function"},{"location":"API/#PEtab.OptimizationProblem","page":"API","title":"PEtab.OptimizationProblem","text":"OptimizationProblem(prob::PEtabODEProblem; box_constraints::Bool = true)\n\nCreate an Optimization.jl OptimizationProblem from prob.\n\nTo use algorithms not compatible with box constraints (e.g., Optim.jl NewtonTrustRegion), set box_constraints = false. Note that with this option, optimizers may move outside the bounds, which can negatively impact performance. More information on how to use an OptimizationProblem can be found in the Optimization.jl documentation.\n\n\n\n\n\n","category":"function"},{"location":"API/#PEtab.PEtabLogDensity","page":"API","title":"PEtab.PEtabLogDensity","text":"PEtabLogDensity(prob::PEtabODEProblem)\n\nCreate a LogDensityProblem using the posterior and gradient functions from prob.\n\nThis LogDensityProblem interface defines everything needed to perform Bayesian inference with packages such as AdvancedHMC.jl (which includes algorithms like NUTS, used by Turing.jl), and AdaptiveMCMC.jl.\n\n\n\n\n\n","category":"type"},{"location":"API/#PEtab.to_prior_scale","page":"API","title":"PEtab.to_prior_scale","text":"to_prior_scale(xpetab, target::PEtabLogDensity)\n\nTransforms parameter x from the PEtab problem scale to the prior scale.\n\nThis conversion is needed for Bayesian inference, as in PEtab.jl Bayesian inference is performed on the prior scale.\n\nnote: Note\nTo use this function, the Bijectors, LogDensityProblems, and LogDensityProblemsAD packages must be loaded: using Bijectors, LogDensityProblems, LogDensityProblemsAD\n\n\n\n\n\n","category":"function"},{"location":"API/#PEtab.to_chains","page":"API","title":"PEtab.to_chains","text":"to_chains(res, target::PEtabLogDensity; kwargs...)::MCMCChains\n\nConverts Bayesian inference results obtained with PEtabLogDensity into an MCMCChains.\n\nres can be the inference results from AdvancedHMC.jl or AdaptiveMCMC.jl. The returned chain has the parameters on the prior scale.\n\nKeyword Arguments\n\nstart_time: Optional starting time for the inference, obtained with now().\nend_time: Optional ending time for the inference, obtained with now().\n\nnote: Note\nTo use this function, the MCMCChains package must be loaded: using MCMCChains\n\n\n\n\n\n","category":"function"},{"location":"pest_custom/#wrap_est","page":"Wrapping Optimization Packages","title":"Wrapping Optimization Packages","text":"A PEtabODEProblem contains all the necessary information for wrapping a suitable optimizer to estimate model parameters. Since wrapping a package can be cumbersome, PEtab.jl provides wrappers for performing single-start parameter estimation (with calibrate) and multi-start parameter estimation (with calibrate_multistart). More details can be found in this tutorial. Still, in some cases, it may be necessary to manually wrap one of the optimization packages not supported by PEtab.jl.\n\nThis tutorial show how to wrap an existing optimization package, using the IPNewton method from Optim.jl as an example. As a working example, we use the Michaelis-Menten enzyme kinetics model from the starting tutorial. Even though the code below provides the model as a ReactionSystem, everything works exactly the same if the model is provided as an ODESystem.\n\nusing Catalyst, PEtab\n\n# Create the dynamic model\nrn = @reaction_network begin\n    @parameters S0 c3=1.0\n    @species S(t)=S0\n    c1, S + E --> SE\n    c2, SE --> S + E\n    c3, SE --> P + E\nend\nspeciemap = [:E => 50.0, :SE => 0.0, :P => 0.0]\n\n# Observables\n@unpack E, S = rn\nobs_sum = PEtabObservable(S + E, 3.0)\n@unpack P = rn\n@parameters sigma\nobs_p = PEtabObservable(P, sigma)\nobservables = Dict(\"obs_p\" => obs_p, \"obs_sum\" => obs_sum)\n\n# Parameters to estimate\np_c1 = PEtabParameter(:c1)\np_c2 = PEtabParameter(:c2)\np_s0 = PEtabParameter(:S0)\np_sigma = PEtabParameter(:sigma)\npest = [p_c1, p_c2, p_s0, p_sigma]\n\n# Simulate measurement data with 'true' parameters\nusing OrdinaryDiffEq, DataFrames\nps = [:c1 => 1.0, :c2 => 10.0, :c3 => 1.0, :S0 => 100.0]\nu0 = [:S => 100.0, :E => 50.0, :SE => 0.0, :P => 0.0]\ntspan = (0.0, 10.0)\noprob = ODEProblem(rn, u0, tspan, ps)\nsol = solve(oprob, Rodas5P(); saveat = 0:0.5:10.0)\nobs_sum = (sol[:S] + sol[:E]) .+ randn(length(sol[:E]))\nobs_p = sol[:P] + .+ randn(length(sol[:P]))\ndf_sum = DataFrame(obs_id = \"obs_sum\", time = sol.t, measurement = obs_sum)\ndf_p = DataFrame(obs_id = \"obs_p\", time = sol.t, measurement = obs_p)\nmeasurements = vcat(df_sum, df_p)\n\nmodel = PEtabModel(rn, observables, measurements, pest; speciemap = speciemap)\npetab_prob = PEtabODEProblem(model)\nnothing # hide","category":"section"},{"location":"pest_custom/#Extracting-Relevant-Input-from-a-PEtabODEProblem","page":"Wrapping Optimization Packages","title":"Extracting Relevant Input from a PEtabODEProblem","text":"A numerical optimizer requires an objective function, and derivative-based methods also need a gradient function and, in some cases, a Hessian function. Following the PEtab standard, PEtab.jl works with likelihoods, so the objective function corresponds to the negative log-likelihood (nllh), which can be accessed with:\n\nx = get_x(petab_prob)\nnllh = petab_prob.nllh(x; prior = true)\n\nHere, the keyword argument prior = true (default) ensures that potential parameter priors are considered when computing the likelihood. Furthermore, the PEtabODEProblem provides both in-place and out-of-place gradient functions:\n\ng_inplace = similar(x)\npetab_prob.grad!(g_inplace, x; prior = true)\ng_outplace = petab_prob.grad(x)\n\nas well as in-place and out-of-place Hessian functions:\n\nh_inplace = zeros(length(x), length(x))\npetab_prob.hess!(h_inplace, x; prior = true)\nh_outplace = petab_prob.hess(x)\n\nIn the above cases, the input parameter vector is a ComponentArray, but a Vector input is also accepted, and in this case, the gradient functions will also output a Vector. Additionally, the gradients and Hessians are computed using the default methods in the PEtabODEProblem (for more details, see this page).\n\nLastly, for parameter estimation with ODE models, it is often useful to set parameter bounds. Because, without bounds, the optimization algorithm can explore regions where the ODE solver fails to solve the model which prolongs runtime [1]. The bounds can be accessed via:\n\nlb, ub = petab_prob.lower_bounds, petab_prob.upper_bounds\nnothing # hide\n\nBoth lb and ub are ComponentArrays. If an optimization package does not support ComponentArray (as in the example below), they can be converted to a Vector by calling collect.","category":"section"},{"location":"pest_custom/#Wrapping-Optim.jl-IPNewton","page":"Wrapping Optimization Packages","title":"Wrapping Optim.jl IPNewton","text":"From the Optim.jl documentation, we can see that in order to use the IPNewton method, we need to provide the objective, gradient, Hessian, and parameter bounds, where the latter are provided as vectors. Using the information outlined above, we can do:\n\nusing Optim\nx0 = collect(get_x(petab_prob))\ndf = TwiceDifferentiable(petab_prob.nllh, petab_prob.grad!, petab_prob.hess!, x0)\ndfc = TwiceDifferentiableConstraints(collect(lb), collect(ub))\nnothing # hide\n\nNote that we convert any ComponentArray to a Vector with collect. Given this, we can perform parameter estimation with x0 as the starting point:\n\nres = Optim.optimize(df, dfc, x0, IPNewton())","category":"section"},{"location":"pest_custom/#References","page":"Wrapping Optimization Packages","title":"References","text":"F. Fröhlich and P. K. Sorger. Fides: Reliable trust-region optimization for parameter estimation of ordinary differential equation models. PLoS computational biology 18, e1010322 (2022).\n\n\n\n","category":"section"},{"location":"pest_select/#Model-Selection-with-PEtab-Select","page":"Model Selection with PEtab-select","title":"Model Selection with PEtab Select","text":"Sometimes we have competing hypotheses (model structures) that we want to compare to ultimately select the best model/hypothesis. There are various approaches for model selection, such as forward search, backward search, and exhaustive search, where models are compared based on information criteria like AIC or BIC. Additionally, there are efficient algorithms that combine both backward and forward search, such as Famos [11]. All these model selection methods are supported by the Python package PEtab Select, for which PEtab.jl provides an interface.\n\nThis advanced documentation page assumes that you know how to import and crate PEtab problems in the standard format (a tutorial can be found here) as well as the basics of multi-start parameter estimation with PEtab.jl (a tutorial can be found here). Additionally, since PEtab Select is a Python package, to run this code you need to have PyCall.jl installed, and you must build PyCall with a Python environment that has petab_select installed:\n\nusing PyCall\n# Path to Python executable with PEtab Select installed\npath_python_exe = \"path_python\"\nENV[\"PYTHON\"] = path_python_exe\n# Build PyCall with the PEtab Select Python environment\nimport Pkg\nPkg.build(\"PyCall\")\n\nnote: Note\nVersion >0.3 of PEtab Select must be installed.\n\nnote: Note\nModel selection is currently only possible for problem in the PEtab Select standard format. We plan to add a Julia interface.","category":"section"},{"location":"pest_select/#Model-Selection-Example","page":"Model Selection with PEtab-select","title":"Model Selection Example","text":"PEtab.jl provides support for PEtab Select through the petab_select function:\n\nAs an example, for a simple signaling model (files can be downloaded from here), you can run PEtab Select with the IPNewton() algorithm:\n\nusing Optim, PEtab, PyCall\npath_yaml = joinpath(@__DIR__, \"assets\", \"petab_select\", \"petab_select_problem.yaml\")\npath_res = petab_select(path_yaml, IPNewton(); nmultistarts=10)\n\n┌ Info: PEtab select problem info\n│ Method: brute_force\n└ Criterion: AIC\n[ Info: Model selection round 1 with 1 candidates - as the code compiles in this round it takes extra long time https://xkcd.com/303/\n[ Info: Callibrating model M1_1\n[ Info: Saving results for best model at /home/sebpe/.julia/dev/PEtab/docs/build/assets/petab_select/PEtab_select_brute_force_AIC.yaml\n\nWhere the YAML file storing the model selection results is saved at path_res.\n\nM. Gabel, T. Hohl, A. Imle, O. T. Fackler and F. Graw. FAMoS: A Flexible and dynamic Algorithm for Model Selection to analyse complex systems dynamics. PLOS Computational Biology 15, e1007230 (2019).\n\n\n\n","category":"section"},{"location":"pest_select/#PEtab.petab_select-pest_select","page":"Model Selection with PEtab-select","title":"PEtab.petab_select","text":"petab_select(path_yaml, alg; nmultistarts = 100, kwargs...) -> path_res\n\nFor a PEtab-select problem, perform model selection with the method specified in the PEtab select problem files. Returns the path (path_res) to a YAML-file with model selection results.\n\nThe general model selection (e.g. to use forward-search) options are specified in the PEtab-select files. For details on how to set this up, see the PEtab-select documentation.\n\nFor each round of model selection, the candidate models are parameter estimated using multi-start parameter estimation, with nmultistarts performed for each model. The objective values obtained from parameter estimation are then used for the next round of  model evaluation.\n\nA list of available and recommended optimization algorithms (alg) can be found in the package documentation and calibrate documentation.\n\nSee also calibrate_multistart.\n\nKeyword Arguments\n\nkwargs: The same keywords accepted by PEtabODEProblem and calibrate.\n\n\n\n\n\n","category":"function"},{"location":"pest_plot/#optimization_output_plotting","page":"Plotting Estimation Results","title":"Plots Evaluating Parameter Estimation","text":"Following parameter estimation, it is prudent to evaluate the estimation results. The most straightforward approach is to simulate the model with the estimated parameters and inspect the fit. While informative, this kind of plot does not help determine whether:\n\nThere are unfound parameter sets that yield better fits than those found (indicating that a local minimum was reached).\nThere are additional parameter sets yielding equally good fits to those found (suggesting a parameter identifiability problem).\n\nThis page demonstrates various plots implemented in PEtab for evaluating parameter estimation results. These plots can be generated by calling plot on the output of calibrate_model (a PEtabOptimisationResult structure) or calibrate_multistart (a PEtabMultistartResult structure), with the plot_type argument allowing you to select the type of plot. There are two main types of plots that can be generated: (i) those that evaluate parameter estimation results (e.g., objective value, model parameter values), and (ii) those that evaluate and visualize how well the model fits the measured data. This tutorial covers both types.","category":"section"},{"location":"pest_plot/#Parameter-Estimation-Result-Plots","page":"Plotting Estimation Results","title":"Parameter Estimation Result Plots","text":"As a working example, we use already pre-computed parameter estimation results for a published signaling model, which we load into a PEtabMultistartResult struct (the files to load can be found here):\n\nusing PEtab, Plots\npath_res = joinpath(@__DIR__, \"assets\", \"optimization_results\", \"boehm\")\nms_res = PEtabMultistartResult(path_res)\ndefault(left_margin=12.5Plots.Measures.mm, bottom_margin=12.5Plots.Measures.mm, size = (600*1.25, 400 * 1.25), palette = [\"#CC79A7\", \"#009E73\", \"#0072B2\", \"#D55E00\", \"#999999\", \"#E69F00\", \"#56B4E9\", \"#F0E442\"], linewidth=4.0) # hide\nnothing # hide","category":"section"},{"location":"pest_plot/#Objective-Function-Evaluations-Plots","page":"Plotting Estimation Results","title":"Objective Function Evaluations Plots","text":"The objective function evaluation plot can be generated by setting plot_type=waterfall, and is available for both single-start and multi-start optimization results. This plot shows the objective value for each iteration of the optimization process. For single-start optimization results, a single trajectory of dots is plotted. For multi-start optimization results, each run corresponds to a trajectory of dots.\n\nplot(ms_res; plot_type=:objective)\n\nIf the objective function fails to successfully simulate the model for a particular parameter set (indicating a poor fit), the trajectory for said run is marked with crosses instead of circles.\n\nIn this and other plots for multi-start parameter estimation, different runs are separated by color. The color is assigned via a clustering process that identifies runs converging to the same local minimum (details and tunable options can be found here). Additionally, when many multi-starts are performed, plots like the one above can become too cluttered. Therefore, only the 10 best runs are shown by default, but this can be customized.\n\nnote: Note\nFor the :objective plot type (as well as the :best_objective, :waterfall, and :runtime_eval plot types), PEtab automatically determine whether to use linear or logarithmic scaling of the y-axis. If the largest value in the plot is at least two orders of magnitude larger than the smallest one, logarithmic scaling is used (else, linear). Petab also checks whether a logarithmic y-axis is used in combination with negative objective values. As these cannot be plotted on the logarithmic scale, an automatic rescaling is performed. Here, from each value plotmin - 1 is subtracted, where plotmin is the minimal value encountered in that plot (i.e. the smallest value is set to 1, and other values are scaled linearly with it). These defaults can be changed through the yaxis_scale (scaling of the y-axis) and obj_shift arguments to plot.","category":"section"},{"location":"pest_plot/#Best-Objective-Function-Evaluations-Plots","page":"Plotting Estimation Results","title":"Best Objective Function Evaluations Plots","text":"The best objective function evaluation plot can be generated by setting plot_type=waterfall, and is available for both single-start and multi-start optimization results. This plot is similar to the objective function evaluation plot, but instead, it shows the best value reached so far during the process (and is therefore a decreasing function). This is the default plot type for single-start parameter estimation.\n\nplot(ms_res; plot_type=:best_objective)","category":"section"},{"location":"pest_plot/#Waterfall-Plots","page":"Plotting Estimation Results","title":"Waterfall Plots","text":"The waterfall plot can be generated by setting plot_type=waterfall, and is only available for multi-start optimization results. This plot-type shows final objective values of all runs, sorted from best to worst. Typically, local minima can be identified as plateaus in the plot, and in PEtab runs with similar final objective value are grouped by colors. This plot is also the default for multi-start optimization results.\n\nplot(ms_res; plot_type=:waterfall)\n\nWe strongly recommend to include a waterfall plot when reporting results from a multistart parameter estimation run. For more information on interpreting a waterfall plot, see Fig. 5 in [2].","category":"section"},{"location":"pest_plot/#Parallel-Coordinates-Plots","page":"Plotting Estimation Results","title":"Parallel Coordinates Plots","text":"The parallel coordinates plot can be generated by setting plot_type=parallel_coordinates, and it is available for multi-start optimization results. This plot shows parameter values for the best parameter estimation runs, with each run represented by a line. The parameter values are normalized, where 0 corresponds to the minimum value encountered for that parameter and 1 to the maximum. If several runs share similar parameter values, the runs in this cluster likely converged to the same local minimum. Meanwhile, if runs in the same cluster show widely different values for a particular parameter, it indicates that the parameter is unidentifiable (i.e., multiple values of that parameter fit the data equally well).\n\nplot(ms_res; plot_type=:parallel_coordinates)","category":"section"},{"location":"pest_plot/#Runtime-Evaluation-Plots","page":"Plotting Estimation Results","title":"Runtime Evaluation Plots","text":"The runtime evaluation plot can be generated by setting the plot_type=runtime_eval, and it is only available for multi-start optimization results. It is a scatter plot that shows the relationship between runtime and final objective value for each run:\n\nplot(ms_res; plot_type=:runtime_eval)","category":"section"},{"location":"pest_plot/#optimization_output_plotting_multirun_clustering","page":"Plotting Estimation Results","title":"Multi-Start Run Color Clustering","text":"When using the calibrate_multistart function, multiple parameter estimation runs are performed. When plotting results for multiple runs, a clustering function is applied by default to identify runs that have likely converged to the same local minimum, and these runs are assigned the same color. The default clustering method is the objective_value_clustering function, which clusters runs if their objective function values are within 0.1 of each other. Users can define their own clustering function and supply it to the plot command via the clustering_function argument. The custom clustering function should take a Vector{PEtabOptimisationResult} as input and return a Vector{Int64} of the same size, where each index corresponds to the cluster assignment for that run.","category":"section"},{"location":"pest_plot/#optimization_output_plotting_multirun_indexing","page":"Plotting Estimation Results","title":"Sub-selecting Runs to Plot","text":"When plotting multi-start parameter estimation results with the :objective, :best_objective, or :parallel_coordinates plot types, the output becomes hard to read if more than 10 runs are performed. Therefore, for these plot types, only the 10 runs with the best final objective values are plotted by default. This can be adjusted using the best_idxs_n optional argument, an Int64 specifying how many runs to include in the plot (starting with the best one). Alternatively, the idxs optional argument can be used to specify the indexes of the runs to plot.\n\nFor the :waterfall and :runtime_eval plot types, all runs are plotted by default. However, both the best_idxs_n and idxs arguments can be provided.","category":"section"},{"location":"pest_plot/#Plotting-the-Model-Fit","page":"Plotting Estimation Results","title":"Plotting the Model Fit","text":"After fitting the model, it is useful to compare the model output against the measurement data. This can be done by providing both the optimization solution and the PEtabODEProblem to the plot command. By default, the plot will show the output solution for all observables for the first simulation condition. However, any subset of observables can be selected using the obsid option, and any simulation condition can be specified using the cid option. Moreover, if a problem has potential pre-equilibration IDs, a specific pre-equilibration condition can be selected using the preeq_id option.\n\nThis tutorial covers how to plot the model fit for different observables and simulation conditions. It assumes you are familiar with PEtab simulation conditions; if not, see this tutorial. As a working example, we use the Michaelis-Menten enzyme kinetics model from the starting tutorial, which we fit to for two simulation conditions (cond1 and cond2) and two observables (obs_e and obs_p).  Even though the code below encodes the model as a ReactionSystem, everything works exactly the same if the model is encoded as an ODESystem.\n\nusing Catalyst\nrn = @reaction_network begin\n    kB, S + E --> SE\n    kD, SE --> S + E\n    kP, SE --> P + E\nend\nu0 = [:E => 1.0, :SE => 0.0, :P => 0.0]\np_true = [:kB => 1.0, :kD => 0.1, :kP => 0.5]\n\n# Simulate data.\nusing OrdinaryDiffEq\n# cond1\noprob_true_cond1 = ODEProblem(rn,  [:S => 1.0; u0], (0.0, 10.0), p_true)\ntrue_sol_cond1 = solve(oprob_true_cond1, Rodas5P())\ndata_sol_cond1 = solve(oprob_true_cond1, Rodas5P(); saveat=1.0)\ncond1_t, cond1_e, cond1_p = (data_sol_cond1.t[2:end], (0.8 .+ 0.1*randn(10)) .*\n                             data_sol_cond1[:E][2:end], (0.8 .+ 0.1*randn(10)) .*\n                             data_sol_cond1[:P][2:end])\n\n# cond2\noprob_true_cond2 = ODEProblem(rn,  [:S => 0.5; u0], (0.0, 10.0), p_true)\ntrue_sol_cond2 = solve(oprob_true_cond2, Tsit5())\ndata_sol_cond2 = solve(oprob_true_cond2, Tsit5(); saveat=1.0)\ncond2_t, cond2_e, cond2_p = (data_sol_cond2.t[2:end], (0.8 .+ 0.1*randn(10)) .* \n                             data_sol_cond2[:E][2:end], (0.8 .+ 0.1*randn(10)) .* \n                             data_sol_cond2[:P][2:end])\n\nusing PEtab\n@unpack E, P = rn\nobs_e = PEtabObservable(E, 0.5)\nobs_p = PEtabObservable(P, 0.5)\nobservables = Dict(\"obs_e\" => obs_e, \"obs_p\" => obs_p)\n\np_kB = PEtabParameter(:kB)\np_kD = PEtabParameter(:kD)\np_kP = PEtabParameter(:kP)\npest = [p_kB, p_kD, p_kP]\n\ncond1 = Dict(:S => 1.0)\ncond2 = Dict(:S => 0.5)\nconds = Dict(\"cond1\" => cond1, \"cond2\" => cond2)\n\nusing DataFrames\nm_cond1_e = DataFrame(simulation_id=\"cond1\", obs_id=\"obs_e\", time=cond1_t,\n                      measurement=cond1_e)\nm_cond1_p = DataFrame(simulation_id=\"cond1\", obs_id=\"obs_p\", time=cond1_t,\n                      measurement=cond1_p)\nm_cond2_e = DataFrame(simulation_id=\"cond2\", obs_id=\"obs_e\", time=cond2_t,\n                      measurement=cond2_e)\nm_cond2_p = DataFrame(simulation_id=\"cond2\", obs_id=\"obs_p\", time=cond2_t,\n                      measurement=cond2_p)\nmeasurements = vcat(m_cond1_e, m_cond1_p, m_cond2_e, m_cond2_p)\n\nmodel = PEtabModel(rn , observables, measurements, pest; simulation_conditions = conds,\n                   speciemap=u0)\npetab_prob = PEtabODEProblem(model)\n\nusing Optim\nres = calibrate_multistart(petab_prob, IPNewton(), 50)\nnothing #hide\n\nFollowing parameter estimation, we can plot the fitted solution for P in the first simulation condition (cond1) as:\n\nusing Plots\ndefault(left_margin=12.5Plots.Measures.mm, bottom_margin=12.5Plots.Measures.mm, size = (600*1.25, 400 * 1.25), palette = [\"#CC79A7\", \"#009E73\", \"#0072B2\", \"#D55E00\", \"#999999\", \"#E69F00\", \"#56B4E9\", \"#F0E442\"], linewidth=4.0) # hide\nplot(res, petab_prob; obsids=[\"obs_p\"], cid=\"cond1\", linewidth = 2.0)\n\nTo instead wish to plot both observables for the second simulation condition (cond2), do:\n\nplot(res, petab_prob; obsids=[\"obs_e\", \"obs_p\"], cid=\"cond2\", linewidth = 2.0)\n\nIn this example, the obsid option is technically not required, as plotting all observables is the default behavior. Furthermore, by default, the observable formula is shown in the legend or label. If the observable formula is long (e.g., the sum of all model species), this can make the plot unreadable. To address this, you can display only the observable ID in the label by setting obsid_label = true:\n\nplot(res, petab_prob; obsids=[\"obs_e\", \"obs_p\"], cid=\"cond2\", linewidth = 2.0, obsid_label = true)\n\nIf as above a parameter estimation result (res) is provided, the fit for the best-found parameter vector is plotted. It can also be useful to plot the fit for another parameter vector, such as the initial values x0. This can be easily done, as the plot_fit function also works for any parameter vector that is in the correct order expected by PEtab.jl (for more on parameter order, see get_x). For example, to plot the fit for the initial value for parameter estimation run 1, do:\n\nx0 = res.runs[1].x0\nplot(x0, petab_prob; obsids=[\"obs_e\", \"obs_p\"], cid=\"cond2\", linewidth = 2.0)\n\nFinally, it is possible to retrieve a dictionary containing plots for all combinations of observables and simulation conditions with:\n\ncomp_dict = get_obs_comparison_plots(res, petab_prob; linewidth = 2.0)\nnothing # hide\n\nHere, comp_dict contains one entry for each condition (with keys corresponding to their condition IDs). Each entry is itself a dictionary that contains one entry for each observable (with keys corresponding to their observable IDs). To retrieve the plot for E and cond1 do:\n\ncomp_dict[\"cond1\"][\"obs_e\"]\n\nThe input to get_obs_comparison_plots can also be a parameter vector.","category":"section"},{"location":"pest_plot/#References","page":"Plotting Estimation Results","title":"References","text":"A. Raue, M. Schilling, J. Bachmann, A. Matteson, M. Schelke, D. Kaschek, S. Hug, C. Kreutz, B. D. Harms, F. J. Theis and others. Lessons learned from quantitative dynamical modeling in systems biology. PloS one 8, e74335 (2013).\n\n\n\n","category":"section"},{"location":"nonstiff_models/#nonstiff_models","page":"Non-Biology (Non-Stiff) Models","title":"Non-Biology (Non-Stiff) Models","text":"The default options when creating a PEtabODEProblem in PEtab.jl are based on extensive benchmarks for dynamic models in biology. A key feature of ODEs in biology is that they are often stiff [23]. While an exact definition of stiffness is elusive, informally, explicit (non-stiff) solvers struggle to efficiently solve stiff models. The degree of stiffness does not impact the choice of the optimal gradient method, as this depends on the number of parameters to estimate rather than the ODE solver. Therefore, using the default gradient method in PEtab.jl is often a good choice. However, for non-stiff models, using a different ODE solver than the default in PEtab.jl can drastically reduce runtime.\n\nIf a problem is non-stiff, it is much more computationally efficient to use an explicit (non-stiff) solver, as a non-linear system does not need to be solved at each iteration. However, choosing a purely explicit (non-stiff) solver is often not ideal. When performing multi-start parameter estimation using random initial points, benchmarks have shown that even if the model is non-stiff around the best parameter values, this may not hold for random parameter values. Therefore, for non-stiff (or mildly stiff) models, a good compromise is to use composite solvers that can automatically switch between a stiff and non-stiff solver. Therefore, a good setup often is:\n\npetab_prob = PEtabODEProblem(model; odesolver=ODESolver(AutoVern7(Rodas5P())))\n\nThis ODE solver automatically switches between solvers based on stiffness. For more details on non-stiff solver choices, as well as composite solvers, see the documentation for OrdinaryDiffEq.jl.","category":"section"},{"location":"nonstiff_models/#References","page":"Non-Biology (Non-Stiff) Models","title":"References","text":"P. Städter, Y. Schälte, L. Schmiester, J. Hasenauer and P. L. Stapor. Benchmarking of numerical integration methods for ODE models of biological systems. Scientific reports 11, 2696 (2021).\n\n\n\n","category":"section"},{"location":"#PEtab.jl","page":"Home","title":"PEtab.jl","text":"PEtab.jl is a Julia package for creating parameter estimation problems for fitting Ordinary Differential Equation (ODE) models to data in Julia.","category":"section"},{"location":"#Major-highlights","page":"Home","title":"Major highlights","text":"Support for coding parameter estimation problems directly in Julia, where the dynamic model can be provided as a Catalyst.jl ReactionSystem, a ModelingToolkit.jl ODESystem, or as an SBML file imported via SBMLImporter.jl.\nDirect import and full support for parameter estimation problems in the PEtab standard format\nSupport for a wide range of parameter estimation problem features, including multiple observables, multiple simulation conditions, models with events, and models with steady-state pre-equilibration simulations.\nIntegration with Julia's DifferentialEquations.jl ecosystem, which, among other things, means PEtab.jl supports the state-of-the-art ODE solvers in OrdinaryDiffEq.jl. Consequently, PEtab.jl is suitable for both stiff and non-stiff ODE models.\nSupport for efficient forward and adjoint gradient methods, suitable for small and large models, respectively.\nSupport for exact Hessian's for small models and good approximations for large models.\nIncludes wrappers for performing parameter estimation with optimization packages Optim.jl, Ipopt, Optimization.jl, and Fides.py.\nIncludes wrappers for performing Bayesian inference with the state-of-the-art NUTS sampler (the same sampler used in Turing.jl) or with AdaptiveMCMC.jl.\n\nnote: Star us on GitHub!\nIf you find the package useful in your work please consider giving us a star on GitHub. This will help us secure funding in the future to continue maintaining the package.\n\ntip: Latest news: PEtab.jl v3.0\nVersion 3.0 is a breaking release that added support for ModelingToolkit v9 and Catalyst v14. Along with updating these packages, PEtab.jl underwent a major update, with new functionality added as well as the renaming of several functions to be more consistent with the naming convention in the SciML ecosystem. See the HISTORY file for more details.","category":"section"},{"location":"#Installation","page":"Home","title":"Installation","text":"PEtab.jl is an officially registered Julia package, tested and supported on Linux, macOS and Windows. The easiest way to install it is via the Julia package manager. In the Julia REPL, enter:\n\njulia> ] add PEtab\n\nor alternatively\n\njulia> using Pkg; Pkg.add(\"PEtab\")\n\nPEtab.jl is compatible with Julia 1.10 and above. For best performance, we strongly recommend using the latest Julia version, which can be most reliably installed using juliaup.\n\nIf you encounter installation issues, please consult the troubleshooting guide.","category":"section"},{"location":"#Getting-help","page":"Home","title":"Getting help","text":"If you have any problems using PEtab, here are some helpful tips:\n\nRead the FAQ section in the online documentation.\nPost your questions in the #sciml-sysbio channel on the Julia Slack. While PEtab.jl is not exclusively for systems biology, the #sciml-sysbio channel is where the package authors are most active.\nIf you have encountered unexpected behavior or a bug, please open an issue on GitHub.","category":"section"},{"location":"#Citation","page":"Home","title":"Citation","text":"If you use PEtab.jl in work that is published, please cite the paper below:\n\n@article{PEtabBioinformatics2025,\n  title={PEtab.jl: advancing the efficiency and utility of dynamic modelling},\n  author={Persson, Sebastian and Fr{\\\"o}hlich, Fabian and Grein, Stephan and Loman, Torkel and Ognissanti, Damiano and Hasselgren, Viktor and Hasenauer, Jan and Cvijovic, Marija},\n  journal={Bioinformatics},\n  volume={41},\n  number={9},\n  pages={btaf497},\n  year={2025},\n  publisher={Oxford University Press}\n}","category":"section"},{"location":"import_petab/#import_petab_problem","page":"Importing PEtab Standard Format","title":"Importing PEtab Standard Format","text":"PEtab, from which PEtab.jl gets its name, is a flexible, table-based standard format for specifying parameter estimation problems [7]. If a problem is provided in this standard format, PEtab.jl can import it directly. This tutorial covers how to import PEtab problems.","category":"section"},{"location":"import_petab/#Input-a-Valid-PEtab-Problem","page":"Importing PEtab Standard Format","title":"Input - a Valid PEtab Problem","text":"To import a PEtab problem, a valid PEtab problem is required. A tutorial on creating a PEtab problem can be found in the PEtab documentation, and a linting tool is available in Python for checking correctness. Additionally, PEtab.jl performs several format checks when importing the problem.\n\nA collection of valid PEtab problems is also available in the PEtab benchmark repository. In this tutorial, we will use an already published model from the PEtab benchmark repository. Specifically, we will consider the STAT5 signaling model, referred to here as the Boehm model (after the first author) [8]. The PEtab files for this model can be found here.","category":"section"},{"location":"import_petab/#Importing-a-PEtabModel","page":"Importing PEtab Standard Format","title":"Importing a PEtabModel","text":"A PEtab problem consists of five files: an SBML model file, a table with simulation conditions, a table with observables, a table with measurements, and a table with parameters to estimate. These are tied together by a YAML file, and to import a problem, you only need to provide the YAML file path:\n\nusing PEtab\n# path_yaml depends on where the model is saved\npath_yaml = joinpath(@__DIR__, \"assets\", \"boehm\", \"Boehm_JProteomeRes2014.yaml\")\nmodel = PEtabModel(path_yaml)\nnothing # hide\n\nGiven a PEtabModel, it is straightforward to create a PEtabODEProblem:\n\npetab_prob = PEtabODEProblem(model)\n\nAs described in the starting tutorial, this PEtabODEProblem can then be used for parameter estimation, or Bayesian inference. For tunable options when importing a PEtab problem, see the API documentation.","category":"section"},{"location":"import_petab/#What-Happens-During-PEtab-Import-(Deep-Dive)","page":"Importing PEtab Standard Format","title":"What Happens During PEtab Import (Deep Dive)","text":"When importing a PEtab model, several things happen:\n\nThe SBML file is converted into a Catalyst.jl ReactionSystem using the SBMLImporter.jl package. This ReactionSystem is then converted into an ODESystem. During this step, the model is symbolically pre-processed, which includes computing the ODE Jacobian symbolically. The latter typically improves simulation performance.\nThe observable PEtab table is translated into Julia functions that compute observables (h), measurement noise (σ), and initial values (u0).\nAny potential model events are translated into Julia callbacks.\n\nAll of these steps happen automatically. By setting write_to_file=true when importing the model, the generated model functions can be found in the dir_yaml/Julia_model_files/ directory.","category":"section"},{"location":"import_petab/#References","page":"Importing PEtab Standard Format","title":"References","text":"L. Schmiester, Y. Schälte, F. T. Bergmann, T. Camba, E. Dudkin, J. Egert, F. Fröhlich, L. Fuhrmann, A. L. Hauber, S. Kemmer and others. PEtab—Interoperable specification of parameter estimation problems in systems biology. PLoS computational biology 17, e1008646 (2021).\n\n\n\nM. E. Boehm, L. Adlung, M. Schilling, S. Roth, U. Klingmüller and W. D. Lehmann. Identification of isoform-specific dynamics in phosphorylation-dependent STAT5 dimerization by quantitative mass spectrometry and mathematical modeling. Journal of proteome research 13, 5685–5694 (2014).\n\n\n\n","category":"section"},{"location":"tutorial/#tutorial","page":"Tutorial","title":"Tutorial","text":"This overarching tutorial of PEtab.jl covers how to create a parameter estimation problem in Julia (a PEtabODEProblem) and how to estimate the unknown parameters for the created problem.","category":"section"},{"location":"tutorial/#Input-Problem","page":"Tutorial","title":"Input Problem","text":"As a working example, this tutorial considers the Michaelis-Menten enzyme kinetics chemical reaction model:\n\nS + E xrightarrowc_1 SE \nSE xrightarrowc_2 S + E \nSE xrightarrowc_3 P + E\n\nWhich, via the law of mass action, can be converted to a system of Ordinary Differential Equations (ODEs):\n\nbeginalign*\n    fracmathrmdEmathrmdt = c_2 SE + c_3 SE - c_1 S cdot E  \n    fracmathrmdPmathrmdt = c_3 SE \n    fracmathrmdSmathrmdt = c_2 SE - c_1 S cdot E \n    fracmathrmdSEmathrmdt =  -c_2 SE - c_3 SE + c_1 S cdot E\nendalign*\n\nFor the working example, we assume that the initial values for the species [S, E, SE, P] are:\n\nS(t_0) = S_0 quad E(t_0) = 500 quad SE(t_0) = 00 quad P(t_0) = 00\n\nAnd that the observables for which we have time-lapse measurement data are the sum of S + E as well as P:\n\nbeginalign*\n    obs_1 = S + E \n    obs_2 = P\nendalign*\n\nFor the parameter estimation, we aim to estimate the parameters [c1, c2] and the initial value S(t_0) = S0 (a total of three parameters), while assuming c3 = 1.0 is known. This tutorial demonstrates how to set up this parameter estimation problem (create a PEtabODEProblem) and estimate parameters using Optim.jl.","category":"section"},{"location":"tutorial/#Creating-the-Parameter-Estimation-Problem","page":"Tutorial","title":"Creating the Parameter Estimation Problem","text":"To define a parameter estimation problem we need four components:\n\nDynamic Model: The dynamic model can be provided as either a Catalyst.jl ReactionSystem or a ModellingToolkit.jl ODESystem.\nObservable Formulas: To link the model to the measurement data, we need observable formulas. Since real-world data often comes with measurement noise, PEtab also requires that noise formulas and noise distributions are provided for each observable. All of this is specified with the PEtabObservable.\nParameters to Estimate: A parameter estimation problem needs parameters to be estimated. Since often only a subset of the dynamic model parameters is estimated, PEtab explicitly requires that the parameters to be estimated are specified as a PEtabParameter. It is also possible to set priors on these parameters.\nMeasurement Data: To estimate parameters, measurement data is required. This data should be provided as a DataFrame in the format explained below.\nSimulation Conditions (Optional): Measurements are often collected under various experimental conditions, which correspond to different simulation conditions. Details on how to handle such conditions are provided in this tutorial.","category":"section"},{"location":"tutorial/#Defining-the-Dynamic-Model","page":"Tutorial","title":"Defining the Dynamic Model","text":"The dynamic model can be either a Catalyst.jl ReactionSystem or a ModelingToolkit.jl ODESystem. For the Michaelis-Menten model above, the Catalyst representation is given by:\n\nusing Catalyst\nrn = @reaction_network begin\n    @parameters S0 c3=1.0\n    @species S(t)=S0\n    c1, S + E --> SE\n    c2, SE --> S + E\n    c3, SE --> P + E\nend\n\nParameters that are constant (c3) and those that set initial values (S0) should be defined in the parameters block. Values for parameters that are to be estimated (here [c1, c2, S0]) do not need to be specified. Similarly, for species, only those with a parameter-dependent initial value need to be defined in the species block, while species with a constant initial value can be defined directly in the system (similar to c3 above) or as a specie map:\n\nspeciemap = [:E => 50.0, :SE => 0.0, :P => 0.0]\n\nAny species or parameters with undeclared initial values default to 0. For additional details on how to create a ReactionSystem, see the excellent Catalyst documentation.\n\nUsing a ModelingToolkit ODESystem, the model is defined as:\n\nusing ModelingToolkit\nusing ModelingToolkit: t_nounits as t, D_nounits as D\n@mtkmodel SYS begin\n    @parameters begin\n        S0\n        c1\n        c2\n        c3 = 1.0\n    end\n    @variables begin\n        S(t) = S0\n        E(t) = 50.0\n        SE(t) = 0.0\n        P(t) = 0.0\n    end\n    @equations begin\n        D(S) ~ -c1 * S * E + c2 * SE\n        D(E) ~ -c1 * S * E + c2 * SE + c3 * SE\n        D(SE) ~ c1 * S * E - c2 * SE - c3 * SE\n        D(P) ~ c3 * SE\n    end\nend\n@mtkbuild sys = SYS()\n\nFor an ODESystem, all parameters and species must be declared in the @mtkmodel block. If the value of a parameter or species is left empty (e.g., c2 above) and the parameter is not set to be estimated, it defaults to 0. For additional details on how to create an ODESystem model, see the ModelingToolkit documentation.","category":"section"},{"location":"tutorial/#Defining-the-Observables","page":"Tutorial","title":"Defining the Observables","text":"To connect the model with measurement data, we need an observable formula. Additionally, since measurement data is typically noisy, PEtab requires a measurement noise formula.\n\nFor example, let us assume we have observed the sum E + S (obs_1 above) with a known normally distributed measurement error (σ = 3.0). This in encoded as:\n\nusing PEtab\n@unpack E, S = rn\nobs_sum = PEtabObservable(S + E, 3.0)\n\nNote that @unpack is a Julia macro that can conveniently be used to extract any species from a Catalyst ReactionSystem (more details can be found here). In PEtabObservable, the first argument is the observed formula, and the second argument is the formula for the measurement error. In this case, we assumed a known measurement error (σ = 3.0), but often the measurement error is unknown and needs to be estimated. For example, let us assume we have observed P (obs_2) with an unknown measurement error sigma. This in encoded as:\n\n@unpack P = rn\n@parameters sigma\nobs_p = PEtabObservable(P, sigma)\n\nBy defining sigma as a PEtabParameter (explained below), it is estimated along with the other parameters. To complete the definition of the observables, we need to group all PEtabObservables together into a Dict and assign an appropriate name for each observable:\n\nobservables = Dict(\"obs_p\" => obs_p, \"obs_sum\" => obs_sum)\n\nMore formally, a PEtabObservable defines a likelihood function for an observable. By default, a normally distributed error and corresponding likelihood is assumed, but log-normal distribution is also supported. For more details, see the API.","category":"section"},{"location":"tutorial/#Defining-Parameters-to-Estimate","page":"Tutorial","title":"Defining Parameters to Estimate","text":"To set up a parameter estimation problem, we need to specify the parameters to estimate via PEtabParameter. To set c1 to be estimated, use:\n\np_c1 = PEtabParameter(:c1)\n\nFrom the printout, we see that by default c1 is assigned bounds [1e-3, 1e3]. This is because benchmarks have shown that using bounds is advantageous, as it prevents simulation failures during parameter estimation[1]. Furthermore, we see that by default c1 is estimated on a log10 scale. Benchmarks have demonstrated that estimating parameters on a log10 scale improves performance [2, 3]. Naturally, it is possible to change the bounds and/or scale; see the API for details.\n\nWhen specifying a PEtabParameter we can also provide prior information. For example, assume we know that c2 should have a value around 10. To account for this we can provide a prior for the parameter using any continuous distribution from Distributions.jl. For example, to assign a Normal(10.0, 0.3) prior to c2, do:\n\nusing Distributions\np_c2 = PEtabParameter(:c2; prior = Normal(10.0, 0.3))\n\nBy default, the prior is on a linear scale (not the default log10 scale), but this can be changed if needed. For more details, see the API.\n\nTo complete the definition of the parameters to estimate, we need to assign a PEtabParameter for each unknown and group them into a Vector:\n\np_s0 = PEtabParameter(:S0)\np_sigma = PEtabParameter(:sigma)\npest = [p_c1, p_c2, p_s0, p_sigma]","category":"section"},{"location":"tutorial/#Measurement-Data-Format","page":"Tutorial","title":"Measurement Data Format","text":"The measurement data should be provided in a DataFrame with the following format (the column names matter, but not the order):\n\nobs_id (str) time (float) measurement (float)\nid val val\n... ... ...\n\nWhere the columns correspond to:\n\nobs_id: The observable to which the measurement corresponds. It must match one of the keys in the PEtabObservable Dict.\ntime: The time point at which the measurement was collected.\nmeasurement: The measurement value.\n\nFor our working example, using simulated data, a valid measurement table would look like:\n\nusing OrdinaryDiffEq, DataFrames\n# Simulate with 'true' parameters\nps = [:c1 => 1.0, :c2 => 10.0, :c3 => 1.0, :S0 => 100.0]\nu0 = [:S => 100.0, :E => 50.0, :SE => 0.0, :P => 0.0]\ntspan = (0.0, 10.0)\noprob = ODEProblem(rn, u0, tspan, ps)\nsol = solve(oprob, Rodas5P(); saveat = 0:0.5:10.0)\nobs_sum = (sol[:S] + sol[:E]) .+ randn(length(sol[:E]))\nobs_p = sol[:P] .+ randn(length(sol[:P]))\ndf_sum = DataFrame(obs_id = \"obs_sum\", time = sol.t, measurement = obs_sum)\ndf_p = DataFrame(obs_id = \"obs_p\", time = sol.t, measurement = obs_p)\nmeasurements = vcat(df_sum, df_p)\nfirst(measurements, 5) # hide\n\nIt is important to note that the measurement table follows a tidy format [4], where each row corresponds to one measurement. Therefore, for repeated measurements at a single time point, one row should be added for each repeat.","category":"section"},{"location":"tutorial/#Bringing-It-All-Together","page":"Tutorial","title":"Bringing It All Together","text":"Given a model, observables, parameters to estimate, and measurement data, it is possible to create a PEtabODEProblem, which contains all the information needed for parameter estimation. This is done in a two-step process, where the first step is to create a PEtabModel. For our ReactionSystem, this is done as:\n\nmodel_rn = PEtabModel(rn, observables, measurements, pest; speciemap = speciemap)\nnothing # hide\n\nFor an ODESystem the syntax is the same:\n\nmodel_sys = PEtabModel(sys, observables, measurements, pest)\nnothing # hide\n\nNote that any potential speciemap or parametermap must be provided as a keyword. Given a PEtabModel, it is straightforward to create a PEtabODEProblem:\n\npetab_prob = PEtabODEProblem(model_rn)\n\nThe printout shows relevant statistics for the PEtabODEProblem. First, we see that there are 4 parameters to estimate. Additionally, we see that the ODE solver used for simulating the model is the stiff Rodas5P solver, and that both the gradient and Hessian are computed via forward-mode automatic differentiation using ForwardDiff.jl. These defaults are based on extensive benchmarks and typically do not need to be changed for models in biology. For models outside of biology, a discussion of the options can be found here. While the defaults generally perform well, they are not always perfect. Therefore, when creating a PEtabODEProblem, anything from the ODESolver to the gradient methods can be customized. For details, see the API.\n\nOverall, the PEtabODEProblem contains all the information needed for performing parameter estimation. Next, this tutorial covers how to estimate unknown model parameters given a PEtabODEProblem.","category":"section"},{"location":"tutorial/#Parameter-estimation","page":"Tutorial","title":"Parameter estimation","text":"A PEtabODEProblem (which we defined above) contains all the information needed to wrap a numerical optimization library to perform parameter estimation, and details on how to do this can be found here. However, wrapping existing optimization libraries is cumbersome, therefore PEtab.jl provides wrappers for Optim.jl, Ipopt, Optimization.jl, and Fides.py.\n\nThis section of the tutorial covers how to use Optim.jl to estimate parameters given a starting guess x0. Moreover, since the objective function to minimize for ODE models often contains multiple local minima, the tutorial also covers how to perform global optimization using multistart parameter estimation.","category":"section"},{"location":"tutorial/#Single-Start-Parameter-Estimation","page":"Tutorial","title":"Single-Start Parameter Estimation","text":"To perform parameter estimation with a numerical optimization algorithm, we typically need a starting point x0, where it is important that x0 follows the parameter order expected by the PEtabODEProblem. One way to obtain such a vector is by retrieving the PEtabODEProblem's vector of nominal values, which correspond to the optional parameter values specified in PEtabParameter (if unspecified, these values default to the mean of the lower and upper bounds). This vector can be retrieved with get_x:\n\nx0 = get_x(petab_prob)\n\nFrom the printout we see that x0 is a ComponentArray, so in addition to the parameter values, it also holds the parameter names. Additionally, we see that parameters like log10_c1 have a log10 prefix. This is because the parameter (by default) is estimated on the log10 scale, which, as mentioned above, often improves parameter estimation performance [3]. Consequently, when changing the value for this parameter, the new value should be provided on the log10 scale. For example, to change c1 to 10.0 do:\n\nx0.log10_c1 = log10(10.0)\nnothing # hide\n\nFor more details on how to interact with a ComponentArray, see the ComponentArrays.jl documentation. get_x is not the only way, and generally not the recommended way to retrieve a starting point. To avoid biasing the parameter estimation, it is recommended to use a random starting guess within the parameter bounds. This can be generated with get_startguesses:\n\nusing Random # hide\nRandom.seed!(123) # hide\nx0 = get_startguesses(petab_prob, 1)\nnothing # hide\n\nGiven a starting point x0, we can now perform the parameter estimation. As this is a small problem with only 4 parameters to estimate, we use the Interior-point Newton method from Optim.jl (for algorithm recommendations, see this page):\n\nusing Optim\nres = calibrate(petab_prob, x0, IPNewton())\n\nThe printout shows parameter estimation statistics, such as the final objective value fmin (which, since PEtab works with likelihoods, corresponds to the negative log-likelihood). We can further obtain the minimizing parameter vector:\n\nres.xmin\n\nThis vector is close to the true parameters used to simulate the data above. For information on additional statistics stored in res, see the API on PEtabOptimisationResult.\n\nLastly, to evaluate the parameter estimation, it is useful to plot how well the model fits the data. Using the built-in plotting functionality in PEtab, this is straightforward:\n\nusing Plots\ndefault(left_margin=12.5Plots.Measures.mm, bottom_margin=12.5Plots.Measures.mm, size = (600*1.25, 400 * 1.25), palette = [\"#CC79A7\", \"#009E73\", \"#0072B2\", \"#D55E00\", \"#999999\", \"#E69F00\", \"#56B4E9\", \"#F0E442\"], linewidth=4.0) # hide\nplot(res, petab_prob; linewidth = 2.0)\nplot(res, petab_prob; linewidth = 2.0) # hide\n\nEven though the plot looks good, it is important to remember that ODE models often have multiple local minima [2]. To ensure the global optimum is found, a global optimization approach is required. One effective method is multi-start parameter estimation, which we cover next.","category":"section"},{"location":"tutorial/#Multi-Start-Parameter-Estimation","page":"Tutorial","title":"Multi-Start Parameter Estimation","text":"In multi-start parameter estimation, n parameter estimation runs are initiated from n random starting points. The rationale is that a subset of these runs should converge to the global optimum, and even though this is a simple global optimization approach, benchmarks have shown that it performs well for ODE models in biology [2, 5].\n\nThe first step in multi-start parameter estimation is to generate n starting points. Simple uniform sampling is not preferred, as randomly generated points tend to cluster. Instead, a Quasi-Monte Carlo method, such as Latin hypercube sampling, is better suited to generate well-spread starting points. In get_startguesses, LatinHypercubeSample is the default method used. Therefore, n = 50 Latin hypercube-sampled starting points can be generated with:\n\nRandom.seed!(123) # hide\nx0s = get_startguesses(petab_prob, 50)\nnothing # hide\n\nBesides LatinHypercubeSample, get_startguesses also supports other sampling methods; for details, see the API. Given our starting points, we can perform multi-start parameter estimation:\n\nres = Any[]\nfor x0 in x0s\n    push!(res, calibrate(petab_prob, x0, IPNewton()))\nend\nnothing # hide\n\nAs manually generating start guesses and calling calibrate can be cumbersome, PEtab.jl provides a convenience function, calibrate_multistart. For example, to run n = 50 multistarts, do:\n\nRandom.seed!(123) # hide\nms_res = calibrate_multistart(petab_prob, IPNewton(), 50)\n\nThe printout shows parameter estimation statistics, such as the best objective value fmin across all runs. For further details on what is stored in ms_res see the API documentation for PEtabMultistartResult.\n\ntip: Parallelize Parameter Estimation\nRuntime of calibrate_multistart can often be reduced by performing parameter estimation runs in parallel. To do this, set the nprocs keyword argument, more details can be found here.\n\nFollowing multi-start parameter estimation, it is important to evaluate the results. One common evaluation approach is plotting, and a frequently used evaluation plot is the waterfall plot, which in a sorted manner shows the final objective values for each run:\n\nplot(ms_res; plot_type=:waterfall)\n\nIn the waterfall plot, each plateau corresponds to different local optima. Since many runs (dots) are found on the plateau with the smallest objective value, we can be confident that the global optimum has been found. Further, we can check how well the best run fits the data:\n\nplot(ms_res, petab_prob; linewidth = 2.0)","category":"section"},{"location":"tutorial/#Next-Steps","page":"Tutorial","title":"Next Steps","text":"This overarching tutorial provides an overview of how to create a parameter estimation problem in Julia. As an introduction, it showcases only a subset of the features supported by PEtab.jl for creating parameter estimation problems. In the extended tutorials, you will find how to handle:\n\nSimulation conditions: Sometimes data is gathered under various experimental conditions, where, for example, the initial concentration of a substrate differs between condition. To learn how to setup a problem with such simulation conditions see this tutorial.\nSteady-State Initialization: Sometimes the model should be at a steady state at time zero, before it is simulated and compared against data. To learn how to set up a problem with such pre-equilibration criteria, see this tutorial.\nEvents: Sometimes a model may incorporate events like substrate addition at specific time points or parameter changes when a state/species reaches a certain value. To learn how to add model events see this tutorial.\nCondition-Specific System/Model Parameters: Sometimes a subset of model parameters to estimate, such as protein synthesis rates, varies between simulation conditions, while other parameters remain constant across all conditions. To learn how to handle condition-specific parameters, see this tutorial.\nTimepoint Specific Parameters: Sometimes one observable is measured with different assays. This can be handled by introducing different observable parameters (e.g., scale and offset) and noise parameters for different measurements. To learn how to add timepoint-specific measurement and noise parameters, see this tutorial.\nImport PEtab Models: PEtab is a standard table-based format for parameter estimation. If a problem is provided in this standard format, PEtab.jl can import it directly. To learn how to import models in the standard format, see this tutorial.\n\nBesides creating a parameter estimation problem, this overarching tutorial demonstrated how to perform parameter estimation using Optim.jl. In addition, PEtab.jl also supports using Ipopt, Optimization.jl, and Fides.py. More information on available algorithms for parameter estimation can be found on this page. Besides frequentist parameter estimation, PEtab.jl also supports Bayesian inference with state-of-the-art samplers such as NUTS (the same sampler used in Turing.jl) and AdaptiveMCMC.jl. For more information, see the Bayesian inference page.\n\nLastly, when creating a PEtabODEProblem there are many configurable options (see the API). The default options are based on extensive benchmarks for dynamic models in biology, see this page. For how to configure models outside of biology, see this page. Additionally, for a discussion on available gradient and Hessian methods, see this page.","category":"section"},{"location":"tutorial/#Copy-Pasteable-Example","page":"Tutorial","title":"Copy Pasteable Example","text":"using Catalyst, PEtab\n# Create the dynamic model(s)\nrn = @reaction_network begin\n    @parameters S0 c3=1.0\n    @species S(t)=S0\n    c1, S + E --> SE\n    c2, SE --> S + E\n    c3, SE --> P + E\nend\nspeciemap = [:E => 50.0, :SE => 0.0, :P => 0.0]\n\nusing ModelingToolkit\nusing ModelingToolkit: t_nounits as t, D_nounits as D\n@mtkmodel SYS begin\n    @parameters begin\n        S0\n        c1\n        c2\n        c3 = 1.0\n    end\n    @variables begin\n        S(t) = S0\n        E(t) = 50.0\n        SE(t) = 0.0\n        P(t) = 0.0\n    end\n    @equations begin\n        D(S) ~ -c1 * S * E + c2 * SE\n        D(E) ~ -c1 * S * E + c2 * SE + c3 * SE\n        D(SE) ~ c1 * S * E - c2 * SE - c3 * SE\n        D(P) ~ c3 * SE\n    end\nend\n@mtkbuild sys = SYS()\n\n# Observables\n@unpack E, S = rn\nobs_sum = PEtabObservable(S + E, 3.0)\n@unpack P = rn\n@parameters sigma\nobs_p = PEtabObservable(P, sigma)\nobservables = Dict(\"obs_p\" => obs_p, \"obs_sum\" => obs_sum)\n\n# Parameters to estimate\nusing Distributions\np_c1 = PEtabParameter(:c1)\np_c2 = PEtabParameter(:c2; prior = Normal(10.0, 0.3))\np_s0 = PEtabParameter(:S0)\np_sigma = PEtabParameter(:sigma)\npest = [p_c1, p_c2, p_s0, p_sigma]\n\n# Simulate measurement data with 'true' parameters\nusing OrdinaryDiffEq, DataFrames\nps = [:c1 => 1.0, :c2 => 10.0, :c3 => 1.0, :S0 => 100.0]\nu0 = [:S => 100.0, :E => 50.0, :SE => 0.0, :P => 0.0]\ntspan = (0.0, 10.0)\noprob = ODEProblem(rn, u0, tspan, ps)\nsol = solve(oprob, Rodas5P(); saveat = 0:0.5:10.0)\nobs_sum = (sol[:S] + sol[:E]) .+ randn(length(sol[:E]))\nobs_p = sol[:P] + .+ randn(length(sol[:P]))\ndf_sum = DataFrame(obs_id = \"obs_sum\", time = sol.t, measurement = obs_sum)\ndf_p = DataFrame(obs_id = \"obs_p\", time = sol.t, measurement = obs_p)\nmeasurements = vcat(df_sum, df_p)\n\nmodel_sys = PEtabModel(sys, observables, measurements, pest)\nmodel_rn = PEtabModel(rn, observables, measurements, pest; speciemap = speciemap)\npetab_prob = PEtabODEProblem(model_rn)\n\n# Parameter estimation\nusing Optim, Plots\nx0 = get_startguesses(petab_prob, 1)\nres = calibrate(petab_prob, x0, IPNewton())\nplot(res, petab_prob; linewidth = 2.0)\n\nms_res = calibrate_multistart(petab_prob, IPNewton(), 50)\nplot(ms_res; plot_type=:waterfall)\nplot(ms_res, petab_prob; linewidth = 2.0)\nnothing # hide","category":"section"},{"location":"tutorial/#References","page":"Tutorial","title":"References","text":"F. Fröhlich and P. K. Sorger. Fides: Reliable trust-region optimization for parameter estimation of ordinary differential equation models. PLoS computational biology 18, e1010322 (2022).\n\n\n\nA. Raue, M. Schilling, J. Bachmann, A. Matteson, M. Schelke, D. Kaschek, S. Hug, C. Kreutz, B. D. Harms, F. J. Theis and others. Lessons learned from quantitative dynamical modeling in systems biology. PloS one 8, e74335 (2013).\n\n\n\nH. Hass, C. Loos, E. Raimundez-Alvarez, J. Timmer, J. Hasenauer and C. Kreutz. Benchmark problems for dynamic modeling of intracellular processes. Bioinformatics 35, 3073–3082 (2019).\n\n\n\nH. Wickham. Tidy data. Journal of statistical software 59, 1–23 (2014).\n\n\n\nA. F. Villaverde, F. Fröhlich, D. Weindl, J. Hasenauer and J. R. Banga. Benchmarking optimization methods for parameter estimation in large kinetic models. Bioinformatics 35, 830–838 (2019).\n\n\n\n","category":"section"}]
}
